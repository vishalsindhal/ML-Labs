{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "lXLyhZJMrIdE",
        "outputId": "c8b1cf9f-266e-404a-ba97-7613975b24f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73a2259b-006b-49c4-ae56-76ea26b7d76e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-73a2259b-006b-49c4-ae56-76ea26b7d76e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BuyComputer.csv to BuyComputer.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  EstimatedSalary  Purchased\n",
              "0   19            19000          0\n",
              "1   35            20000          0\n",
              "2   26            43000          0\n",
              "3   27            57000          0\n",
              "4   19            76000          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dcb5b4f-e3d1-4ee4-a357-9fc0cc5aad6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dcb5b4f-e3d1-4ee4-a357-9fc0cc5aad6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dcb5b4f-e3d1-4ee4-a357-9fc0cc5aad6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dcb5b4f-e3d1-4ee4-a357-9fc0cc5aad6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "data = pd.read_csv(io.BytesIO(uploaded['BuyComputer.csv']))\n",
        "\n",
        "data.drop(columns=['User ID',],axis=1,inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yMs3NempRqnM",
        "outputId": "cc1020d0-b358-4cb3-fd22-c276fad78a88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Age  EstimatedSalary  Purchased\n",
              "0     19            19000          0\n",
              "1     35            20000          0\n",
              "2     26            43000          0\n",
              "3     27            57000          0\n",
              "4     19            76000          0\n",
              "..   ...              ...        ...\n",
              "395   46            41000          1\n",
              "396   51            23000          1\n",
              "397   50            20000          1\n",
              "398   36            33000          0\n",
              "399   49            36000          1\n",
              "\n",
              "[400 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3384666-bd98-4e07-8f51-133412387661\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>46</td>\n",
              "      <td>41000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>51</td>\n",
              "      <td>23000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>50</td>\n",
              "      <td>20000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>36</td>\n",
              "      <td>33000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>49</td>\n",
              "      <td>36000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3384666-bd98-4e07-8f51-133412387661')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3384666-bd98-4e07-8f51-133412387661 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3384666-bd98-4e07-8f51-133412387661');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring X as all columns excluding last\n",
        "X = data.iloc[:,:-1].values\n",
        "\n",
        "#Declare label as last column in the source file\n",
        "Y = data.iloc[:,-1].values\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0RcSAFlRvrL",
        "outputId": "e677db61-7926-4814-ba69-fa6462f0674d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    19,  19000],\n",
              "       [    35,  20000],\n",
              "       [    26,  43000],\n",
              "       [    27,  57000],\n",
              "       [    19,  76000],\n",
              "       [    27,  58000],\n",
              "       [    27,  84000],\n",
              "       [    32, 150000],\n",
              "       [    25,  33000],\n",
              "       [    35,  65000],\n",
              "       [    26,  80000],\n",
              "       [    26,  52000],\n",
              "       [    20,  86000],\n",
              "       [    32,  18000],\n",
              "       [    18,  82000],\n",
              "       [    29,  80000],\n",
              "       [    47,  25000],\n",
              "       [    45,  26000],\n",
              "       [    46,  28000],\n",
              "       [    48,  29000],\n",
              "       [    45,  22000],\n",
              "       [    47,  49000],\n",
              "       [    48,  41000],\n",
              "       [    45,  22000],\n",
              "       [    46,  23000],\n",
              "       [    47,  20000],\n",
              "       [    49,  28000],\n",
              "       [    47,  30000],\n",
              "       [    29,  43000],\n",
              "       [    31,  18000],\n",
              "       [    31,  74000],\n",
              "       [    27, 137000],\n",
              "       [    21,  16000],\n",
              "       [    28,  44000],\n",
              "       [    27,  90000],\n",
              "       [    35,  27000],\n",
              "       [    33,  28000],\n",
              "       [    30,  49000],\n",
              "       [    26,  72000],\n",
              "       [    27,  31000],\n",
              "       [    27,  17000],\n",
              "       [    33,  51000],\n",
              "       [    35, 108000],\n",
              "       [    30,  15000],\n",
              "       [    28,  84000],\n",
              "       [    23,  20000],\n",
              "       [    25,  79000],\n",
              "       [    27,  54000],\n",
              "       [    30, 135000],\n",
              "       [    31,  89000],\n",
              "       [    24,  32000],\n",
              "       [    18,  44000],\n",
              "       [    29,  83000],\n",
              "       [    35,  23000],\n",
              "       [    27,  58000],\n",
              "       [    24,  55000],\n",
              "       [    23,  48000],\n",
              "       [    28,  79000],\n",
              "       [    22,  18000],\n",
              "       [    32, 117000],\n",
              "       [    27,  20000],\n",
              "       [    25,  87000],\n",
              "       [    23,  66000],\n",
              "       [    32, 120000],\n",
              "       [    59,  83000],\n",
              "       [    24,  58000],\n",
              "       [    24,  19000],\n",
              "       [    23,  82000],\n",
              "       [    22,  63000],\n",
              "       [    31,  68000],\n",
              "       [    25,  80000],\n",
              "       [    24,  27000],\n",
              "       [    20,  23000],\n",
              "       [    33, 113000],\n",
              "       [    32,  18000],\n",
              "       [    34, 112000],\n",
              "       [    18,  52000],\n",
              "       [    22,  27000],\n",
              "       [    28,  87000],\n",
              "       [    26,  17000],\n",
              "       [    30,  80000],\n",
              "       [    39,  42000],\n",
              "       [    20,  49000],\n",
              "       [    35,  88000],\n",
              "       [    30,  62000],\n",
              "       [    31, 118000],\n",
              "       [    24,  55000],\n",
              "       [    28,  85000],\n",
              "       [    26,  81000],\n",
              "       [    35,  50000],\n",
              "       [    22,  81000],\n",
              "       [    30, 116000],\n",
              "       [    26,  15000],\n",
              "       [    29,  28000],\n",
              "       [    29,  83000],\n",
              "       [    35,  44000],\n",
              "       [    35,  25000],\n",
              "       [    28, 123000],\n",
              "       [    35,  73000],\n",
              "       [    28,  37000],\n",
              "       [    27,  88000],\n",
              "       [    28,  59000],\n",
              "       [    32,  86000],\n",
              "       [    33, 149000],\n",
              "       [    19,  21000],\n",
              "       [    21,  72000],\n",
              "       [    26,  35000],\n",
              "       [    27,  89000],\n",
              "       [    26,  86000],\n",
              "       [    38,  80000],\n",
              "       [    39,  71000],\n",
              "       [    37,  71000],\n",
              "       [    38,  61000],\n",
              "       [    37,  55000],\n",
              "       [    42,  80000],\n",
              "       [    40,  57000],\n",
              "       [    35,  75000],\n",
              "       [    36,  52000],\n",
              "       [    40,  59000],\n",
              "       [    41,  59000],\n",
              "       [    36,  75000],\n",
              "       [    37,  72000],\n",
              "       [    40,  75000],\n",
              "       [    35,  53000],\n",
              "       [    41,  51000],\n",
              "       [    39,  61000],\n",
              "       [    42,  65000],\n",
              "       [    26,  32000],\n",
              "       [    30,  17000],\n",
              "       [    26,  84000],\n",
              "       [    31,  58000],\n",
              "       [    33,  31000],\n",
              "       [    30,  87000],\n",
              "       [    21,  68000],\n",
              "       [    28,  55000],\n",
              "       [    23,  63000],\n",
              "       [    20,  82000],\n",
              "       [    30, 107000],\n",
              "       [    28,  59000],\n",
              "       [    19,  25000],\n",
              "       [    19,  85000],\n",
              "       [    18,  68000],\n",
              "       [    35,  59000],\n",
              "       [    30,  89000],\n",
              "       [    34,  25000],\n",
              "       [    24,  89000],\n",
              "       [    27,  96000],\n",
              "       [    41,  30000],\n",
              "       [    29,  61000],\n",
              "       [    20,  74000],\n",
              "       [    26,  15000],\n",
              "       [    41,  45000],\n",
              "       [    31,  76000],\n",
              "       [    36,  50000],\n",
              "       [    40,  47000],\n",
              "       [    31,  15000],\n",
              "       [    46,  59000],\n",
              "       [    29,  75000],\n",
              "       [    26,  30000],\n",
              "       [    32, 135000],\n",
              "       [    32, 100000],\n",
              "       [    25,  90000],\n",
              "       [    37,  33000],\n",
              "       [    35,  38000],\n",
              "       [    33,  69000],\n",
              "       [    18,  86000],\n",
              "       [    22,  55000],\n",
              "       [    35,  71000],\n",
              "       [    29, 148000],\n",
              "       [    29,  47000],\n",
              "       [    21,  88000],\n",
              "       [    34, 115000],\n",
              "       [    26, 118000],\n",
              "       [    34,  43000],\n",
              "       [    34,  72000],\n",
              "       [    23,  28000],\n",
              "       [    35,  47000],\n",
              "       [    25,  22000],\n",
              "       [    24,  23000],\n",
              "       [    31,  34000],\n",
              "       [    26,  16000],\n",
              "       [    31,  71000],\n",
              "       [    32, 117000],\n",
              "       [    33,  43000],\n",
              "       [    33,  60000],\n",
              "       [    31,  66000],\n",
              "       [    20,  82000],\n",
              "       [    33,  41000],\n",
              "       [    35,  72000],\n",
              "       [    28,  32000],\n",
              "       [    24,  84000],\n",
              "       [    19,  26000],\n",
              "       [    29,  43000],\n",
              "       [    19,  70000],\n",
              "       [    28,  89000],\n",
              "       [    34,  43000],\n",
              "       [    30,  79000],\n",
              "       [    20,  36000],\n",
              "       [    26,  80000],\n",
              "       [    35,  22000],\n",
              "       [    35,  39000],\n",
              "       [    49,  74000],\n",
              "       [    39, 134000],\n",
              "       [    41,  71000],\n",
              "       [    58, 101000],\n",
              "       [    47,  47000],\n",
              "       [    55, 130000],\n",
              "       [    52, 114000],\n",
              "       [    40, 142000],\n",
              "       [    46,  22000],\n",
              "       [    48,  96000],\n",
              "       [    52, 150000],\n",
              "       [    59,  42000],\n",
              "       [    35,  58000],\n",
              "       [    47,  43000],\n",
              "       [    60, 108000],\n",
              "       [    49,  65000],\n",
              "       [    40,  78000],\n",
              "       [    46,  96000],\n",
              "       [    59, 143000],\n",
              "       [    41,  80000],\n",
              "       [    35,  91000],\n",
              "       [    37, 144000],\n",
              "       [    60, 102000],\n",
              "       [    35,  60000],\n",
              "       [    37,  53000],\n",
              "       [    36, 126000],\n",
              "       [    56, 133000],\n",
              "       [    40,  72000],\n",
              "       [    42,  80000],\n",
              "       [    35, 147000],\n",
              "       [    39,  42000],\n",
              "       [    40, 107000],\n",
              "       [    49,  86000],\n",
              "       [    38, 112000],\n",
              "       [    46,  79000],\n",
              "       [    40,  57000],\n",
              "       [    37,  80000],\n",
              "       [    46,  82000],\n",
              "       [    53, 143000],\n",
              "       [    42, 149000],\n",
              "       [    38,  59000],\n",
              "       [    50,  88000],\n",
              "       [    56, 104000],\n",
              "       [    41,  72000],\n",
              "       [    51, 146000],\n",
              "       [    35,  50000],\n",
              "       [    57, 122000],\n",
              "       [    41,  52000],\n",
              "       [    35,  97000],\n",
              "       [    44,  39000],\n",
              "       [    37,  52000],\n",
              "       [    48, 134000],\n",
              "       [    37, 146000],\n",
              "       [    50,  44000],\n",
              "       [    52,  90000],\n",
              "       [    41,  72000],\n",
              "       [    40,  57000],\n",
              "       [    58,  95000],\n",
              "       [    45, 131000],\n",
              "       [    35,  77000],\n",
              "       [    36, 144000],\n",
              "       [    55, 125000],\n",
              "       [    35,  72000],\n",
              "       [    48,  90000],\n",
              "       [    42, 108000],\n",
              "       [    40,  75000],\n",
              "       [    37,  74000],\n",
              "       [    47, 144000],\n",
              "       [    40,  61000],\n",
              "       [    43, 133000],\n",
              "       [    59,  76000],\n",
              "       [    60,  42000],\n",
              "       [    39, 106000],\n",
              "       [    57,  26000],\n",
              "       [    57,  74000],\n",
              "       [    38,  71000],\n",
              "       [    49,  88000],\n",
              "       [    52,  38000],\n",
              "       [    50,  36000],\n",
              "       [    59,  88000],\n",
              "       [    35,  61000],\n",
              "       [    37,  70000],\n",
              "       [    52,  21000],\n",
              "       [    48, 141000],\n",
              "       [    37,  93000],\n",
              "       [    37,  62000],\n",
              "       [    48, 138000],\n",
              "       [    41,  79000],\n",
              "       [    37,  78000],\n",
              "       [    39, 134000],\n",
              "       [    49,  89000],\n",
              "       [    55,  39000],\n",
              "       [    37,  77000],\n",
              "       [    35,  57000],\n",
              "       [    36,  63000],\n",
              "       [    42,  73000],\n",
              "       [    43, 112000],\n",
              "       [    45,  79000],\n",
              "       [    46, 117000],\n",
              "       [    58,  38000],\n",
              "       [    48,  74000],\n",
              "       [    37, 137000],\n",
              "       [    37,  79000],\n",
              "       [    40,  60000],\n",
              "       [    42,  54000],\n",
              "       [    51, 134000],\n",
              "       [    47, 113000],\n",
              "       [    36, 125000],\n",
              "       [    38,  50000],\n",
              "       [    42,  70000],\n",
              "       [    39,  96000],\n",
              "       [    38,  50000],\n",
              "       [    49, 141000],\n",
              "       [    39,  79000],\n",
              "       [    39,  75000],\n",
              "       [    54, 104000],\n",
              "       [    35,  55000],\n",
              "       [    45,  32000],\n",
              "       [    36,  60000],\n",
              "       [    52, 138000],\n",
              "       [    53,  82000],\n",
              "       [    41,  52000],\n",
              "       [    48,  30000],\n",
              "       [    48, 131000],\n",
              "       [    41,  60000],\n",
              "       [    41,  72000],\n",
              "       [    42,  75000],\n",
              "       [    36, 118000],\n",
              "       [    47, 107000],\n",
              "       [    38,  51000],\n",
              "       [    48, 119000],\n",
              "       [    42,  65000],\n",
              "       [    40,  65000],\n",
              "       [    57,  60000],\n",
              "       [    36,  54000],\n",
              "       [    58, 144000],\n",
              "       [    35,  79000],\n",
              "       [    38,  55000],\n",
              "       [    39, 122000],\n",
              "       [    53, 104000],\n",
              "       [    35,  75000],\n",
              "       [    38,  65000],\n",
              "       [    47,  51000],\n",
              "       [    47, 105000],\n",
              "       [    41,  63000],\n",
              "       [    53,  72000],\n",
              "       [    54, 108000],\n",
              "       [    39,  77000],\n",
              "       [    38,  61000],\n",
              "       [    38, 113000],\n",
              "       [    37,  75000],\n",
              "       [    42,  90000],\n",
              "       [    37,  57000],\n",
              "       [    36,  99000],\n",
              "       [    60,  34000],\n",
              "       [    54,  70000],\n",
              "       [    41,  72000],\n",
              "       [    40,  71000],\n",
              "       [    42,  54000],\n",
              "       [    43, 129000],\n",
              "       [    53,  34000],\n",
              "       [    47,  50000],\n",
              "       [    42,  79000],\n",
              "       [    42, 104000],\n",
              "       [    59,  29000],\n",
              "       [    58,  47000],\n",
              "       [    46,  88000],\n",
              "       [    38,  71000],\n",
              "       [    54,  26000],\n",
              "       [    60,  46000],\n",
              "       [    60,  83000],\n",
              "       [    39,  73000],\n",
              "       [    59, 130000],\n",
              "       [    37,  80000],\n",
              "       [    46,  32000],\n",
              "       [    46,  74000],\n",
              "       [    42,  53000],\n",
              "       [    41,  87000],\n",
              "       [    58,  23000],\n",
              "       [    42,  64000],\n",
              "       [    48,  33000],\n",
              "       [    44, 139000],\n",
              "       [    49,  28000],\n",
              "       [    57,  33000],\n",
              "       [    56,  60000],\n",
              "       [    49,  39000],\n",
              "       [    39,  71000],\n",
              "       [    47,  34000],\n",
              "       [    48,  35000],\n",
              "       [    48,  33000],\n",
              "       [    47,  23000],\n",
              "       [    45,  45000],\n",
              "       [    60,  42000],\n",
              "       [    39,  59000],\n",
              "       [    46,  41000],\n",
              "       [    51,  23000],\n",
              "       [    50,  20000],\n",
              "       [    36,  33000],\n",
              "       [    49,  36000]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X,Y ,\n",
        "                                   random_state=25, \n",
        "                                   test_size=0.25, \n",
        "                                   shuffle=True)\n",
        "     \n",
        "\n",
        "from os import XATTR_SIZE_MAX\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.fit_transform(X_test)\n",
        "     \n",
        "\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBjaca-uR6X8",
        "outputId": "c7b500e0-ce9d-4c85-fac7-32522db6ca6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.74794123,  0.1546519 ],\n",
              "       [-0.13969655, -0.60069237],\n",
              "       [ 1.37394551, -1.44319175],\n",
              "       [ 0.04950871,  0.00939338],\n",
              "       [ 1.46854813,  2.10111597],\n",
              "       [ 0.04950871, -0.57164067],\n",
              "       [-0.80191495,  2.24637449],\n",
              "       [ 2.0361639 ,  1.72344384],\n",
              "       [-0.42350443, -0.31017535],\n",
              "       [-0.23429918, -0.60069237],\n",
              "       [ 0.14411134,  1.49103022],\n",
              "       [-0.3289018 ,  1.20051319],\n",
              "       [-0.70731232, -0.25207194],\n",
              "       [ 1.09013762, -1.00741621],\n",
              "       [ 0.80632974,  0.50327233],\n",
              "       [-1.74794123,  0.41611722],\n",
              "       [ 1.94156127,  0.88094446],\n",
              "       [ 0.42791922, -0.48448556],\n",
              "       [ 0.04950871, -0.60069237],\n",
              "       [-0.23429918, -1.41414004],\n",
              "       [-0.04509392,  0.1837036 ],\n",
              "       [ 0.99553499,  1.83965065],\n",
              "       [-0.13969655,  1.57818533],\n",
              "       [-0.61270969, -1.61750196],\n",
              "       [-1.27492809, -0.45543386],\n",
              "       [-0.42350443,  1.22956489],\n",
              "       [-0.42350443, -0.04871002],\n",
              "       [-0.9911202 ,  1.92680576],\n",
              "       [ 0.61712448,  1.98490916],\n",
              "       [-0.3289018 , -0.80405429],\n",
              "       [-0.23429918,  0.03844509],\n",
              "       [ 1.84695865, -0.31017535],\n",
              "       [-1.46413334, -1.53034686],\n",
              "       [ 0.80632974, -1.41414004],\n",
              "       [ 1.09013762, -1.23982983],\n",
              "       [-0.89651757,  0.47422063],\n",
              "       [-0.70731232, -1.61750196],\n",
              "       [ 0.04950871, -0.33922705],\n",
              "       [-0.23429918, -0.39733045],\n",
              "       [ 0.42791922,  0.241807  ],\n",
              "       [ 0.14411134,  0.73568595],\n",
              "       [ 0.99553499,  0.56137573],\n",
              "       [-0.23429918,  0.50327233],\n",
              "       [ 0.42791922,  0.27085871],\n",
              "       [-0.51810706, -1.53034686],\n",
              "       [-0.70731232,  1.31672   ],\n",
              "       [ 0.99553499, -1.18172642],\n",
              "       [ 2.13076653, -1.06551961],\n",
              "       [-0.9911202 , -1.55939856],\n",
              "       [ 1.75235602, -0.31017535],\n",
              "       [ 0.14411134,  0.241807  ],\n",
              "       [ 0.23871397,  1.05525468],\n",
              "       [-0.23429918, -0.51353726],\n",
              "       [ 0.14411134,  0.1837036 ],\n",
              "       [-0.04509392, -0.51353726],\n",
              "       [-1.27492809, -1.50129515],\n",
              "       [ 0.33331659, -0.57164067],\n",
              "       [ 1.46854813, -1.06551961],\n",
              "       [ 0.14411134,  0.00939338],\n",
              "       [-1.55873597, -0.07776172],\n",
              "       [-1.6533386 ,  0.09654849],\n",
              "       [-1.55873597,  0.03844509],\n",
              "       [ 0.14411134, -0.83310599],\n",
              "       [ 0.14411134,  1.83965065],\n",
              "       [-0.23429918, -1.47224345],\n",
              "       [ 1.09013762,  2.04301257],\n",
              "       [ 0.90093236, -1.32698494],\n",
              "       [ 0.33331659, -0.54258897],\n",
              "       [ 0.42791922, -0.51353726],\n",
              "       [-0.61270969, -0.07776172],\n",
              "       [ 0.80632974,  0.73568595],\n",
              "       [ 0.04950871, -0.28112364],\n",
              "       [-0.9911202 , -1.47224345],\n",
              "       [-1.18032546,  0.27085871],\n",
              "       [ 0.99553499, -1.09457132],\n",
              "       [ 0.14411134, -0.33922705],\n",
              "       [-0.61270969,  0.09654849],\n",
              "       [-1.27492809, -0.36827875],\n",
              "       [-0.89651757,  0.41611722],\n",
              "       [-0.9911202 , -0.39733045],\n",
              "       [ 0.23871397, -0.16491683],\n",
              "       [ 0.33331659, -0.31017535],\n",
              "       [-1.18032546, -1.41414004],\n",
              "       [ 0.90093236,  1.05525468],\n",
              "       [ 1.75235602,  0.96809957],\n",
              "       [ 1.84695865, -1.29793323],\n",
              "       [-0.13969655,  1.37482341],\n",
              "       [ 1.37394551,  1.2586166 ],\n",
              "       [-1.08572283, -1.18172642],\n",
              "       [ 0.14411134,  0.12560019],\n",
              "       [-0.13969655,  0.12560019],\n",
              "       [-1.74794123, -1.50129515],\n",
              "       [ 1.09013762,  0.44516892],\n",
              "       [-0.13969655, -1.09457132],\n",
              "       [-1.08572283, -0.54258897],\n",
              "       [-0.23429918, -0.33922705],\n",
              "       [-0.51810706, -1.53034686],\n",
              "       [-0.80191495, -1.23982983],\n",
              "       [ 0.52252185,  1.20051319],\n",
              "       [ 0.23871397, -0.68784748],\n",
              "       [-1.46413334, -1.26888153],\n",
              "       [ 0.33331659,  0.03844509],\n",
              "       [-0.04509392,  0.27085871],\n",
              "       [-0.9911202 ,  0.56137573],\n",
              "       [-1.08572283,  0.27085871],\n",
              "       [ 0.99553499,  1.40387511],\n",
              "       [-1.08572283,  1.37482341],\n",
              "       [-0.61270969,  1.37482341],\n",
              "       [ 1.18474025, -0.77500259],\n",
              "       [-1.36953072, -0.22302024],\n",
              "       [-0.23429918,  0.03844509],\n",
              "       [ 0.99553499,  1.75249554],\n",
              "       [-1.55873597, -1.58845026],\n",
              "       [ 0.04950871, -0.16491683],\n",
              "       [ 0.90093236,  0.99715127],\n",
              "       [-0.04509392, -0.01965832],\n",
              "       [-0.42350443,  2.27542619],\n",
              "       [ 1.27934288,  2.18827108],\n",
              "       [-0.04509392, -0.39733045],\n",
              "       [-1.55873597,  0.50327233],\n",
              "       [ 1.84695865,  0.09654849],\n",
              "       [-0.80191495, -0.80405429],\n",
              "       [-0.23429918,  0.241807  ],\n",
              "       [-0.42350443, -0.57164067],\n",
              "       [-0.61270969,  0.53232403],\n",
              "       [-1.08572283,  0.27085871],\n",
              "       [-0.9911202 ,  0.53232403],\n",
              "       [-0.23429918,  0.12560019],\n",
              "       [-0.51810706,  2.30447789],\n",
              "       [-0.70731232,  0.241807  ],\n",
              "       [ 0.23871397,  0.12560019],\n",
              "       [ 0.23871397, -0.39733045],\n",
              "       [-0.89651757, -1.12362302],\n",
              "       [ 0.99553499,  1.95585746],\n",
              "       [-1.08572283,  0.03844509],\n",
              "       [ 0.42791922,  0.96809957],\n",
              "       [ 0.23871397,  2.07206427],\n",
              "       [ 1.94156127,  2.13016768],\n",
              "       [ 0.42791922, -0.16491683],\n",
              "       [-0.23429918, -1.26888153],\n",
              "       [ 0.23871397,  0.00939338],\n",
              "       [ 0.33331659,  0.03844509],\n",
              "       [-0.04509392,  2.13016768],\n",
              "       [ 0.14411134, -0.83310599],\n",
              "       [-0.23429918, -0.77500259],\n",
              "       [ 1.56315076, -0.01965832],\n",
              "       [ 0.99553499, -1.09457132],\n",
              "       [ 1.46854813,  0.03844509],\n",
              "       [ 2.13076653,  0.90999617],\n",
              "       [-0.51810706,  1.43292681],\n",
              "       [ 0.33331659,  0.03844509],\n",
              "       [-0.23429918, -0.36827875],\n",
              "       [-1.08572283, -1.12362302],\n",
              "       [ 0.90093236, -0.62974407],\n",
              "       [-1.6533386 , -0.62974407],\n",
              "       [-0.23429918,  0.06749679],\n",
              "       [-0.23429918,  1.08430638],\n",
              "       [-0.51810706,  1.3457717 ],\n",
              "       [ 1.46854813,  0.32896211],\n",
              "       [-0.61270969, -0.13586513],\n",
              "       [ 0.42791922, -0.01965832],\n",
              "       [-0.51810706,  1.3457717 ],\n",
              "       [-1.84254386, -0.07776172],\n",
              "       [ 0.14411134,  0.06749679],\n",
              "       [ 0.52252185,  1.69439214],\n",
              "       [ 0.90093236, -1.47224345],\n",
              "       [-0.23429918, -0.60069237],\n",
              "       [-0.13969655,  1.60723703],\n",
              "       [ 2.13076653,  1.08430638],\n",
              "       [ 0.23871397,  0.03844509],\n",
              "       [ 1.09013762,  0.50327233],\n",
              "       [-1.18032546, -1.09457132],\n",
              "       [-0.13969655, -0.48448556],\n",
              "       [-1.08572283,  0.44516892],\n",
              "       [-0.9911202 , -0.36827875],\n",
              "       [ 1.94156127, -1.38508834],\n",
              "       [ 1.18474025, -1.00741621],\n",
              "       [-0.23429918,  2.21732278],\n",
              "       [ 1.94156127,  0.70663425],\n",
              "       [-1.74794123, -0.01965832],\n",
              "       [-0.80191495,  0.27085871],\n",
              "       [-0.89651757, -0.97836451],\n",
              "       [-0.89651757, -0.33922705],\n",
              "       [ 0.71172711, -1.41414004],\n",
              "       [-0.70731232, -1.55939856],\n",
              "       [ 0.33331659,  0.27085871],\n",
              "       [ 2.0361639 ,  0.35801382],\n",
              "       [ 0.42791922,  0.56137573],\n",
              "       [-0.80191495,  0.12560019],\n",
              "       [ 0.33331659, -0.54258897],\n",
              "       [-0.80191495,  0.35801382],\n",
              "       [-0.23429918, -0.28112364],\n",
              "       [ 0.42791922,  0.06749679],\n",
              "       [-0.70731232,  0.27085871],\n",
              "       [ 2.13076653, -0.83310599],\n",
              "       [ 1.75235602,  1.81059895],\n",
              "       [ 2.13076653, -0.83310599],\n",
              "       [ 0.23871397,  0.2127553 ],\n",
              "       [ 0.14411134,  1.83965065],\n",
              "       [-1.27492809, -0.45543386],\n",
              "       [-0.04509392,  0.2127553 ],\n",
              "       [ 0.90093236, -1.18172642],\n",
              "       [-0.9911202 ,  0.73568595],\n",
              "       [-1.27492809, -1.26888153],\n",
              "       [-0.61270969,  0.1546519 ],\n",
              "       [-0.61270969, -1.53034686],\n",
              "       [ 0.90093236, -0.80405429],\n",
              "       [ 0.71172711, -1.29793323],\n",
              "       [-0.42350443, -0.80405429],\n",
              "       [-1.84254386,  0.44516892],\n",
              "       [-1.74794123, -1.32698494],\n",
              "       [ 0.33331659, -1.18172642],\n",
              "       [ 0.14411134,  0.00939338],\n",
              "       [ 0.99553499, -1.03646791],\n",
              "       [-0.9911202 , -0.36827875],\n",
              "       [ 1.56315076, -1.29793323],\n",
              "       [-1.08572283, -1.55939856],\n",
              "       [-0.42350443, -0.86215769],\n",
              "       [ 0.42791922,  1.08430638],\n",
              "       [-0.04509392, -0.54258897],\n",
              "       [-1.74794123, -1.29793323],\n",
              "       [ 1.94156127, -0.9493128 ],\n",
              "       [-0.89651757,  0.38706552],\n",
              "       [ 0.04950871,  1.22956489],\n",
              "       [-1.36953072,  0.32896211],\n",
              "       [-1.36953072, -0.13586513],\n",
              "       [-0.23429918, -1.38508834],\n",
              "       [-1.18032546,  0.241807  ],\n",
              "       [ 0.23871397, -0.28112364],\n",
              "       [ 0.42791922,  0.27085871],\n",
              "       [-0.61270969,  0.00939338],\n",
              "       [-0.3289018 ,  0.03844509],\n",
              "       [ 1.09013762, -1.23982983],\n",
              "       [-0.13969655, -0.22302024],\n",
              "       [-1.84254386, -0.54258897],\n",
              "       [ 0.90093236, -0.57164067],\n",
              "       [ 2.0361639 ,  0.1546519 ],\n",
              "       [-1.27492809,  0.38706552],\n",
              "       [ 0.42791922,  0.12560019],\n",
              "       [ 0.52252185,  1.81059895],\n",
              "       [-1.84254386, -0.77500259],\n",
              "       [ 1.27934288,  1.83965065],\n",
              "       [ 2.0361639 , -1.21077813],\n",
              "       [-1.84254386,  0.32896211],\n",
              "       [-1.27492809,  0.53232403],\n",
              "       [ 1.37394551,  2.30447789],\n",
              "       [ 2.0361639 , -0.83310599],\n",
              "       [ 1.27934288, -1.38508834],\n",
              "       [-1.46413334,  0.29991041],\n",
              "       [-0.3289018 ,  1.2876683 ],\n",
              "       [-1.08572283, -0.80405429],\n",
              "       [-0.04509392,  0.09654849],\n",
              "       [ 0.99553499, -0.86215769],\n",
              "       [-0.89651757,  0.241807  ],\n",
              "       [-0.13969655,  2.13016768],\n",
              "       [-0.61270969, -0.36827875],\n",
              "       [-0.23429918,  0.12560019],\n",
              "       [-1.46413334, -0.45543386],\n",
              "       [ 0.42791922,  2.27542619],\n",
              "       [ 0.80632974,  0.241807  ],\n",
              "       [-0.13969655,  0.82284106],\n",
              "       [ 1.65775339, -0.9202611 ],\n",
              "       [-1.08572283, -1.61750196],\n",
              "       [ 2.0361639 ,  2.10111597],\n",
              "       [ 0.33331659,  0.47422063],\n",
              "       [-1.08572283, -1.03646791],\n",
              "       [-0.04509392,  0.241807  ],\n",
              "       [ 1.56315076,  0.96809957],\n",
              "       [-0.89651757, -0.33922705],\n",
              "       [-0.51810706,  0.85189276],\n",
              "       [-0.70731232,  1.05525468],\n",
              "       [-0.42350443, -1.23982983],\n",
              "       [-1.27492809, -1.12362302],\n",
              "       [ 0.04950871,  0.27085871],\n",
              "       [-0.3289018 , -1.32698494],\n",
              "       [ 1.09013762,  0.09654849],\n",
              "       [-0.9911202 , -0.48448556],\n",
              "       [ 0.23871397, -0.31017535],\n",
              "       [ 0.23871397, -0.39733045],\n",
              "       [-0.42350443, -1.15267472],\n",
              "       [ 0.99553499,  0.09654849],\n",
              "       [ 1.46854813,  0.96809957],\n",
              "       [ 1.84695865, -1.09457132],\n",
              "       [-1.08572283,  0.29991041],\n",
              "       [ 0.71172711,  1.75249554],\n",
              "       [-0.23429918,  0.00939338],\n",
              "       [-1.08572283,  0.38706552],\n",
              "       [ 0.71172711, -0.74595088],\n",
              "       [ 0.33331659, -0.22302024],\n",
              "       [ 0.90093236, -1.06551961],\n",
              "       [ 0.80632974, -0.33922705],\n",
              "       [-1.6533386 ,  0.32896211],\n",
              "       [-0.04509392,  2.18827108],\n",
              "       [ 0.33331659, -0.74595088],\n",
              "       [ 1.37394551,  0.56137573],\n",
              "       [-0.04509392,  0.27085871],\n",
              "       [-0.23429918, -0.45543386],\n",
              "       [-0.70731232,  0.53232403],\n",
              "       [ 0.71172711, -1.12362302],\n",
              "       [-0.70731232,  0.47422063]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IUh4PmTR_xu",
        "outputId": "e9cf0615-27f7-497d-bc92-ed7519ea4898"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.11732603,  0.15441358],\n",
              "       [-0.11732603, -1.03573063],\n",
              "       [-0.01873273, -0.36436723],\n",
              "       [ 0.77001366, -1.06624715],\n",
              "       [ 1.65735335,  1.77178906],\n",
              "       [-0.11732603, -0.1507516 ],\n",
              "       [ 0.27704717,  0.12389706],\n",
              "       [ 1.06579356, -0.85263152],\n",
              "       [-0.11732603,  2.13798728],\n",
              "       [ 0.67142036, -1.37141234],\n",
              "       [-1.79341211,  0.45957877],\n",
              "       [-1.10325901, -1.09676367],\n",
              "       [ 0.17845387, -0.24230116],\n",
              "       [-1.79341211, -1.34089582],\n",
              "       [-0.21591932, -0.21178464],\n",
              "       [ 0.27704717,  0.36802921],\n",
              "       [-1.30044561,  0.70371091],\n",
              "       [ 0.86860696, -0.51694982],\n",
              "       [-0.31451262, -0.21178464],\n",
              "       [-0.90607242, -0.60849938],\n",
              "       [-0.11732603,  0.79526047],\n",
              "       [ 1.16438686, -1.43244537],\n",
              "       [ 0.86860696,  1.40559084],\n",
              "       [-0.90607242, -0.73056545],\n",
              "       [ 1.36157346,  2.1685038 ],\n",
              "       [-0.41310592, -0.73056545],\n",
              "       [ 2.15031985, -0.6390159 ],\n",
              "       [ 0.77001366,  1.52765691],\n",
              "       [-1.20185231, -1.55451145],\n",
              "       [ 0.27704717,  0.15441358],\n",
              "       [-0.01873273,  1.37507432],\n",
              "       [-1.10325901,  0.5206118 ],\n",
              "       [ 1.55876005,  1.25300825],\n",
              "       [-0.90607242,  0.49009529],\n",
              "       [ 1.85453995,  1.6802395 ],\n",
              "       [ 0.07986057,  1.19197521],\n",
              "       [-0.11732603,  0.24596314],\n",
              "       [ 0.17845387, -0.30333419],\n",
              "       [ 2.15031985,  0.49009529],\n",
              "       [ 2.05172655,  0.64267788],\n",
              "       [-0.11732603, -0.36436723],\n",
              "       [-1.30044561,  0.61216136],\n",
              "       [ 0.67142036,  0.36802921],\n",
              "       [-0.31451262, -1.27986278],\n",
              "       [-1.59622551, -0.12023508],\n",
              "       [-0.31451262, -0.88314804],\n",
              "       [ 0.07986057, -0.18126812],\n",
              "       [ 0.77001366,  0.21544662],\n",
              "       [ 0.77001366, -0.79159849],\n",
              "       [-1.49763221, -1.43244537],\n",
              "       [ 0.86860696, -0.60849938],\n",
              "       [-0.11732603,  0.12389706],\n",
              "       [-1.00466571,  1.71075602],\n",
              "       [-1.10325901,  0.64267788],\n",
              "       [-0.31451262,  0.91732654],\n",
              "       [ 0.86860696, -1.34089582],\n",
              "       [ 0.37564047, -0.39488375],\n",
              "       [-1.00466571, -0.70004893],\n",
              "       [-1.00466571, -0.36436723],\n",
              "       [ 1.65735335,  1.92437165],\n",
              "       [ 0.77001366, -1.34089582],\n",
              "       [ 0.17845387,  0.24596314],\n",
              "       [-1.20185231, -1.58502797],\n",
              "       [-0.31451262, -0.85263152],\n",
              "       [-0.01873273, -0.18126812],\n",
              "       [-0.80747912,  2.07695424],\n",
              "       [-0.70888582, -1.00521412],\n",
              "       [-0.01873273, -0.51694982],\n",
              "       [ 0.77001366,  0.45957877],\n",
              "       [ 0.86860696,  2.35160291],\n",
              "       [ 0.96720026, -1.15779671],\n",
              "       [-0.31451262, -0.60849938],\n",
              "       [ 1.95313325, -0.60849938],\n",
              "       [-0.90607242, -0.18126812],\n",
              "       [-1.39903891, -1.34089582],\n",
              "       [-0.21591932, -0.45591678],\n",
              "       [-1.79341211,  0.58164484],\n",
              "       [-0.61029252,  0.58164484],\n",
              "       [-1.49763221, -0.57798286],\n",
              "       [-0.31451262,  0.30699618],\n",
              "       [-0.01873273,  0.12389706],\n",
              "       [-0.80747912, -0.54746634],\n",
              "       [ 0.96720026,  2.26005335],\n",
              "       [ 0.96720026,  0.88681002],\n",
              "       [ 1.16438686,  0.64267788],\n",
              "       [-0.31451262,  0.73422743],\n",
              "       [-1.8920054 , -1.40192885],\n",
              "       [-1.79341211, -0.94418108],\n",
              "       [-0.61029252,  2.07695424],\n",
              "       [ 1.36157346, -0.88314804],\n",
              "       [ 1.06579356,  0.6731944 ],\n",
              "       [ 1.06579356, -0.05920205],\n",
              "       [ 0.37564047, -0.08971856],\n",
              "       [-1.00466571,  0.6731944 ],\n",
              "       [-1.49763221, -1.18831323],\n",
              "       [ 0.27704717, -0.24230116],\n",
              "       [ 0.57282707, -0.85263152],\n",
              "       [ 0.77001366, -1.18831323],\n",
              "       [-0.31451262, -0.05920205],\n",
              "       [ 0.37564047, -0.05920205]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Variabes to calculate sigmoid function\n",
        "y_pred = []\n",
        "len_x = len(X_train[0])\n",
        "w = []\n",
        "b = 0.2\n",
        "print(len_x)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCs8csAESMVQ",
        "outputId": "9dc7f8c5-7bc0-45fa-d039-0d3b810703e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entries = len(X_train[:,0])\n",
        "   \n",
        "\n",
        "entries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EtcReRBSRlV",
        "outputId": "86ae8324-4501-4438-9945-69dcea1928a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for weights in range(len_x):\n",
        "  w.append(0)\n",
        "     \n",
        "w\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_82zDqhFSRHX",
        "outputId": "ac6c64ba-ef09-4dec-fdb9-58927f8b04d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return (1/(1+np.exp(-z)))\n",
        "\n",
        "     \n",
        "\n",
        "def predict(inputs):\n",
        "  z=np.dot(inputs,w)+b\n",
        "  h=sigmoid(z)\n",
        "  for i in range((len(h))):\n",
        "    if(h[i]>=0.5):\n",
        "      h[i]=1\n",
        "    else:\n",
        "      h[i]=0\n",
        "  return h\n",
        "  "
      ],
      "metadata": {
        "id": "-eqpTda5SazN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize.minpack import shape\n",
        "def loss_func(y,y1):\n",
        "  total_loss=np.sum(-y*np.log(y1)-(1-y)*np.log(1-y1))\n",
        "  m=y.shape[0]\n",
        "  j=total_loss/m\n",
        "  return j\n",
        "     \n",
        "\n",
        "dw = []\n",
        "db = 0\n",
        "J = 0\n",
        "alpha = 0.1\n",
        "for x in range(len_x):\n",
        "  dw.append(0)\n",
        "     \n",
        "\n",
        "l1=[]\n",
        "for i in range(3000):\n",
        "    z = np.dot(X_train, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "    l = loss_func(y_train, y_pred)\n",
        "    l1.append(l)\n",
        "    dw = np.dot((y_pred-y_train).T, X_train)/X_train.shape[0]\n",
        "    db = np.mean(y_pred-y_train)\n",
        "    w = w - alpha * dw\n",
        "    b = b - alpha* db\n",
        "    print(\"Round:\",i,\"Weight:\",w,\"Bias:\",b,\"loss:\",l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxw6eJ5JSdXw",
        "outputId": "e5199a20-0d38-4a59-828c-ca14c34cae8e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-db82e2489b52>:1: DeprecationWarning: Please use `shape` from the `scipy.optimize` namespace, the `scipy.optimize.minpack` namespace is deprecated.\n",
            "  from scipy.optimize.minpack import shape\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round: 0 Weight: [0.0301796  0.01779168] Bias: 0.18134993360208554 loss: 0.7254722027149253\n",
            "Round: 1 Weight: [0.05955298 0.03504366] Bias: 0.16316346315314978 loss: 0.7099332185396486\n",
            "Round: 2 Weight: [0.08814111 0.05177184] Bias: 0.14543230294646636 loss: 0.6952233582412951\n",
            "Round: 3 Weight: [0.11596589 0.0679927 ] Bias: 0.12814732425128014 loss: 0.6812994160210768\n",
            "Round: 4 Weight: [0.1430499  0.08372307] Bias: 0.11129870344493895 loss: 0.6681189932181743\n",
            "Round: 5 Weight: [0.16941612 0.09897999] Bias: 0.09487606289318515 loss: 0.6556407945368076\n",
            "Round: 6 Weight: [0.19508778 0.11378057] Bias: 0.07886860219629804 loss: 0.6438248636801185\n",
            "Round: 7 Weight: [0.22008809 0.1281418 ] Bias: 0.06326521820709705 loss: 0.6326327627071493\n",
            "Round: 8 Weight: [0.24444017 0.14208051] Bias: 0.048054612920874214 loss: 0.6220277006223041\n",
            "Round: 9 Weight: [0.26816681 0.15561322] Bias: 0.0332253889175976 loss: 0.611974617358524\n",
            "Round: 10 Weight: [0.29129047 0.16875608] Bias: 0.01876613249774943 loss: 0.6024402295247768\n",
            "Round: 11 Weight: [0.31383308 0.18152484] Bias: 0.004665484999745888 loss: 0.5933930441596483\n",
            "Round: 12 Weight: [0.33581604 0.19393475] Bias: -0.009087796969510469 loss: 0.5848033463644527\n",
            "Round: 13 Weight: [0.35726014 0.20600057] Bias: -0.02250479150374416 loss: 0.57664316616754\n",
            "Round: 14 Weight: [0.37818551 0.21773651] Bias: -0.035596370594967355 loss: 0.568886229366798\n",
            "Round: 15 Weight: [0.3986116  0.22915625] Bias: -0.0483731675606215 loss: 0.561507896464019\n",
            "Round: 16 Weight: [0.41855717 0.24027292] Bias: -0.06084555171487377 loss: 0.5544850931820039\n",
            "Round: 17 Weight: [0.43804027 0.25109911] Bias: -0.07302360934189539 loss: 0.5477962354693703\n",
            "Round: 18 Weight: [0.45707823 0.26164683] Bias: -0.08491713009141956 loss: 0.5414211513648899\n",
            "Round: 19 Weight: [0.4756877  0.27192758] Bias: -0.09653559799067632 loss: 0.5353410016207859\n",
            "Round: 20 Weight: [0.49388465 0.28195233] Bias: -0.10788818634584751 loss: 0.5295382005749406\n",
            "Round: 21 Weight: [0.51168433 0.29173155] Bias: -0.11898375588602184 loss: 0.5239963384136774\n",
            "Round: 22 Weight: [0.52910138 0.30127519] Bias: -0.12983085558014393 loss: 0.5187001056754891\n",
            "Round: 23 Weight: [0.54614977 0.31059277] Bias: -0.14043772563059384 loss: 0.5136352206061825\n",
            "Round: 24 Weight: [0.56284288 0.31969331] Bias: -0.15081230221456993 loss: 0.5087883597812654\n",
            "Round: 25 Weight: [0.57919349 0.32858541] Bias: -0.16096222360575685 loss: 0.504147092255762\n",
            "Round: 26 Weight: [0.59521378 0.33727726] Bias: -0.17089483736365285 loss: 0.4996998173791038\n",
            "Round: 27 Weight: [0.61091543 0.34577666] Bias: -0.18061720832652367 loss: 0.4954357063178615\n",
            "Round: 28 Weight: [0.62630956 0.354091  ] Bias: -0.1901361271865546 loss: 0.4913446472570225\n",
            "Round: 29 Weight: [0.64140681 0.36222734] Bias: -0.1994581194628213 loss: 0.487417194197065\n",
            "Round: 30 Weight: [0.65621734 0.37019237] Bias: -0.20858945471968784 loss: 0.4836445192256114\n",
            "Round: 31 Weight: [0.67075085 0.37799249] Bias: -0.21753615590568104 loss: 0.48001836811592624\n",
            "Round: 32 Weight: [0.68501661 0.38563377] Bias: -0.2263040087112972 loss: 0.4765310190874117\n",
            "Round: 33 Weight: [0.69902348 0.39312198] Bias: -0.23489857086405588 loss: 0.4731752445534521\n",
            "Round: 34 Weight: [0.71277992 0.40046264] Bias: -0.24332518129587885 loss: 0.46994427567777186\n",
            "Round: 35 Weight: [0.72629402 0.40766099] Bias: -0.2515889691319546 loss: 0.46683176956049804\n",
            "Round: 36 Weight: [0.73957352 0.41472202] Bias: -0.2596948624620227 loss: 0.46383177887828747\n",
            "Round: 37 Weight: [0.75262582 0.42165049] Bias: -0.267647596864806 loss: 0.4609387238082626\n",
            "Round: 38 Weight: [0.76545801 0.42845095] Bias: -0.2754517236644243 loss: 0.4581473660724645\n",
            "Round: 39 Weight: [0.77807685 0.43512773] Bias: -0.28311161790429634 loss: 0.45545278494748703\n",
            "Round: 40 Weight: [0.79048885 0.44168495] Bias: -0.29063148602949396 loss: 0.45285035509252064\n",
            "Round: 41 Weight: [0.8027002  0.44812657] Bias: -0.2980153732729477 loss: 0.45033572605788064\n",
            "Round: 42 Weight: [0.81471687 0.45445633] Bias: -0.3052671707444775 loss: 0.44790480334498095\n",
            "Round: 43 Weight: [0.82654457 0.46067785] Bias: -0.31239062222447644 loss: 0.4455537308974785\n",
            "Round: 44 Weight: [0.83818875 0.46679456] Bias: -0.3193893306663272 loss: 0.4432788749118187\n",
            "Round: 45 Weight: [0.84965468 0.47280975] Bias: -0.32626676441338465 loss: 0.4410768088635816\n",
            "Round: 46 Weight: [0.86094738 0.47872656] Bias: -0.3330262631376938 loss: 0.4389442996537969\n",
            "Round: 47 Weight: [0.87207169 0.48454799] Bias: -0.33967104350860877 loss: 0.4368782947867403\n",
            "Round: 48 Weight: [0.88303226 0.49027693] Bias: -0.3462042046001916 loss: 0.434875910497615\n",
            "Round: 49 Weight: [0.89383353 0.49591613] Bias: -0.3526287330467529 loss: 0.43293442075496547\n",
            "Round: 50 Weight: [0.9044798  0.50146824] Bias: -0.35894750795619457 loss: 0.4310512470686741\n",
            "Round: 51 Weight: [0.91497518 0.50693578] Bias: -0.3651633055909565 loss: 0.4292239490399499\n",
            "Round: 52 Weight: [0.92532364 0.51232119] Bias: -0.3712788038263969 loss: 0.4274502155948818\n",
            "Round: 53 Weight: [0.93552899 0.51762679] Bias: -0.37729658639636 loss: 0.4257278568478747\n",
            "Round: 54 Weight: [0.94559489 0.52285482] Bias: -0.38321914693553927 loss: 0.42405479654568345\n",
            "Round: 55 Weight: [0.95552488 0.52800742] Bias: -0.38904889282803595 loss: 0.42242906504678385\n",
            "Round: 56 Weight: [0.96532237 0.53308665] Bias: -0.39478814887126334 loss: 0.42084879279453996\n",
            "Round: 57 Weight: [0.97499063 0.53809451] Bias: -0.40043916076406266 loss: 0.41931220424602333\n",
            "Round: 58 Weight: [0.98453282 0.54303288] Bias: -0.4060040984275911 loss: 0.4178176122214721\n",
            "Round: 59 Weight: [0.99395199 0.54790359] Bias: -0.41148505916721945 loss: 0.4163634126422356\n",
            "Round: 60 Weight: [1.00325108 0.55270842] Bias: -0.41688407068334704 loss: 0.4149480796276822\n",
            "Round: 61 Weight: [1.01243293 0.55744905] Bias: -0.42220309393870636 loss: 0.41357016092394566\n",
            "Round: 62 Weight: [1.02150027 0.56212712] Bias: -0.42744402588939495 loss: 0.4122282736395935\n",
            "Round: 63 Weight: [1.03045576 0.5667442 ] Bias: -0.43260870208654084 loss: 0.41092110026531176\n",
            "Round: 64 Weight: [1.03930195 0.57130179] Bias: -0.4376988991551821 loss: 0.40964738495655045\n",
            "Round: 65 Weight: [1.0480413  0.57580137] Bias: -0.4427163371566231 loss: 0.4084059300597617\n",
            "Round: 66 Weight: [1.05667621 0.58024433] Bias: -0.44766268184022084 loss: 0.4071955928644106\n",
            "Round: 67 Weight: [1.06520897 0.58463203] Bias: -0.45253954679025604 loss: 0.40601528256435515\n",
            "Round: 68 Weight: [1.07364184 0.58896579] Bias: -0.4573484954732567 loss: 0.4048639574134896\n",
            "Round: 69 Weight: [1.08197695 0.59324687] Bias: -0.46209104319086314 loss: 0.4037406220617338\n",
            "Round: 70 Weight: [1.09021642 0.59747648] Bias: -0.4667686589430617 loss: 0.4026443250585416\n",
            "Round: 71 Weight: [1.09836225 0.60165581] Bias: -0.4713827672063576 loss: 0.4015741565120968\n",
            "Round: 72 Weight: [1.10641642 0.60578599] Bias: -0.47593474963121907 loss: 0.40052924589328315\n",
            "Round: 73 Weight: [1.11438082 0.60986813] Bias: -0.4804259466628926 loss: 0.3995087599743516\n",
            "Round: 74 Weight: [1.1222573  0.61390329] Bias: -0.48485765908947126 loss: 0.39851190089298183\n",
            "Round: 75 Weight: [1.13004764 0.6178925 ] Bias: -0.48923114952089014 loss: 0.39753790433313746\n",
            "Round: 76 Weight: [1.13775357 0.62183675] Bias: -0.4935476438023259 loss: 0.39658603781476626\n",
            "Round: 77 Weight: [1.14537677 0.62573702] Bias: -0.49780833236529004 loss: 0.3956555990849923\n",
            "Round: 78 Weight: [1.15291887 0.62959422] Bias: -0.5020143715195291 loss: 0.39474591460399494\n",
            "Round: 79 Weight: [1.16038146 0.63340927] Bias: -0.5061668846886769 loss: 0.39385633811927195\n",
            "Round: 80 Weight: [1.16776606 0.63718304] Bias: -0.5102669635924457 loss: 0.39298624932245085\n",
            "Round: 81 Weight: [1.17507418 0.64091638] Bias: -0.5143156693779939 loss: 0.3921350525832341\n",
            "Round: 82 Weight: [1.18230725 0.64461012] Bias: -0.5183140337029639 loss: 0.39130217575546217\n",
            "Round: 83 Weight: [1.18946669 0.64826504] Bias: -0.522263059772554 loss: 0.3904870690506348\n",
            "Round: 84 Weight: [1.19655386 0.65188192] Bias: -0.5261637233328574 loss: 0.3896892039745682\n",
            "Round: 85 Weight: [1.20357009 0.65546151] Bias: -0.530016973622585 loss: 0.38890807232317154\n",
            "Round: 86 Weight: [1.21051669 0.65900454] Bias: -0.5338237342851754 loss: 0.3881431852336096\n",
            "Round: 87 Weight: [1.21739489 0.66251172] Bias: -0.5375849042431873 loss: 0.3873940722873809\n",
            "Round: 88 Weight: [1.22420594 0.66598373] Bias: -0.5413013585367725 loss: 0.3866602806620826\n",
            "Round: 89 Weight: [1.23095101 0.66942123] Bias: -0.5449739491279296 loss: 0.3859413743288557\n",
            "Round: 90 Weight: [1.23763127 0.67282488] Bias: -0.5486035056721499 loss: 0.38523693329271114\n",
            "Round: 91 Weight: [1.24424785 0.6761953 ] Bias: -0.5521908362589851 loss: 0.38454655287312955\n",
            "Round: 92 Weight: [1.25080184 0.67953311] Bias: -0.5557367281229825 loss: 0.3838698430225019\n",
            "Round: 93 Weight: [1.25729431 0.68283889] Bias: -0.559241948326361 loss: 0.38320642768014396\n",
            "Round: 94 Weight: [1.26372632 0.68611323] Bias: -0.56270724441473 loss: 0.38255594415976757\n",
            "Round: 95 Weight: [1.27009887 0.68935668] Bias: -0.5661333450470842 loss: 0.3819180425684332\n",
            "Round: 96 Weight: [1.27641295 0.6925698 ] Bias: -0.5695209606012474 loss: 0.38129238525513764\n",
            "Round: 97 Weight: [1.28266953 0.69575311] Bias: -0.5728707837558739 loss: 0.3806786462873134\n",
            "Round: 98 Weight: [1.28886955 0.69890713] Bias: -0.5761834900500651 loss: 0.3800765109536243\n",
            "Round: 99 Weight: [1.29501393 0.70203237] Bias: -0.5794597384216009 loss: 0.3794856752915519\n",
            "Round: 100 Weight: [1.30110357 0.70512932] Bias: -0.5827001717247373 loss: 0.37890584563835905\n",
            "Round: 101 Weight: [1.30713934 0.70819845] Bias: -0.5859054172284733 loss: 0.3783367382041083\n",
            "Round: 102 Weight: [1.31312209 0.71124023] Bias: -0.5890760870961467 loss: 0.37777807866549856\n",
            "Round: 103 Weight: [1.31905265 0.71425511] Bias: -0.5922127788471722 loss: 0.3772296017793579\n",
            "Round: 104 Weight: [1.32493184 0.71724355] Bias: -0.5953160758016994 loss: 0.376691051014706\n",
            "Round: 105 Weight: [1.33076045 0.72020596] Bias: -0.5983865475089272 loss: 0.37616217820236336\n",
            "Round: 106 Weight: [1.33653926 0.72314276] Bias: -0.6014247501597748 loss: 0.37564274320115204\n",
            "Round: 107 Weight: [1.34226902 0.72605438] Bias: -0.6044312269845795 loss: 0.3751325135797875\n",
            "Round: 108 Weight: [1.34795047 0.7289412 ] Bias: -0.6074065086364527 loss: 0.3746312643136166\n",
            "Round: 109 Weight: [1.35358434 0.73180362] Bias: -0.6103511135609013 loss: 0.37413877749540875\n",
            "Round: 110 Weight: [1.35917133 0.73464202] Bias: -0.6132655483522887 loss: 0.3736548420594547\n",
            "Round: 111 Weight: [1.36471214 0.73745677] Bias: -0.6161503080976841 loss: 0.3731792535182699\n",
            "Round: 112 Weight: [1.37020743 0.74024823] Bias: -0.6190058767086217 loss: 0.37271181371124423\n",
            "Round: 113 Weight: [1.37565787 0.74301675] Bias: -0.6218327272412681 loss: 0.37225233056461493\n",
            "Round: 114 Weight: [1.38106411 0.74576269] Bias: -0.6246313222054719 loss: 0.37180061786217905\n",
            "Round: 115 Weight: [1.38642677 0.74848639] Bias: -0.6274021138631476 loss: 0.3713564950261943\n",
            "Round: 116 Weight: [1.39174648 0.75118816] Bias: -0.6301455445164251 loss: 0.370919786907948\n",
            "Round: 117 Weight: [1.39702384 0.75386833] Bias: -0.6328620467859771 loss: 0.37049032358750605\n",
            "Round: 118 Weight: [1.40225944 0.75652722] Bias: -0.6355520438799152 loss: 0.37006794018217787\n",
            "Round: 119 Weight: [1.40745386 0.75916514] Bias: -0.6382159498536306 loss: 0.3696524766632659\n",
            "Round: 120 Weight: [1.41260767 0.76178239] Bias: -0.6408541698609379 loss: 0.369243777680683\n",
            "Round: 121 Weight: [1.41772142 0.76437926] Bias: -0.6434671003968607 loss: 0.36884169239505454\n",
            "Round: 122 Weight: [1.42279566 0.76695603] Bias: -0.646055129532389 loss: 0.3684460743169352\n",
            "Round: 123 Weight: [1.42783093 0.769513  ] Bias: -0.6486186371415164 loss: 0.36805678115279633\n",
            "Round: 124 Weight: [1.43282773 0.77205044] Bias: -0.6511579951208583 loss: 0.3676736746574547\n",
            "Round: 125 Weight: [1.43778659 0.77456862] Bias: -0.6536735676021334 loss: 0.36729662049263356\n",
            "Round: 126 Weight: [1.44270801 0.77706779] Bias: -0.6561657111577817 loss: 0.3669254880913646\n",
            "Round: 127 Weight: [1.44759247 0.77954823] Bias: -0.6586347749999797 loss: 0.36656015052795027\n",
            "Round: 128 Weight: [1.45244046 0.78201018] Bias: -0.6610811011733012 loss: 0.3662004843932283\n",
            "Round: 129 Weight: [1.45725246 0.78445389] Bias: -0.6635050247412625 loss: 0.36584636967488654\n",
            "Round: 130 Weight: [1.46202891 0.7868796 ] Bias: -0.6659068739669796 loss: 0.36549768964259505\n",
            "Round: 131 Weight: [1.46677028 0.78928755] Bias: -0.6682869704881562 loss: 0.3651543307377312\n",
            "Round: 132 Weight: [1.47147701 0.79167797] Bias: -0.670645629486612 loss: 0.36481618246748765\n",
            "Round: 133 Weight: [1.47614954 0.7940511 ] Bias: -0.6729831598525496 loss: 0.3644831373031615\n",
            "Round: 134 Weight: [1.48078829 0.79640715] Bias: -0.6752998643437548 loss: 0.36415509058243567\n",
            "Round: 135 Weight: [1.48539369 0.79874634] Bias: -0.677596039739911 loss: 0.36383194041547195\n",
            "Round: 136 Weight: [1.48996615 0.80106889] Bias: -0.6798719769922067 loss: 0.36351358759464414\n",
            "Round: 137 Weight: [1.49450607 0.803375  ] Bias: -0.6821279613684028 loss: 0.36319993550774965\n",
            "Round: 138 Weight: [1.49901385 0.80566489] Bias: -0.6843642725935228 loss: 0.36289089005454417\n",
            "Round: 139 Weight: [1.50348987 0.80793876] Bias: -0.686581184986321 loss: 0.36258635956645396\n",
            "Round: 140 Weight: [1.50793453 0.8101968 ] Bias: -0.6887789675916771 loss: 0.36228625472932635\n",
            "Round: 141 Weight: [1.51234819 0.81243921] Bias: -0.6909578843090614 loss: 0.36199048850908483\n",
            "Round: 142 Weight: [1.51673123 0.81466618] Bias: -0.6931181940172064 loss: 0.36169897608016444\n",
            "Round: 143 Weight: [1.52108401 0.81687789] Bias: -0.695260150695118 loss: 0.36141163475660726\n",
            "Round: 144 Weight: [1.52540688 0.81907453] Bias: -0.697384003539551 loss: 0.36112838392570296\n",
            "Round: 145 Weight: [1.52970019 0.82125629] Bias: -0.6994899970790713 loss: 0.36084914498406817\n",
            "Round: 146 Weight: [1.53396428 0.82342333] Bias: -0.7015783712848227 loss: 0.3605738412760596\n",
            "Round: 147 Weight: [1.5381995  0.82557583] Bias: -0.7036493616781073 loss: 0.36030239803442315\n",
            "Round: 148 Weight: [1.54240617 0.82771396] Bias: -0.7057031994348901 loss: 0.3600347423230866\n",
            "Round: 149 Weight: [1.54658462 0.82983789] Bias: -0.7077401114873301 loss: 0.3597708029820044\n",
            "Round: 150 Weight: [1.55073517 0.83194778] Bias: -0.709760320622437 loss: 0.35951051057397226\n",
            "Round: 151 Weight: [1.55485813 0.83404379] Bias: -0.7117640455779503 loss: 0.3592537973333283\n",
            "Round: 152 Weight: [1.55895381 0.83612609] Bias: -0.7137515011355315 loss: 0.3590005971164644\n",
            "Round: 153 Weight: [1.56302252 0.83819482] Bias: -0.7157228982113598 loss: 0.35875084535407564\n",
            "Round: 154 Weight: [1.56706456 0.84025014] Bias: -0.7176784439442135 loss: 0.3585044790050733\n",
            "Round: 155 Weight: [1.57108021 0.8422922 ] Bias: -0.719618341781123 loss: 0.3582614365121\n",
            "Round: 156 Weight: [1.57506977 0.84432115] Bias: -0.7215427915606705 loss: 0.3580216577585779\n",
            "Round: 157 Weight: [1.57903352 0.84633714] Bias: -0.7234519895940145 loss: 0.35778508402723236\n",
            "Round: 158 Weight: [1.58297175 0.8483403 ] Bias: -0.7253461287437122 loss: 0.3575516579600305\n",
            "Round: 159 Weight: [1.58688472 0.85033077] Bias: -0.7272253985004091 loss: 0.3573213235194802\n",
            "Round: 160 Weight: [1.5907727 0.8523087] Bias: -0.7290899850574648 loss: 0.3570940259512358\n",
            "Round: 161 Weight: [1.59463597 0.85427421] Bias: -0.7309400713835792 loss: 0.35686971174795906\n",
            "Round: 162 Weight: [1.59847479 0.85622745] Bias: -0.7327758372934834 loss: 0.3566483286143883\n",
            "Round: 163 Weight: [1.6022894  0.85816854] Bias: -0.7345974595167548 loss: 0.3564298254335671\n",
            "Round: 164 Weight: [1.60608007 0.86009761] Bias: -0.7364051117648159 loss: 0.35621415223418945\n",
            "Round: 165 Weight: [1.60984705 0.86201479] Bias: -0.7381989647961723 loss: 0.3560012601590186\n",
            "Round: 166 Weight: [1.61359058 0.8639202 ] Bias: -0.7399791864799445 loss: 0.3557911014343384\n",
            "Round: 167 Weight: [1.6173109  0.86581396] Bias: -0.741745941857747 loss: 0.3555836293403987\n",
            "Round: 168 Weight: [1.62100825 0.86769621] Bias: -0.7434993932039637 loss: 0.355378798182817\n",
            "Round: 169 Weight: [1.62468286 0.86956704] Bias: -0.7452397000844697 loss: 0.35517656326490044\n",
            "Round: 170 Weight: [1.62833498 0.87142659] Bias: -0.7469670194138454 loss: 0.3549768808608551\n",
            "Round: 171 Weight: [1.63196481 0.87327496] Bias: -0.74868150551113 loss: 0.35477970818984855\n",
            "Round: 172 Weight: [1.63557259 0.87511227] Bias: -0.7503833101541567 loss: 0.35458500339089444\n",
            "Round: 173 Weight: [1.63915854 0.87693863] Bias: -0.752072582632513 loss: 0.35439272549852946\n",
            "Round: 174 Weight: [1.64272288 0.87875414] Bias: -0.7537494697991661 loss: 0.3542028344192537\n",
            "Round: 175 Weight: [1.64626581 0.88055893] Bias: -0.7554141161207945 loss: 0.3540152909087067\n",
            "Round: 176 Weight: [1.64978755 0.88235309] Bias: -0.7570666637268616 loss: 0.3538300565495523\n",
            "Round: 177 Weight: [1.65328831 0.88413673] Bias: -0.758707252457471 loss: 0.35364709373004716\n",
            "Round: 178 Weight: [1.65676829 0.88590995] Bias: -0.7603360199100361 loss: 0.3534663656232689\n",
            "Round: 179 Weight: [1.66022769 0.88767285] Bias: -0.7619531014848014 loss: 0.3532878361669796\n",
            "Round: 180 Weight: [1.66366672 0.88942553] Bias: -0.7635586304292468 loss: 0.353111470044103\n",
            "Round: 181 Weight: [1.66708556 0.89116809] Bias: -0.7651527378814066 loss: 0.3529372326637926\n",
            "Round: 182 Weight: [1.67048441 0.89290063] Bias: -0.7667355529121376 loss: 0.3527650901430722\n",
            "Round: 183 Weight: [1.67386347 0.89462325] Bias: -0.7683072025663622 loss: 0.3525950092890261\n",
            "Round: 184 Weight: [1.67722291 0.89633603] Bias: -0.7698678119033183 loss: 0.35242695758152204\n",
            "Round: 185 Weight: [1.68056292 0.89803907] Bias: -0.7714175040358433 loss: 0.3522609031564474\n",
            "Round: 186 Weight: [1.68388369 0.89973246] Bias: -0.7729564001687192 loss: 0.3520968147894421\n",
            "Round: 187 Weight: [1.68718539 0.9014163 ] Bias: -0.7744846196361064 loss: 0.35193466188010886\n",
            "Round: 188 Weight: [1.69046821 0.90309066] Bias: -0.7760022799380889 loss: 0.3517744144366884\n",
            "Round: 189 Weight: [1.69373231 0.90475564] Bias: -0.7775094967763594 loss: 0.35161604306117966\n",
            "Round: 190 Weight: [1.69697787 0.90641132] Bias: -0.779006384089065 loss: 0.3514595189348931\n",
            "Round: 191 Weight: [1.70020506 0.9080578 ] Bias: -0.7804930540848376 loss: 0.35130481380442075\n",
            "Round: 192 Weight: [1.70341405 0.90969514] Bias: -0.7819696172760329 loss: 0.3511518999680108\n",
            "Round: 193 Weight: [1.70660499 0.91132344] Bias: -0.7834361825111966 loss: 0.3510007502623308\n",
            "Round: 194 Weight: [1.70977807 0.91294278] Bias: -0.7848928570067821 loss: 0.3508513380496094\n",
            "Round: 195 Weight: [1.71293342 0.91455323] Bias: -0.7863397463781375 loss: 0.35070363720514164\n",
            "Round: 196 Weight: [1.71607122 0.91615488] Bias: -0.7877769546697831 loss: 0.35055762210514824\n",
            "Round: 197 Weight: [1.71919163 0.9177478 ] Bias: -0.7892045843849979 loss: 0.35041326761497504\n",
            "Round: 198 Weight: [1.72229478 0.91933207] Bias: -0.7906227365147334 loss: 0.3502705490776231\n",
            "Round: 199 Weight: [1.72538085 0.92090777] Bias: -0.7920315105658735 loss: 0.3501294423025984\n",
            "Round: 200 Weight: [1.72844997 0.92247498] Bias: -0.7934310045888571 loss: 0.3499899235550703\n",
            "Round: 201 Weight: [1.7315023  0.92403376] Bias: -0.7948213152046798 loss: 0.3498519695453296\n",
            "Round: 202 Weight: [1.73453798 0.92558419] Bias: -0.7962025376312931 loss: 0.3497155574185365\n",
            "Round: 203 Weight: [1.73755716 0.92712634] Bias: -0.7975747657094141 loss: 0.34958066474474786\n",
            "Round: 204 Weight: [1.74055998 0.92866028] Bias: -0.7989380919277634 loss: 0.3494472695092182\n",
            "Round: 205 Weight: [1.74354658 0.93018608] Bias: -0.8002926074477453 loss: 0.3493153501029614\n",
            "Round: 206 Weight: [1.7465171  0.93170382] Bias: -0.8016384021275841 loss: 0.34918488531356917\n",
            "Round: 207 Weight: [1.74947168 0.93321356] Bias: -0.8029755645459311 loss: 0.349055854316275\n",
            "Round: 208 Weight: [1.75241045 0.93471536] Bias: -0.8043041820249571 loss: 0.348928236665258\n",
            "Round: 209 Weight: [1.75533354 0.9362093 ] Bias: -0.8056243406529408 loss: 0.3488020122851781\n",
            "Round: 210 Weight: [1.7582411  0.93769544] Bias: -0.8069361253063686 loss: 0.3486771614629365\n",
            "Round: 211 Weight: [1.76113325 0.93917384] Bias: -0.808239619671557 loss: 0.34855366483965283\n",
            "Round: 212 Weight: [1.76401011 0.94064457] Bias: -0.8095349062658098 loss: 0.34843150340285445\n",
            "Round: 213 Weight: [1.76687182 0.94210769] Bias: -0.8108220664581218 loss: 0.3483106584788693\n",
            "Round: 214 Weight: [1.7697185  0.94356327] Bias: -0.8121011804894408 loss: 0.34819111172541817\n",
            "Round: 215 Weight: [1.77255028 0.94501136] Bias: -0.8133723274924982 loss: 0.3480728451243987\n",
            "Round: 216 Weight: [1.77536727 0.94645203] Bias: -0.8146355855112201 loss: 0.34795584097485666\n",
            "Round: 217 Weight: [1.77816961 0.94788534] Bias: -0.8158910315197276 loss: 0.34784008188613713\n",
            "Round: 218 Weight: [1.7809574  0.94931134] Bias: -0.817138741440939 loss: 0.3477255507712132\n",
            "Round: 219 Weight: [1.78373077 0.9507301 ] Bias: -0.8183787901647803 loss: 0.3476122308401832\n",
            "Round: 220 Weight: [1.78648984 0.95214168] Bias: -0.8196112515660173 loss: 0.34750010559393446\n",
            "Round: 221 Weight: [1.78923471 0.95354612] Bias: -0.8208361985217155 loss: 0.34738915881796756\n",
            "Round: 222 Weight: [1.79196551 0.95494349] Bias: -0.822053702928339 loss: 0.34727937457637575\n",
            "Round: 223 Weight: [1.79468234 0.95633384] Bias: -0.8232638357184956 loss: 0.34717073720597647\n",
            "Round: 224 Weight: [1.79738532 0.95771723] Bias: -0.8244666668773378 loss: 0.34706323131058897\n",
            "Round: 225 Weight: [1.80007455 0.95909371] Bias: -0.8256622654586278 loss: 0.3469568417554552\n",
            "Round: 226 Weight: [1.80275016 0.96046334] Bias: -0.8268506996004732 loss: 0.34685155366179904\n",
            "Round: 227 Weight: [1.80541223 0.96182617] Bias: -0.8280320365407441 loss: 0.34674735240151944\n",
            "Round: 228 Weight: [1.80806089 0.96318225] Bias: -0.829206342632176 loss: 0.3466442235920153\n",
            "Round: 229 Weight: [1.81069623 0.96453163] Bias: -0.8303736833571679 loss: 0.3465421530911362\n",
            "Round: 230 Weight: [1.81331836 0.96587437] Bias: -0.831534123342283 loss: 0.34644112699225743\n",
            "Round: 231 Weight: [1.81592738 0.96721052] Bias: -0.8326877263724576 loss: 0.34634113161947433\n",
            "Round: 232 Weight: [1.81852339 0.96854012] Bias: -0.833834555404926 loss: 0.34624215352291315\n",
            "Round: 233 Weight: [1.82110649 0.96986323] Bias: -0.8349746725828682 loss: 0.3461441794741549\n",
            "Round: 234 Weight: [1.82367679 0.9711799 ] Bias: -0.8361081392487862 loss: 0.3460471964617702\n",
            "Round: 235 Weight: [1.82623437 0.97249016] Bias: -0.837235015957616 loss: 0.34595119168695965\n",
            "Round: 236 Weight: [1.82877934 0.97379408] Bias: -0.83835536248958 loss: 0.34585615255929963\n",
            "Round: 237 Weight: [1.8313118 0.9750917] Bias: -0.8394692378627883 loss: 0.34576206669258835\n",
            "Round: 238 Weight: [1.83383183 0.97638307] Bias: -0.8405767003455917 loss: 0.34566892190079024\n",
            "Round: 239 Weight: [1.83633952 0.97766823] Bias: -0.8416778074686945 loss: 0.34557670619407654\n",
            "Round: 240 Weight: [1.83883499 0.97894722] Bias: -0.8427726160370309 loss: 0.3454854077749586\n",
            "Round: 241 Weight: [1.8413183 0.9802201] Bias: -0.8438611821414119 loss: 0.3453950150345117\n",
            "Round: 242 Weight: [1.84378956 0.98148691] Bias: -0.8449435611699463 loss: 0.34530551654868674\n",
            "Round: 243 Weight: [1.84624886 0.98274769] Bias: -0.8460198078192422 loss: 0.3452169010747081\n",
            "Round: 244 Weight: [1.84869628 0.98400249] Bias: -0.8470899761053937 loss: 0.3451291575475545\n",
            "Round: 245 Weight: [1.85113191 0.98525135] Bias: -0.8481541193747564 loss: 0.34504227507652097\n",
            "Round: 246 Weight: [1.85355583 0.98649431] Bias: -0.8492122903145186 loss: 0.34495624294185995\n",
            "Round: 247 Weight: [1.85596814 0.98773141] Bias: -0.8502645409630708 loss: 0.3448710505914994\n",
            "Round: 248 Weight: [1.85836892 0.9889627 ] Bias: -0.851310922720179 loss: 0.3447866876378351\n",
            "Round: 249 Weight: [1.86075825 0.99018822] Bias: -0.8523514863569661 loss: 0.344703143854597\n",
            "Round: 250 Weight: [1.86313621 0.99140802] Bias: -0.8533862820257047 loss: 0.3446204091737846\n",
            "Round: 251 Weight: [1.86550289 0.99262212] Bias: -0.8544153592694269 loss: 0.344538473682674\n",
            "Round: 252 Weight: [1.86785837 0.99383057] Bias: -0.8554387670313546 loss: 0.3444573276208895\n",
            "Round: 253 Weight: [1.87020273 0.99503341] Bias: -0.856456553664153 loss: 0.3443769613775427\n",
            "Round: 254 Weight: [1.87253604 0.99623068] Bias: -0.857468766939013 loss: 0.3442973654884348\n",
            "Round: 255 Weight: [1.87485839 0.99742242] Bias: -0.8584754540545654 loss: 0.3442185306333208\n",
            "Round: 256 Weight: [1.87716986 0.99860867] Bias: -0.85947666164563 loss: 0.34414044763323426\n",
            "Round: 257 Weight: [1.87947051 0.99978947] Bias: -0.8604724357918039 loss: 0.3440631074478718\n",
            "Round: 258 Weight: [1.88176044 1.00096484] Bias: -0.8614628220258925 loss: 0.3439865011730342\n",
            "Round: 259 Weight: [1.88403971 1.00213484] Bias: -0.8624478653421864 loss: 0.3439106200381244\n",
            "Round: 260 Weight: [1.88630839 1.00329949] Bias: -0.8634276102045867 loss: 0.3438354554036991\n",
            "Round: 261 Weight: [1.88856657 1.00445884] Bias: -0.8644021005545831 loss: 0.3437609987590749\n",
            "Round: 262 Weight: [1.89081431 1.00561292] Bias: -0.8653713798190881 loss: 0.343687241719985\n",
            "Round: 263 Weight: [1.89305169 1.00676176] Bias: -0.8663354909181282 loss: 0.3436141760262875\n",
            "Round: 264 Weight: [1.89527878 1.00790541] Bias: -0.8672944762723983 loss: 0.34354179353972275\n",
            "Round: 265 Weight: [1.89749565 1.00904389] Bias: -0.8682483778106792 loss: 0.34347008624171815\n",
            "Round: 266 Weight: [1.89970237 1.01017725] Bias: -0.8691972369771231 loss: 0.34339904623124123\n",
            "Round: 267 Weight: [1.90189901 1.01130551] Bias: -0.8701410947384091 loss: 0.34332866572269705\n",
            "Round: 268 Weight: [1.90408564 1.01242871] Bias: -0.8710799915907707 loss: 0.34325893704387106\n",
            "Round: 269 Weight: [1.90626233 1.01354688] Bias: -0.8720139675668999 loss: 0.34318985263391527\n",
            "Round: 270 Weight: [1.90842914 1.01466006] Bias: -0.8729430622427283 loss: 0.34312140504137706\n",
            "Round: 271 Weight: [1.91058614 1.01576828] Bias: -0.8738673147440895 loss: 0.3430535869222687\n",
            "Round: 272 Weight: [1.9127334  1.01687158] Bias: -0.8747867637532631 loss: 0.34298639103817813\n",
            "Round: 273 Weight: [1.91487098 1.01796998] Bias: -0.8757014475154057 loss: 0.34291981025441887\n",
            "Round: 274 Weight: [1.91699895 1.01906351] Bias: -0.8766114038448686 loss: 0.34285383753821835\n",
            "Round: 275 Weight: [1.91911737 1.02015222] Bias: -0.8775166701314054 loss: 0.3427884659569434\n",
            "Round: 276 Weight: [1.92122631 1.02123613] Bias: -0.8784172833462729 loss: 0.3427236886763634\n",
            "Round: 277 Weight: [1.92332582 1.02231527] Bias: -0.8793132800482247 loss: 0.34265949895894815\n",
            "Round: 278 Weight: [1.92541598 1.02338967] Bias: -0.880204696389403 loss: 0.342595890162201\n",
            "Round: 279 Weight: [1.92749684 1.02445936] Bias: -0.881091568121128 loss: 0.3425328557370268\n",
            "Round: 280 Weight: [1.92956846 1.02552438] Bias: -0.8819739305995881 loss: 0.34247038922613154\n",
            "Round: 281 Weight: [1.93163091 1.02658476] Bias: -0.8828518187914333 loss: 0.3424084842624563\n",
            "Round: 282 Weight: [1.93368424 1.02764051] Bias: -0.8837252672792726 loss: 0.34234713456764143\n",
            "Round: 283 Weight: [1.93572852 1.02869168] Bias: -0.8845943102670781 loss: 0.3422863339505228\n",
            "Round: 284 Weight: [1.9377638 1.0297383] Bias: -0.8854589815854975 loss: 0.34222607630565743\n",
            "Round: 285 Weight: [1.93979014 1.03078038] Bias: -0.8863193146970767 loss: 0.3421663556118792\n",
            "Round: 286 Weight: [1.9418076  1.03181796] Bias: -0.8871753427013942 loss: 0.34210716593088364\n",
            "Round: 287 Weight: [1.94381624 1.03285107] Bias: -0.8880270983401096 loss: 0.34204850140584\n",
            "Round: 288 Weight: [1.9458161  1.03387974] Bias: -0.8888746140019271 loss: 0.3419903562600322\n",
            "Round: 289 Weight: [1.94780726 1.03490399] Bias: -0.889717921727476 loss: 0.34193272479552517\n",
            "Round: 290 Weight: [1.94978977 1.03592386] Bias: -0.8905570532141098 loss: 0.3418756013918589\n",
            "Round: 291 Weight: [1.95176367 1.03693936] Bias: -0.8913920398206261 loss: 0.34181898050476706\n",
            "Round: 292 Weight: [1.95372903 1.03795053] Bias: -0.8922229125719074 loss: 0.3417628566649216\n",
            "Round: 293 Weight: [1.95568589 1.03895739] Bias: -0.893049702163486 loss: 0.3417072244767016\n",
            "Round: 294 Weight: [1.95763432 1.03995997] Bias: -0.8938724389660329 loss: 0.34165207861698527\n",
            "Round: 295 Weight: [1.95957436 1.0409583 ] Bias: -0.8946911530297733 loss: 0.3415974138339672\n",
            "Round: 296 Weight: [1.96150607 1.0419524 ] Bias: -0.8955058740888302 loss: 0.3415432249459967\n",
            "Round: 297 Weight: [1.96342951 1.0429423 ] Bias: -0.8963166315654957 loss: 0.34148950684043944\n",
            "Round: 298 Weight: [1.96534471 1.04392802] Bias: -0.8971234545744341 loss: 0.3414362544725612\n",
            "Round: 299 Weight: [1.96725174 1.04490959] Bias: -0.8979263719268159 loss: 0.34138346286443244\n",
            "Round: 300 Weight: [1.96915064 1.04588704] Bias: -0.8987254121343847 loss: 0.341331127103854\n",
            "Round: 301 Weight: [1.97104146 1.04686038] Bias: -0.8995206034134589 loss: 0.3412792423433033\n",
            "Round: 302 Weight: [1.97292426 1.04782965] Bias: -0.9003119736888682 loss: 0.3412278037989012\n",
            "Round: 303 Weight: [1.97479908 1.04879487] Bias: -0.9010995505978274 loss: 0.34117680674939677\n",
            "Round: 304 Weight: [1.97666598 1.04975606] Bias: -0.9018833614937479 loss: 0.3411262465351732\n",
            "Round: 305 Weight: [1.978525   1.05071325] Bias: -0.902663433449988 loss: 0.3410761185572712\n",
            "Round: 306 Weight: [1.98037618 1.05166646] Bias: -0.9034397932635437 loss: 0.3410264182764309\n",
            "Round: 307 Weight: [1.98221958 1.05261571] Bias: -0.9042124674586807 loss: 0.34097714121215206\n",
            "Round: 308 Weight: [1.98405525 1.05356103] Bias: -0.9049814822905083 loss: 0.3409282829417713\n",
            "Round: 309 Weight: [1.98588323 1.05450244] Bias: -0.9057468637484983 loss: 0.3408798390995572\n",
            "Round: 310 Weight: [1.98770356 1.05543997] Bias: -0.9065086375599462 loss: 0.34083180537582114\n",
            "Round: 311 Weight: [1.9895163  1.05637364] Bias: -0.9072668291933793 loss: 0.3407841775160458\n",
            "Round: 312 Weight: [1.99132149 1.05730346] Bias: -0.9080214638619117 loss: 0.3407369513200287\n",
            "Round: 313 Weight: [1.99311917 1.05822947] Bias: -0.9087725665265454 loss: 0.34069012264104204\n",
            "Round: 314 Weight: [1.9949094  1.05915168] Bias: -0.9095201618994208 loss: 0.3406436873850077\n",
            "Round: 315 Weight: [1.9966922  1.06007012] Bias: -0.9102642744470164 loss: 0.34059764150968763\n",
            "Round: 316 Weight: [1.99846763 1.06098481] Bias: -0.911004928393299 loss: 0.34055198102388845\n",
            "Round: 317 Weight: [2.00023574 1.06189577] Bias: -0.9117421477228247 loss: 0.3405067019866807\n",
            "Round: 318 Weight: [2.00199656 1.06280303] Bias: -0.9124759561837922 loss: 0.3404618005066331\n",
            "Round: 319 Weight: [2.00375014 1.06370659] Bias: -0.913206377291049 loss: 0.34041727274105865\n",
            "Round: 320 Weight: [2.00549652 1.0646065 ] Bias: -0.9139334343290518 loss: 0.34037311489527683\n",
            "Round: 321 Weight: [2.00723574 1.06550275] Bias: -0.9146571503547809 loss: 0.34032932322188664\n",
            "Round: 322 Weight: [2.00896784 1.06639539] Bias: -0.9153775482006102 loss: 0.34028589402005416\n",
            "Round: 323 Weight: [2.01069288 1.06728442] Bias: -0.9160946504771341 loss: 0.3402428236348127\n",
            "Round: 324 Weight: [2.01241088 1.06816987] Bias: -0.9168084795759501 loss: 0.3402001084563746\n",
            "Round: 325 Weight: [2.01412189 1.06905176] Bias: -0.9175190576724007 loss: 0.34015774491945616\n",
            "Round: 326 Weight: [2.01582594 1.06993011] Bias: -0.9182264067282726 loss: 0.3401157295026138\n",
            "Round: 327 Weight: [2.01752309 1.07080494] Bias: -0.9189305484944558 loss: 0.3400740587275925\n",
            "Round: 328 Weight: [2.01921336 1.07167626] Bias: -0.9196315045135622 loss: 0.34003272915868515\n",
            "Round: 329 Weight: [2.02089681 1.07254411] Bias: -0.9203292961225058 loss: 0.33999173740210376\n",
            "Round: 330 Weight: [2.02257346 1.07340849] Bias: -0.921023944455043 loss: 0.3399510801053611\n",
            "Round: 331 Weight: [2.02424336 1.07426943] Bias: -0.9217154704442759 loss: 0.3399107539566635\n",
            "Round: 332 Weight: [2.02590654 1.07512694] Bias: -0.9224038948251178 loss: 0.3398707556843139\n",
            "Round: 333 Weight: [2.02756305 1.07598105] Bias: -0.9230892381367222 loss: 0.339831082056126\n",
            "Round: 334 Weight: [2.02921291 1.07683178] Bias: -0.923771520724876 loss: 0.3397917298788469\n",
            "Round: 335 Weight: [2.03085618 1.07767914] Bias: -0.9244507627443569 loss: 0.3397526959975922\n",
            "Round: 336 Weight: [2.03249288 1.07852315] Bias: -0.9251269841612562 loss: 0.3397139772952881\n",
            "Round: 337 Weight: [2.03412306 1.07936383] Bias: -0.9258002047552674 loss: 0.3396755706921253\n",
            "Round: 338 Weight: [2.03574674 1.0802012 ] Bias: -0.9264704441219415 loss: 0.3396374731450206\n",
            "Round: 339 Weight: [2.03736397 1.08103528] Bias: -0.9271377216749085 loss: 0.33959968164708904\n",
            "Round: 340 Weight: [2.03897479 1.08186608] Bias: -0.9278020566480674 loss: 0.33956219322712405\n",
            "Round: 341 Weight: [2.04057922 1.08269362] Bias: -0.9284634680977436 loss: 0.3395250049490867\n",
            "Round: 342 Weight: [2.0421773  1.08351793] Bias: -0.9291219749048152 loss: 0.3394881139116039\n",
            "Round: 343 Weight: [2.04376908 1.08433901] Bias: -0.9297775957768082 loss: 0.33945151724747463\n",
            "Round: 344 Weight: [2.04535458 1.08515689] Bias: -0.9304303492499622 loss: 0.33941521212318465\n",
            "Round: 345 Weight: [2.04693384 1.08597158] Bias: -0.9310802536912649 loss: 0.3393791957384294\n",
            "Round: 346 Weight: [2.04850689 1.08678311] Bias: -0.9317273273004589 loss: 0.3393434653256451\n",
            "Round: 347 Weight: [2.05007377 1.08759148] Bias: -0.9323715881120185 loss: 0.3393080181495471\n",
            "Round: 348 Weight: [2.05163451 1.08839671] Bias: -0.9330130539970983 loss: 0.33927285150667624\n",
            "Round: 349 Weight: [2.05318914 1.08919883] Bias: -0.9336517426654549 loss: 0.3392379627249533\n",
            "Round: 350 Weight: [2.0547377  1.08999784] Bias: -0.93428767166734 loss: 0.33920334916323963\n",
            "Round: 351 Weight: [2.05628023 1.09079377] Bias: -0.9349208583953671 loss: 0.33916900821090595\n",
            "Round: 352 Weight: [2.05781675 1.09158663] Bias: -0.9355513200863522 loss: 0.339134937287408\n",
            "Round: 353 Weight: [2.05934729 1.09237643] Bias: -0.9361790738231276 loss: 0.3391011338418694\n",
            "Round: 354 Weight: [2.0608719 1.0931632] Bias: -0.9368041365363303 loss: 0.33906759535267045\n",
            "Round: 355 Weight: [2.0623906  1.09394695] Bias: -0.9374265250061657 loss: 0.33903431932704525\n",
            "Round: 356 Weight: [2.06390342 1.0947277 ] Bias: -0.9380462558641461 loss: 0.3390013033006836\n",
            "Round: 357 Weight: [2.06541039 1.09550545] Bias: -0.9386633455948048 loss: 0.33896854483734046\n",
            "Round: 358 Weight: [2.06691155 1.09628024] Bias: -0.9392778105373861 loss: 0.3389360415284518\n",
            "Round: 359 Weight: [2.06840693 1.09705206] Bias: -0.9398896668875125 loss: 0.3389037909927561\n",
            "Round: 360 Weight: [2.06989656 1.09782095] Bias: -0.9404989306988276 loss: 0.33887179087592206\n",
            "Round: 361 Weight: [2.07138047 1.09858691] Bias: -0.9411056178846171 loss: 0.33884003885018305\n",
            "Round: 362 Weight: [2.07285868 1.09934995] Bias: -0.9417097442194066 loss: 0.338808532613976\n",
            "Round: 363 Weight: [2.07433124 1.1001101 ] Bias: -0.9423113253405379 loss: 0.3387772698915878\n",
            "Round: 364 Weight: [2.07579817 1.10086737] Bias: -0.9429103767497232 loss: 0.3387462484328056\n",
            "Round: 365 Weight: [2.07725949 1.10162177] Bias: -0.9435069138145782 loss: 0.3387154660125742\n",
            "Round: 366 Weight: [2.07871524 1.10237333] Bias: -0.9441009517701338 loss: 0.3386849204306579\n",
            "Round: 367 Weight: [2.08016546 1.10312204] Bias: -0.9446925057203274 loss: 0.33865460951130805\n",
            "Round: 368 Weight: [2.08161016 1.10386793] Bias: -0.9452815906394736 loss: 0.33862453110293583\n",
            "Round: 369 Weight: [2.08304937 1.10461102] Bias: -0.9458682213737152 loss: 0.33859468307779045\n",
            "Round: 370 Weight: [2.08448313 1.10535131] Bias: -0.9464524126424539 loss: 0.3385650633316416\n",
            "Round: 371 Weight: [2.08591147 1.10608883] Bias: -0.9470341790397623 loss: 0.33853566978346794\n",
            "Round: 372 Weight: [2.0873344  1.10682358] Bias: -0.9476135350357758 loss: 0.33850650037514973\n",
            "Round: 373 Weight: [2.08875197 1.10755558] Bias: -0.9481904949780671 loss: 0.33847755307116656\n",
            "Round: 374 Weight: [2.09016419 1.10828484] Bias: -0.9487650730930006 loss: 0.3384488258582996\n",
            "Round: 375 Weight: [2.0915711  1.10901138] Bias: -0.9493372834870701 loss: 0.3384203167453386\n",
            "Round: 376 Weight: [2.09297272 1.10973521] Bias: -0.9499071401482172 loss: 0.3383920237627937\n",
            "Round: 377 Weight: [2.09436908 1.11045634] Bias: -0.9504746569471327 loss: 0.33836394496261085\n",
            "Round: 378 Weight: [2.09576021 1.1111748 ] Bias: -0.9510398476385413 loss: 0.33833607841789276\n",
            "Round: 379 Weight: [2.09714613 1.11189058] Bias: -0.9516027258624675 loss: 0.33830842222262303\n",
            "Round: 380 Weight: [2.09852688 1.11260372] Bias: -0.9521633051454864 loss: 0.3382809744913956\n",
            "Round: 381 Weight: [2.09990246 1.11331421] Bias: -0.9527215989019567 loss: 0.3382537333591473\n",
            "Round: 382 Weight: [2.10127293 1.11402207] Bias: -0.9532776204352382 loss: 0.33822669698089525\n",
            "Round: 383 Weight: [2.10263829 1.11472731] Bias: -0.9538313829388926 loss: 0.33819986353147746\n",
            "Round: 384 Weight: [2.10399857 1.11542996] Bias: -0.9543828994978686 loss: 0.33817323120529885\n",
            "Round: 385 Weight: [2.10535381 1.11613002] Bias: -0.9549321830896721 loss: 0.3381467982160793\n",
            "Round: 386 Weight: [2.10670403 1.1168275 ] Bias: -0.9554792465855201 loss: 0.33812056279660657\n",
            "Round: 387 Weight: [2.10804924 1.11752241] Bias: -0.9560241027514799 loss: 0.3380945231984929\n",
            "Round: 388 Weight: [2.10938948 1.11821478] Bias: -0.9565667642495934 loss: 0.33806867769193505\n",
            "Round: 389 Weight: [2.11072478 1.1189046 ] Bias: -0.9571072436389875 loss: 0.3380430245654778\n",
            "Round: 390 Weight: [2.11205515 1.11959191] Bias: -0.9576455533769681 loss: 0.3380175621257816\n",
            "Round: 391 Weight: [2.11338062 1.12027669] Bias: -0.9581817058201023 loss: 0.33799228869739284\n",
            "Round: 392 Weight: [2.11470122 1.12095898] Bias: -0.9587157132252848 loss: 0.3379672026225183\n",
            "Round: 393 Weight: [2.11601696 1.12163878] Bias: -0.9592475877507916 loss: 0.3379423022608025\n",
            "Round: 394 Weight: [2.11732789 1.1223161 ] Bias: -0.9597773414573192 loss: 0.3379175859891085\n",
            "Round: 395 Weight: [2.11863401 1.12299096] Bias: -0.9603049863090115 loss: 0.3378930522013019\n",
            "Round: 396 Weight: [2.11993535 1.12366336] Bias: -0.9608305341744727 loss: 0.33786869930803837\n",
            "Round: 397 Weight: [2.12123194 1.12433333] Bias: -0.9613539968277675 loss: 0.3378445257365536\n",
            "Round: 398 Weight: [2.12252379 1.12500086] Bias: -0.9618753859494082 loss: 0.33782052993045686\n",
            "Round: 399 Weight: [2.12381094 1.12566598] Bias: -0.9623947131273306 loss: 0.33779671034952763\n",
            "Round: 400 Weight: [2.12509341 1.1263287 ] Bias: -0.9629119898578553 loss: 0.3377730654695149\n",
            "Round: 401 Weight: [2.12637121 1.12698902] Bias: -0.9634272275466385 loss: 0.33774959378193964\n",
            "Round: 402 Weight: [2.12764437 1.12764695] Bias: -0.9639404375096099 loss: 0.3377262937938999\n",
            "Round: 403 Weight: [2.12891292 1.12830252] Bias: -0.9644516309738996 loss: 0.3377031640278792\n",
            "Round: 404 Weight: [2.13017688 1.12895573] Bias: -0.9649608190787522 loss: 0.33768020302155666\n",
            "Round: 405 Weight: [2.13143626 1.12960659] Bias: -0.96546801287643 loss: 0.33765740932762195\n",
            "Round: 406 Weight: [2.13269109 1.13025511] Bias: -0.9659732233331053 loss: 0.33763478151358994\n",
            "Round: 407 Weight: [2.1339414  1.13090131] Bias: -0.9664764613297406 loss: 0.3376123181616209\n",
            "Round: 408 Weight: [2.1351872  1.13154519] Bias: -0.9669777376629584 loss: 0.3375900178683415\n",
            "Round: 409 Weight: [2.13642852 1.13218677] Bias: -0.9674770630458999 loss: 0.33756787924466874\n",
            "Round: 410 Weight: [2.13766538 1.13282605] Bias: -0.9679744481090732 loss: 0.3375459009156371\n",
            "Round: 411 Weight: [2.1388978  1.13346306] Bias: -0.968469903401191 loss: 0.33752408152022706\n",
            "Round: 412 Weight: [2.1401258  1.13409779] Bias: -0.9689634393899974 loss: 0.3375024197111969\n",
            "Round: 413 Weight: [2.1413494  1.13473026] Bias: -0.9694550664630854 loss: 0.33748091415491654\n",
            "Round: 414 Weight: [2.14256862 1.13536049] Bias: -0.9699447949287033 loss: 0.337459563531204\n",
            "Round: 415 Weight: [2.14378349 1.13598847] Bias: -0.9704326350165519 loss: 0.3374383665331635\n",
            "Round: 416 Weight: [2.14499403 1.13661423] Bias: -0.9709185968785714 loss: 0.3374173218670266\n",
            "Round: 417 Weight: [2.14620025 1.13723776] Bias: -0.9714026905897193 loss: 0.33739642825199545\n",
            "Round: 418 Weight: [2.14740217 1.13785909] Bias: -0.9718849261487381 loss: 0.3373756844200878\n",
            "Round: 419 Weight: [2.14859983 1.13847822] Bias: -0.9723653134789141 loss: 0.3373550891159845\n",
            "Round: 420 Weight: [2.14979323 1.13909517] Bias: -0.9728438624288264 loss: 0.3373346410968792\n",
            "Round: 421 Weight: [2.15098239 1.13970994] Bias: -0.9733205827730874 loss: 0.33731433913232994\n",
            "Round: 422 Weight: [2.15216735 1.14032254] Bias: -0.9737954842130743 loss: 0.3372941820041131\n",
            "Round: 423 Weight: [2.15334811 1.14093298] Bias: -0.9742685763776509 loss: 0.3372741685060789\n",
            "Round: 424 Weight: [2.15452469 1.14154128] Bias: -0.9747398688238817 loss: 0.3372542974440092\n",
            "Round: 425 Weight: [2.15569713 1.14214743] Bias: -0.9752093710377373 loss: 0.3372345676354778\n",
            "Round: 426 Weight: [2.15686542 1.14275147] Bias: -0.9756770924347902 loss: 0.3372149779097112\n",
            "Round: 427 Weight: [2.15802961 1.14335338] Bias: -0.9761430423609034 loss: 0.3371955271074531\n",
            "Round: 428 Weight: [2.15918969 1.14395319] Bias: -0.9766072300929107 loss: 0.33717621408082893\n",
            "Round: 429 Weight: [2.1603457 1.1445509] Bias: -0.977069664839288 loss: 0.33715703769321426\n",
            "Round: 430 Weight: [2.16149765 1.14514652] Bias: -0.9775303557408175 loss: 0.3371379968191031\n",
            "Round: 431 Weight: [2.16264557 1.14574006] Bias: -0.9779893118712434 loss: 0.3371190903439789\n",
            "Round: 432 Weight: [2.16378946 1.14633153] Bias: -0.9784465422379202 loss: 0.33710031716418765\n",
            "Round: 433 Weight: [2.16492935 1.14692094] Bias: -0.9789020557824529 loss: 0.3370816761868118\n",
            "Round: 434 Weight: [2.16606526 1.14750831] Bias: -0.9793558613813304 loss: 0.3370631663295467\n",
            "Round: 435 Weight: [2.1671972  1.14809363] Bias: -0.9798079678465499 loss: 0.33704478652057807\n",
            "Round: 436 Weight: [2.16832519 1.14867692] Bias: -0.9802583839262361 loss: 0.3370265356984618\n",
            "Round: 437 Weight: [2.16944926 1.14925818] Bias: -0.980707118305251 loss: 0.33700841281200494\n",
            "Round: 438 Weight: [2.17056942 1.14983743] Bias: -0.981154179605798 loss: 0.33699041682014785\n",
            "Round: 439 Weight: [2.17168568 1.15041468] Bias: -0.981599576388018 loss: 0.33697254669184895\n",
            "Round: 440 Weight: [2.17279807 1.15098993] Bias: -0.9820433171505792 loss: 0.33695480140597067\n",
            "Round: 441 Weight: [2.1739066 1.1515632] Bias: -0.9824854103312599 loss: 0.336937179951166\n",
            "Round: 442 Weight: [2.17501129 1.15213449] Bias: -0.9829258643075239 loss: 0.3369196813257681\n",
            "Round: 443 Weight: [2.17611216 1.15270381] Bias: -0.9833646873970902 loss: 0.33690230453768\n",
            "Round: 444 Weight: [2.17720922 1.15327117] Bias: -0.9838018878584948 loss: 0.3368850486042669\n",
            "Round: 445 Weight: [2.1783025  1.15383657] Bias: -0.9842374738916476 loss: 0.3368679125522487\n",
            "Round: 446 Weight: [2.179392   1.15440004] Bias: -0.9846714536383817 loss: 0.3368508954175952\n",
            "Round: 447 Weight: [2.18047776 1.15496157] Bias: -0.9851038351829965 loss: 0.33683399624542176\n",
            "Round: 448 Weight: [2.18155977 1.15552118] Bias: -0.985534626552795 loss: 0.3368172140898867\n",
            "Round: 449 Weight: [2.18263807 1.15607887] Bias: -0.9859638357186146 loss: 0.33680054801408993\n",
            "Round: 450 Weight: [2.18371266 1.15663465] Bias: -0.9863914705953518 loss: 0.3367839970899734\n",
            "Round: 451 Weight: [2.18478357 1.15718853] Bias: -0.9868175390424813 loss: 0.3367675603982219\n",
            "Round: 452 Weight: [2.1858508  1.15774052] Bias: -0.9872420488645685 loss: 0.3367512370281659\n",
            "Round: 453 Weight: [2.18691438 1.15829063] Bias: -0.9876650078117766 loss: 0.33673502607768563\n",
            "Round: 454 Weight: [2.18797433 1.15883886] Bias: -0.9880864235803682 loss: 0.3367189266531161\n",
            "Round: 455 Weight: [2.18903065 1.15938523] Bias: -0.9885063038132008 loss: 0.33670293786915323\n",
            "Round: 456 Weight: [2.19008337 1.15992973] Bias: -0.9889246561002162 loss: 0.33668705884876204\n",
            "Round: 457 Weight: [2.1911325  1.16047239] Bias: -0.9893414879789255 loss: 0.3366712887230848\n",
            "Round: 458 Weight: [2.19217806 1.16101321] Bias: -0.9897568069348882 loss: 0.33665562663135146\n",
            "Round: 459 Weight: [2.19322006 1.16155219] Bias: -0.9901706204021854 loss: 0.3366400717207907\n",
            "Round: 460 Weight: [2.19425851 1.16208934] Bias: -0.990582935763888 loss: 0.3366246231465416\n",
            "Round: 461 Weight: [2.19529345 1.16262468] Bias: -0.9909937603525202 loss: 0.33660928007156843\n",
            "Round: 462 Weight: [2.19632487 1.16315821] Bias: -0.9914031014505169 loss: 0.33659404166657336\n",
            "Round: 463 Weight: [2.19735279 1.16368993] Bias: -0.9918109662906766 loss: 0.33657890710991384\n",
            "Round: 464 Weight: [2.19837724 1.16421986] Bias: -0.9922173620566089 loss: 0.3365638755875177\n",
            "Round: 465 Weight: [2.19939822 1.16474801] Bias: -0.9926222958831777 loss: 0.33654894629280213\n",
            "Round: 466 Weight: [2.20041576 1.16527437] Bias: -0.9930257748569384 loss: 0.3365341184265915\n",
            "Round: 467 Weight: [2.20142985 1.16579897] Bias: -0.993427806016571 loss: 0.3365193911970381\n",
            "Round: 468 Weight: [2.20244053 1.1663218 ] Bias: -0.9938283963533084 loss: 0.3365047638195422\n",
            "Round: 469 Weight: [2.20344781 1.16684287] Bias: -0.9942275528113598 loss: 0.3364902355166741\n",
            "Round: 470 Weight: [2.2044517 1.1673622] Bias: -0.9946252822883292 loss: 0.3364758055180972\n",
            "Round: 471 Weight: [2.20545221 1.16787978] Bias: -0.9950215916356301 loss: 0.3364614730604914\n",
            "Round: 472 Weight: [2.20644936 1.16839563] Bias: -0.9954164876588945 loss: 0.3364472373874781\n",
            "Round: 473 Weight: [2.20744316 1.16890976] Bias: -0.9958099771183783 loss: 0.33643309774954605\n",
            "Round: 474 Weight: [2.20843364 1.16942216] Bias: -0.996202066729362 loss: 0.3364190534039773\n",
            "Round: 475 Weight: [2.2094208  1.16993286] Bias: -0.9965927631625471 loss: 0.3364051036147755\n",
            "Round: 476 Weight: [2.21040465 1.17044185] Bias: -0.9969820730444481 loss: 0.33639124765259365\n",
            "Round: 477 Weight: [2.21138522 1.17094914] Bias: -0.99737000295778 loss: 0.3363774847946643\n",
            "Round: 478 Weight: [2.21236251 1.17145474] Bias: -0.9977565594418422 loss: 0.3363638143247285\n",
            "Round: 479 Weight: [2.21333654 1.17195866] Bias: -0.9981417489928976 loss: 0.33635023553296817\n",
            "Round: 480 Weight: [2.21430733 1.17246091] Bias: -0.9985255780645484 loss: 0.3363367477159373\n",
            "Round: 481 Weight: [2.21527488 1.17296149] Bias: -0.9989080530681066 loss: 0.3363233501764945\n",
            "Round: 482 Weight: [2.21623922 1.1734604 ] Bias: -0.9992891803729618 loss: 0.3363100422237373\n",
            "Round: 483 Weight: [2.21720035 1.17395767] Bias: -0.9996689663069444 loss: 0.3362968231729358\n",
            "Round: 484 Weight: [2.21815829 1.17445328] Bias: -1.0000474171566849 loss: 0.33628369234546884\n",
            "Round: 485 Weight: [2.21911305 1.17494726] Bias: -1.0004245391679698 loss: 0.33627064906875875\n",
            "Round: 486 Weight: [2.22006465 1.1754396 ] Bias: -1.000800338546093 loss: 0.3362576926762091\n",
            "Round: 487 Weight: [2.2210131  1.17593031] Bias: -1.0011748214562042 loss: 0.33624482250714194\n",
            "Round: 488 Weight: [2.22195841 1.17641941] Bias: -1.0015479940236525 loss: 0.3362320379067361\n",
            "Round: 489 Weight: [2.22290059 1.17690689] Bias: -1.001919862334328 loss: 0.3362193382259663\n",
            "Round: 490 Weight: [2.22383967 1.17739276] Bias: -1.0022904324349984 loss: 0.3362067228215428\n",
            "Round: 491 Weight: [2.22477565 1.17787704] Bias: -1.0026597103336425 loss: 0.33619419105585213\n",
            "Round: 492 Weight: [2.22570854 1.17835972] Bias: -1.0030277019997804 loss: 0.3361817422968983\n",
            "Round: 493 Weight: [2.22663836 1.17884082] Bias: -1.0033944133647994 loss: 0.33616937591824486\n",
            "Round: 494 Weight: [2.22756512 1.17932034] Bias: -1.0037598503222778 loss: 0.3361570912989571\n",
            "Round: 495 Weight: [2.22848884 1.17979828] Bias: -1.004124018728304 loss: 0.33614488782354607\n",
            "Round: 496 Weight: [2.22940952 1.18027466] Bias: -1.0044869244017933 loss: 0.3361327648819122\n",
            "Round: 497 Weight: [2.23032718 1.18074947] Bias: -1.0048485731248005 loss: 0.3361207218692899\n",
            "Round: 498 Weight: [2.23124184 1.18122274] Bias: -1.00520897064283 loss: 0.3361087581861931\n",
            "Round: 499 Weight: [2.23215349 1.18169445] Bias: -1.0055681226651423 loss: 0.3360968732383616\n",
            "Round: 500 Weight: [2.23306217 1.18216463] Bias: -1.0059260348650567 loss: 0.33608506643670705\n",
            "Round: 501 Weight: [2.23396787 1.18263327] Bias: -1.0062827128802523 loss: 0.3360733371972607\n",
            "Round: 502 Weight: [2.23487062 1.18310038] Bias: -1.0066381623130647 loss: 0.3360616849411211\n",
            "Round: 503 Weight: [2.23577042 1.18356597] Bias: -1.0069923887307801 loss: 0.33605010909440286\n",
            "Round: 504 Weight: [2.23666728 1.18403004] Bias: -1.0073453976659261 loss: 0.3360386090881856\n",
            "Round: 505 Weight: [2.23756123 1.18449261] Bias: -1.00769719461656 loss: 0.33602718435846385\n",
            "Round: 506 Weight: [2.23845226 1.18495367] Bias: -1.0080477850465532 loss: 0.33601583434609705\n",
            "Round: 507 Weight: [2.2393404  1.18541323] Bias: -1.0083971743858742 loss: 0.3360045584967608\n",
            "Round: 508 Weight: [2.24022565 1.1858713 ] Bias: -1.0087453680308667 loss: 0.3359933562608985\n",
            "Round: 509 Weight: [2.24110802 1.18632789] Bias: -1.009092371344527 loss: 0.3359822270936727\n",
            "Round: 510 Weight: [2.24198754 1.186783  ] Bias: -1.0094381896567768 loss: 0.3359711704549188\n",
            "Round: 511 Weight: [2.2428642  1.18723664] Bias: -1.009782828264734 loss: 0.33596018580909714\n",
            "Round: 512 Weight: [2.24373802 1.1876888 ] Bias: -1.0101262924329815 loss: 0.3359492726252474\n",
            "Round: 513 Weight: [2.24460902 1.18813951] Bias: -1.010468587393831 loss: 0.33593843037694265\n",
            "Round: 514 Weight: [2.2454772  1.18858876] Bias: -1.010809718347587 loss: 0.3359276585422442\n",
            "Round: 515 Weight: [2.24634258 1.18903656] Bias: -1.0111496904628057 loss: 0.3359169566036569\n",
            "Round: 516 Weight: [2.24720516 1.18948292] Bias: -1.0114885088765526 loss: 0.33590632404808485\n",
            "Round: 517 Weight: [2.24806496 1.18992784] Bias: -1.0118261786946579 loss: 0.335895760366788\n",
            "Round: 518 Weight: [2.24892199 1.19037133] Bias: -1.0121627049919673 loss: 0.3358852650553388\n",
            "Round: 519 Weight: [2.24977626 1.19081339] Bias: -1.0124980928125928 loss: 0.3358748376135796\n",
            "Round: 520 Weight: [2.25062779 1.19125404] Bias: -1.0128323471701592 loss: 0.33586447754558046\n",
            "Round: 521 Weight: [2.25147657 1.19169326] Bias: -1.013165473048049 loss: 0.3358541843595977\n",
            "Round: 522 Weight: [2.25232264 1.19213108] Bias: -1.0134974753996442 loss: 0.3358439575680322\n",
            "Round: 523 Weight: [2.25316598 1.1925675 ] Bias: -1.0138283591485666 loss: 0.33583379668738916\n",
            "Round: 524 Weight: [2.25400662 1.19300251] Bias: -1.0141581291889148 loss: 0.3358237012382379\n",
            "Round: 525 Weight: [2.25484457 1.19343614] Bias: -1.0144867903854995 loss: 0.3358136707451711\n",
            "Round: 526 Weight: [2.25567984 1.19386838] Bias: -1.0148143475740758 loss: 0.3358037047367667\n",
            "Round: 527 Weight: [2.25651243 1.19429923] Bias: -1.0151408055615745 loss: 0.33579380274554854\n",
            "Round: 528 Weight: [2.25734237 1.19472871] Bias: -1.0154661691263291 loss: 0.33578396430794727\n",
            "Round: 529 Weight: [2.25816965 1.19515682] Bias: -1.0157904430183025 loss: 0.3357741889642634\n",
            "Round: 530 Weight: [2.2589943  1.19558357] Bias: -1.01611363195931 loss: 0.33576447625862876\n",
            "Round: 531 Weight: [2.25981631 1.19600895] Bias: -1.0164357406432416 loss: 0.3357548257389698\n",
            "Round: 532 Weight: [2.26063571 1.19643299] Bias: -1.0167567737362806 loss: 0.335745236956971\n",
            "Round: 533 Weight: [2.2614525  1.19685567] Bias: -1.017076735877121 loss: 0.33573570946803794\n",
            "Round: 534 Weight: [2.26226669 1.19727701] Bias: -1.0173956316771826 loss: 0.33572624283126185\n",
            "Round: 535 Weight: [2.26307829 1.19769701] Bias: -1.0177134657208238 loss: 0.33571683660938384\n",
            "Round: 536 Weight: [2.26388732 1.19811568] Bias: -1.0180302425655523 loss: 0.33570749036876\n",
            "Round: 537 Weight: [2.26469377 1.19853302] Bias: -1.0183459667422343 loss: 0.33569820367932635\n",
            "Round: 538 Weight: [2.26549767 1.19894903] Bias: -1.0186606427553013 loss: 0.3356889761145648\n",
            "Round: 539 Weight: [2.26629903 1.19936374] Bias: -1.0189742750829542 loss: 0.3356798072514688\n",
            "Round: 540 Weight: [2.26709785 1.19977712] Bias: -1.019286868177367 loss: 0.3356706966705101\n",
            "Round: 541 Weight: [2.26789414 1.20018921] Bias: -1.0195984264648867 loss: 0.33566164395560527\n",
            "Round: 542 Weight: [2.26868791 1.20059998] Bias: -1.0199089543462334 loss: 0.3356526486940833\n",
            "Round: 543 Weight: [2.26947917 1.20100947] Bias: -1.0202184561966963 loss: 0.33564371047665226\n",
            "Round: 544 Weight: [2.27026794 1.20141766] Bias: -1.0205269363663292 loss: 0.33563482889736784\n",
            "Round: 545 Weight: [2.27105422 1.20182456] Bias: -1.0208343991801436 loss: 0.3356260035536018\n",
            "Round: 546 Weight: [2.27183803 1.20223018] Bias: -1.0211408489383003 loss: 0.3356172340460097\n",
            "Round: 547 Weight: [2.27261936 1.20263453] Bias: -1.0214462899162988 loss: 0.33560851997850033\n",
            "Round: 548 Weight: [2.27339824 1.2030376 ] Bias: -1.0217507263651653 loss: 0.33559986095820504\n",
            "Round: 549 Weight: [2.27417466 1.20343941] Bias: -1.0220541625116384 loss: 0.3355912565954469\n",
            "Round: 550 Weight: [2.27494865 1.20383995] Bias: -1.0223566025583533 loss: 0.33558270650371147\n",
            "Round: 551 Weight: [2.27572021 1.20423924] Bias: -1.0226580506840246 loss: 0.3355742102996158\n",
            "Round: 552 Weight: [2.27648935 1.20463728] Bias: -1.0229585110436268 loss: 0.33556576760288037\n",
            "Round: 553 Weight: [2.27725607 1.20503406] Bias: -1.0232579877685732 loss: 0.3355573780362987\n",
            "Round: 554 Weight: [2.2780204  1.20542961] Bias: -1.0235564849668939 loss: 0.3355490412257097\n",
            "Round: 555 Weight: [2.27878233 1.20582391] Bias: -1.0238540067234103 loss: 0.3355407567999684\n",
            "Round: 556 Weight: [2.27954188 1.20621699] Bias: -1.0241505570999105 loss: 0.33553252439091824\n",
            "Round: 557 Weight: [2.28029905 1.20660883] Bias: -1.0244461401353206 loss: 0.33552434363336275\n",
            "Round: 558 Weight: [2.28105386 1.20699945] Bias: -1.0247407598458762 loss: 0.3355162141650386\n",
            "Round: 559 Weight: [2.28180631 1.20738886] Bias: -1.025034420225291 loss: 0.33550813562658777\n",
            "Round: 560 Weight: [2.28255642 1.20777704] Bias: -1.0253271252449252 loss: 0.335500107661531\n",
            "Round: 561 Weight: [2.28330419 1.20816402] Bias: -1.0256188788539506 loss: 0.33549212991624083\n",
            "Round: 562 Weight: [2.28404963 1.20854979] Bias: -1.0259096849795162 loss: 0.33548420203991536\n",
            "Round: 563 Weight: [2.28479275 1.20893437] Bias: -1.0261995475269097 loss: 0.33547632368455177\n",
            "Round: 564 Weight: [2.28553356 1.20931774] Bias: -1.0264884703797206 loss: 0.33546849450492144\n",
            "Round: 565 Weight: [2.28627206 1.20969993] Bias: -1.0267764573999993 loss: 0.33546071415854317\n",
            "Round: 566 Weight: [2.28700827 1.21008093] Bias: -1.0270635124284158 loss: 0.33545298230565873\n",
            "Round: 567 Weight: [2.2877422  1.21046074] Bias: -1.0273496392844161 loss: 0.3354452986092075\n",
            "Round: 568 Weight: [2.28847385 1.21083938] Bias: -1.0276348417663792 loss: 0.33543766273480186\n",
            "Round: 569 Weight: [2.28920324 1.21121684] Bias: -1.02791912365177 loss: 0.3354300743507025\n",
            "Round: 570 Weight: [2.28993036 1.21159314] Bias: -1.0282024886972925 loss: 0.3354225331277946\n",
            "Round: 571 Weight: [2.29065524 1.21196827] Bias: -1.0284849406390415 loss: 0.33541503873956335\n",
            "Round: 572 Weight: [2.29137787 1.21234224] Bias: -1.0287664831926522 loss: 0.3354075908620707\n",
            "Round: 573 Weight: [2.29209827 1.21271505] Bias: -1.0290471200534488 loss: 0.3354001891739314\n",
            "Round: 574 Weight: [2.29281645 1.21308671] Bias: -1.0293268548965917 loss: 0.33539283335629017\n",
            "Round: 575 Weight: [2.29353241 1.21345723] Bias: -1.0296056913772238 loss: 0.3353855230927987\n",
            "Round: 576 Weight: [2.29424616 1.2138266 ] Bias: -1.029883633130615 loss: 0.3353782580695926\n",
            "Round: 577 Weight: [2.29495771 1.21419484] Bias: -1.030160683772305 loss: 0.3353710379752692\n",
            "Round: 578 Weight: [2.29566707 1.21456194] Bias: -1.0304368468982459 loss: 0.3353638625008653\n",
            "Round: 579 Weight: [2.29637425 1.2149279 ] Bias: -1.0307121260849428 loss: 0.3353567313398348\n",
            "Round: 580 Weight: [2.29707925 1.21529275] Bias: -1.0309865248895929 loss: 0.3353496441880273\n",
            "Round: 581 Weight: [2.29778209 1.21565647] Bias: -1.031260046850224 loss: 0.3353426007436661\n",
            "Round: 582 Weight: [2.29848277 1.21601907] Bias: -1.0315326954858313 loss: 0.33533560070732754\n",
            "Round: 583 Weight: [2.29918129 1.21638056] Bias: -1.0318044742965136 loss: 0.33532864378191896\n",
            "Round: 584 Weight: [2.29987767 1.21674094] Bias: -1.032075386763607 loss: 0.33532172967265844\n",
            "Round: 585 Weight: [2.30057192 1.21710022] Bias: -1.0323454363498188 loss: 0.335314858087054\n",
            "Round: 586 Weight: [2.30126405 1.2174584 ] Bias: -1.0326146264993594 loss: 0.3353080287348829\n",
            "Round: 587 Weight: [2.30195405 1.21781547] Bias: -1.0328829606380736 loss: 0.33530124132817163\n",
            "Round: 588 Weight: [2.30264194 1.21817146] Bias: -1.0331504421735698 loss: 0.33529449558117563\n",
            "Round: 589 Weight: [2.30332773 1.21852636] Bias: -1.033417074495349 loss: 0.3352877912103595\n",
            "Round: 590 Weight: [2.30401142 1.21888017] Bias: -1.0336828609749324 loss: 0.3352811279343776\n",
            "Round: 591 Weight: [2.30469303 1.2192329 ] Bias: -1.0339478049659874 loss: 0.335274505474054\n",
            "Round: 592 Weight: [2.30537256 1.21958455] Bias: -1.0342119098044529 loss: 0.335267923552364\n",
            "Round: 593 Weight: [2.30605001 1.21993514] Bias: -1.0344751788086641 loss: 0.3352613818944144\n",
            "Round: 594 Weight: [2.3067254  1.22028465] Bias: -1.0347376152794747 loss: 0.33525488022742517\n",
            "Round: 595 Weight: [2.30739874 1.2206331 ] Bias: -1.0349992225003795 loss: 0.3352484182807103\n",
            "Round: 596 Weight: [2.30807002 1.22098048] Bias: -1.0352600037376347 loss: 0.3352419957856597\n",
            "Round: 597 Weight: [2.30873926 1.22132681] Bias: -1.0355199622403786 loss: 0.33523561247572076\n",
            "Round: 598 Weight: [2.30940647 1.22167209] Bias: -1.0357791012407493 loss: 0.3352292680863803\n",
            "Round: 599 Weight: [2.31007165 1.22201632] Bias: -1.0360374239540038 loss: 0.3352229623551465\n",
            "Round: 600 Weight: [2.31073482 1.2223595 ] Bias: -1.0362949335786336 loss: 0.3352166950215313\n",
            "Round: 601 Weight: [2.31139597 1.22270164] Bias: -1.0365516332964808 loss: 0.3352104658270329\n",
            "Round: 602 Weight: [2.31205512 1.22304274] Bias: -1.036807526272853 loss: 0.33520427451511836\n",
            "Round: 603 Weight: [2.31271227 1.2233828 ] Bias: -1.0370626156566374 loss: 0.3351981208312058\n",
            "Round: 604 Weight: [2.31336743 1.22372184] Bias: -1.0373169045804123 loss: 0.3351920045226487\n",
            "Round: 605 Weight: [2.3140206  1.22405985] Bias: -1.03757039616056 loss: 0.3351859253387175\n",
            "Round: 606 Weight: [2.3146718  1.22439684] Bias: -1.0378230934973773 loss: 0.33517988303058405\n",
            "Round: 607 Weight: [2.31532104 1.22473281] Bias: -1.0380749996751855 loss: 0.33517387735130455\n",
            "Round: 608 Weight: [2.31596831 1.22506776] Bias: -1.0383261177624388 loss: 0.3351679080558034\n",
            "Round: 609 Weight: [2.31661363 1.2254017 ] Bias: -1.0385764508118327 loss: 0.3351619749008565\n",
            "Round: 610 Weight: [2.317257   1.22573463] Bias: -1.0388260018604114 loss: 0.33515607764507604\n",
            "Round: 611 Weight: [2.31789844 1.22606656] Bias: -1.039074773929673 loss: 0.33515021604889406\n",
            "Round: 612 Weight: [2.31853794 1.22639749] Bias: -1.0393227700256755 loss: 0.335144389874547\n",
            "Round: 613 Weight: [2.31917551 1.22672742] Bias: -1.0395699931391411 loss: 0.33513859888605957\n",
            "Round: 614 Weight: [2.31981117 1.22705636] Bias: -1.0398164462455592 loss: 0.33513284284923034\n",
            "Round: 615 Weight: [2.32044491 1.2273843 ] Bias: -1.0400621323052894 loss: 0.33512712153161545\n",
            "Round: 616 Weight: [2.32107675 1.22771126] Bias: -1.040307054263663 loss: 0.3351214347025143\n",
            "Round: 617 Weight: [2.32170669 1.22803724] Bias: -1.0405512150510838 loss: 0.335115782132954\n",
            "Round: 618 Weight: [2.32233474 1.22836224] Bias: -1.0407946175831286 loss: 0.3351101635956751\n",
            "Round: 619 Weight: [2.32296091 1.22868626] Bias: -1.0410372647606456 loss: 0.33510457886511646\n",
            "Round: 620 Weight: [2.3235852  1.22900931] Bias: -1.0412791594698534 loss: 0.33509902771740097\n",
            "Round: 621 Weight: [2.32420761 1.22933139] Bias: -1.0415203045824377 loss: 0.335093509930321\n",
            "Round: 622 Weight: [2.32482817 1.2296525 ] Bias: -1.041760702955649 loss: 0.3350880252833246\n",
            "Round: 623 Weight: [2.32544686 1.22997266] Bias: -1.0420003574323975 loss: 0.3350825735575006\n",
            "Round: 624 Weight: [2.32606371 1.23029185] Bias: -1.0422392708413488 loss: 0.33507715453556586\n",
            "Round: 625 Weight: [2.32667871 1.23061009] Bias: -1.0424774459970179 loss: 0.33507176800184996\n",
            "Round: 626 Weight: [2.32729187 1.23092738] Bias: -1.0427148856998627 loss: 0.3350664137422828\n",
            "Round: 627 Weight: [2.32790321 1.23124372] Bias: -1.0429515927363768 loss: 0.3350610915443803\n",
            "Round: 628 Weight: [2.32851272 1.23155911] Bias: -1.0431875698791815 loss: 0.33505580119723133\n",
            "Round: 629 Weight: [2.32912041 1.23187356] Bias: -1.0434228198871165 loss: 0.3350505424914842\n",
            "Round: 630 Weight: [2.32972628 1.23218708] Bias: -1.043657345505331 loss: 0.3350453152193337\n",
            "Round: 631 Weight: [2.33033036 1.23249965] Bias: -1.043891149465373 loss: 0.33504011917450766\n",
            "Round: 632 Weight: [2.33093263 1.2328113 ] Bias: -1.0441242344852784 loss: 0.33503495415225465\n",
            "Round: 633 Weight: [2.33153312 1.23312202] Bias: -1.0443566032696585 loss: 0.3350298199493307\n",
            "Round: 634 Weight: [2.33213181 1.23343181] Bias: -1.0445882585097888 loss: 0.3350247163639871\n",
            "Round: 635 Weight: [2.33272873 1.23374069] Bias: -1.0448192028836945 loss: 0.33501964319595706\n",
            "Round: 636 Weight: [2.33332388 1.23404864] Bias: -1.0450494390562373 loss: 0.3350146002464442\n",
            "Round: 637 Weight: [2.33391725 1.23435568] Bias: -1.0452789696792004 loss: 0.3350095873181098\n",
            "Round: 638 Weight: [2.33450887 1.2346618 ] Bias: -1.0455077973913733 loss: 0.3350046042150605\n",
            "Round: 639 Weight: [2.33509873 1.23496702] Bias: -1.0457359248186355 loss: 0.33499965074283655\n",
            "Round: 640 Weight: [2.33568685 1.23527133] Bias: -1.0459633545740403 loss: 0.3349947267083996\n",
            "Round: 641 Weight: [2.33627322 1.23557474] Bias: -1.0461900892578966 loss: 0.3349898319201212\n",
            "Round: 642 Weight: [2.33685785 1.23587725] Bias: -1.0464161314578517 loss: 0.3349849661877705\n",
            "Round: 643 Weight: [2.33744076 1.23617887] Bias: -1.046641483748972 loss: 0.3349801293225033\n",
            "Round: 644 Weight: [2.33802194 1.23647959] Bias: -1.0468661486938233 loss: 0.3349753211368501\n",
            "Round: 645 Weight: [2.3386014  1.23677942] Bias: -1.0470901288425518 loss: 0.3349705414447048\n",
            "Round: 646 Weight: [2.33917916 1.23707836] Bias: -1.0473134267329625 loss: 0.33496579006131344\n",
            "Round: 647 Weight: [2.3397552  1.23737642] Bias: -1.047536044890598 loss: 0.33496106680326315\n",
            "Round: 648 Weight: [2.34032955 1.2376736 ] Bias: -1.0477579858288166 loss: 0.334956371488471\n",
            "Round: 649 Weight: [2.3409022 1.2379699] Bias: -1.0479792520488704 loss: 0.33495170393617285\n",
            "Round: 650 Weight: [2.34147316 1.23826533] Bias: -1.0481998460399808 loss: 0.3349470639669128\n",
            "Round: 651 Weight: [2.34204245 1.23855989] Bias: -1.0484197702794156 loss: 0.3349424514025319\n",
            "Round: 652 Weight: [2.34261005 1.23885358] Bias: -1.048639027232564 loss: 0.33493786606615844\n",
            "Round: 653 Weight: [2.34317599 1.2391464 ] Bias: -1.0488576193530126 loss: 0.33493330778219643\n",
            "Round: 654 Weight: [2.34374026 1.23943836] Bias: -1.049075549082618 loss: 0.33492877637631535\n",
            "Round: 655 Weight: [2.34430287 1.23972946] Bias: -1.0492928188515824 loss: 0.33492427167544037\n",
            "Round: 656 Weight: [2.34486383 1.2400197 ] Bias: -1.0495094310785256 loss: 0.3349197935077413\n",
            "Round: 657 Weight: [2.34542314 1.24030909] Bias: -1.0497253881705577 loss: 0.33491534170262316\n",
            "Round: 658 Weight: [2.34598081 1.24059764] Bias: -1.049940692523352 loss: 0.3349109160907153\n",
            "Round: 659 Weight: [2.34653684 1.24088533] Bias: -1.0501553465212157 loss: 0.3349065165038621\n",
            "Round: 660 Weight: [2.34709125 1.24117218] Bias: -1.0503693525371605 loss: 0.3349021427751129\n",
            "Round: 661 Weight: [2.34764403 1.24145818] Bias: -1.050582712932974 loss: 0.33489779473871173\n",
            "Round: 662 Weight: [2.34819519 1.24174335] Bias: -1.0507954300592883 loss: 0.3348934722300885\n",
            "Round: 663 Weight: [2.34874473 1.24202768] Bias: -1.0510075062556505 loss: 0.3348891750858486\n",
            "Round: 664 Weight: [2.34929267 1.24231118] Bias: -1.0512189438505901 loss: 0.3348849031437638\n",
            "Round: 665 Weight: [2.34983901 1.24259385] Bias: -1.0514297451616883 loss: 0.3348806562427625\n",
            "Round: 666 Weight: [2.35038375 1.24287569] Bias: -1.0516399124956446 loss: 0.33487643422292074\n",
            "Round: 667 Weight: [2.35092689 1.24315671] Bias: -1.051849448148345 loss: 0.33487223692545254\n",
            "Round: 668 Weight: [2.35146845 1.24343691] Bias: -1.0520583544049271 loss: 0.33486806419270115\n",
            "Round: 669 Weight: [2.35200844 1.24371628] Bias: -1.052266633539848 loss: 0.33486391586812975\n",
            "Round: 670 Weight: [2.35254684 1.24399484] Bias: -1.0524742878169484 loss: 0.33485979179631203\n",
            "Round: 671 Weight: [2.35308368 1.24427259] Bias: -1.0526813194895182 loss: 0.3348556918229241\n",
            "Round: 672 Weight: [2.35361895 1.24454953] Bias: -1.0528877308003608 loss: 0.33485161579473494\n",
            "Round: 673 Weight: [2.35415267 1.24482566] Bias: -1.0530935239818575 loss: 0.33484756355959805\n",
            "Round: 674 Weight: [2.35468483 1.24510098] Bias: -1.0532987012560309 loss: 0.33484353496644254\n",
            "Round: 675 Weight: [2.35521544 1.2453755 ] Bias: -1.0535032648346074 loss: 0.3348395298652645\n",
            "Round: 676 Weight: [2.35574451 1.24564923] Bias: -1.0537072169190809 loss: 0.3348355481071186\n",
            "Round: 677 Weight: [2.35627204 1.24592215] Bias: -1.0539105597007739 loss: 0.33483158954410963\n",
            "Round: 678 Weight: [2.35679803 1.24619429] Bias: -1.0541132953608994 loss: 0.3348276540293842\n",
            "Round: 679 Weight: [2.35732251 1.24646563] Bias: -1.054315426070622 loss: 0.33482374141712223\n",
            "Round: 680 Weight: [2.35784545 1.24673618] Bias: -1.054516953991119 loss: 0.3348198515625287\n",
            "Round: 681 Weight: [2.35836689 1.24700595] Bias: -1.0547178812736402 loss: 0.3348159843218259\n",
            "Round: 682 Weight: [2.35888681 1.24727493] Bias: -1.0549182100595675 loss: 0.3348121395522448\n",
            "Round: 683 Weight: [2.35940522 1.24754313] Bias: -1.0551179424804746 loss: 0.33480831711201764\n",
            "Round: 684 Weight: [2.35992213 1.24781056] Bias: -1.0553170806581855 loss: 0.33480451686036955\n",
            "Round: 685 Weight: [2.36043755 1.24807721] Bias: -1.0555156267048331 loss: 0.33480073865751087\n",
            "Round: 686 Weight: [2.36095147 1.24834308] Bias: -1.0557135827229172 loss: 0.33479698236462935\n",
            "Round: 687 Weight: [2.36146391 1.24860819] Bias: -1.0559109508053617 loss: 0.3347932478438824\n",
            "Round: 688 Weight: [2.36197486 1.24887253] Bias: -1.0561077330355724 loss: 0.33478953495838937\n",
            "Round: 689 Weight: [2.36248434 1.2491361 ] Bias: -1.0563039314874927 loss: 0.33478584357222446\n",
            "Round: 690 Weight: [2.36299235 1.24939891] Bias: -1.0564995482256605 loss: 0.33478217355040824\n",
            "Round: 691 Weight: [2.36349889 1.24966097] Bias: -1.0566945853052638 loss: 0.3347785247589013\n",
            "Round: 692 Weight: [2.36400397 1.24992226] Bias: -1.0568890447721964 loss: 0.33477489706459607\n",
            "Round: 693 Weight: [2.3645076 1.2501828] Bias: -1.0570829286631118 loss: 0.3347712903353098\n",
            "Round: 694 Weight: [2.36500977 1.25044259] Bias: -1.057276239005479 loss: 0.3347677044397774\n",
            "Round: 695 Weight: [2.36551049 1.25070163] Bias: -1.0574689778176363 loss: 0.3347641392476442\n",
            "Round: 696 Weight: [2.36600978 1.25095992] Bias: -1.0576611471088446 loss: 0.3347605946294588\n",
            "Round: 697 Weight: [2.36650762 1.25121746] Bias: -1.0578527488793414 loss: 0.3347570704566659\n",
            "Round: 698 Weight: [2.36700404 1.25147427] Bias: -1.0580437851203934 loss: 0.33475356660159944\n",
            "Round: 699 Weight: [2.36749902 1.25173033] Bias: -1.0582342578143487 loss: 0.33475008293747605\n",
            "Round: 700 Weight: [2.36799258 1.25198566] Bias: -1.0584241689346898 loss: 0.3347466193383871\n",
            "Round: 701 Weight: [2.36848473 1.25224025] Bias: -1.0586135204460847 loss: 0.33474317567929307\n",
            "Round: 702 Weight: [2.36897546 1.25249411] Bias: -1.0588023143044387 loss: 0.33473975183601623\n",
            "Round: 703 Weight: [2.36946478 1.25274725] Bias: -1.0589905524569452 loss: 0.3347363476852341\n",
            "Round: 704 Weight: [2.3699527  1.25299965] Bias: -1.0591782368421363 loss: 0.3347329631044724\n",
            "Round: 705 Weight: [2.37043922 1.25325133] Bias: -1.0593653693899334 loss: 0.3347295979720993\n",
            "Round: 706 Weight: [2.37092435 1.25350228] Bias: -1.059551952021697 loss: 0.33472625216731816\n",
            "Round: 707 Weight: [2.37140808 1.25375252] Bias: -1.0597379866502759 loss: 0.33472292557016164\n",
            "Round: 708 Weight: [2.37189043 1.25400204] Bias: -1.0599234751800566 loss: 0.3347196180614847\n",
            "Round: 709 Weight: [2.3723714  1.25425084] Bias: -1.0601084195070123 loss: 0.3347163295229587\n",
            "Round: 710 Weight: [2.372851   1.25449893] Bias: -1.060292821518751 loss: 0.33471305983706495\n",
            "Round: 711 Weight: [2.37332922 1.25474631] Bias: -1.060476683094564 loss: 0.3347098088870887\n",
            "Round: 712 Weight: [2.37380607 1.25499298] Bias: -1.0606600061054734 loss: 0.3347065765571127\n",
            "Round: 713 Weight: [2.37428156 1.25523894] Bias: -1.0608427924142796 loss: 0.3347033627320111\n",
            "Round: 714 Weight: [2.3747557 1.2554842] Bias: -1.0610250438756084 loss: 0.33470016729744334\n",
            "Round: 715 Weight: [2.37522848 1.25572876] Bias: -1.0612067623359576 loss: 0.3346969901398485\n",
            "Round: 716 Weight: [2.37569991 1.25597263] Bias: -1.0613879496337433 loss: 0.33469383114643886\n",
            "Round: 717 Weight: [2.37616999 1.25621579] Bias: -1.0615686075993462 loss: 0.3346906902051941\n",
            "Round: 718 Weight: [2.37663874 1.25645826] Bias: -1.0617487380551576 loss: 0.334687567204856\n",
            "Round: 719 Weight: [2.37710615 1.25670004] Bias: -1.0619283428156239 loss: 0.3346844620349214\n",
            "Round: 720 Weight: [2.37757223 1.25694112] Bias: -1.0621074236872925 loss: 0.33468137458563785\n",
            "Round: 721 Weight: [2.37803698 1.25718152] Bias: -1.0622859824688564 loss: 0.3346783047479972\n",
            "Round: 722 Weight: [2.37850041 1.25742124] Bias: -1.062464020951198 loss: 0.3346752524137294\n",
            "Round: 723 Weight: [2.37896252 1.25766027] Bias: -1.062641540917434 loss: 0.3346722174752982\n",
            "Round: 724 Weight: [2.37942332 1.25789862] Bias: -1.0628185441429585 loss: 0.3346691998258944\n",
            "Round: 725 Weight: [2.3798828 1.2581363] Bias: -1.0629950323954875 loss: 0.3346661993594307\n",
            "Round: 726 Weight: [2.38034098 1.25837329] Bias: -1.0631710074351008 loss: 0.33466321597053666\n",
            "Round: 727 Weight: [2.38079786 1.25860961] Bias: -1.0633464710142857 loss: 0.33466024955455287\n",
            "Round: 728 Weight: [2.38125345 1.25884526] Bias: -1.0635214248779792 loss: 0.33465730000752525\n",
            "Round: 729 Weight: [2.38170774 1.25908024] Bias: -1.0636958707636104 loss: 0.3346543672262007\n",
            "Round: 730 Weight: [2.38216074 1.25931456] Bias: -1.0638698104011426 loss: 0.3346514511080205\n",
            "Round: 731 Weight: [2.38261246 1.25954821] Bias: -1.0640432455131146 loss: 0.3346485515511166\n",
            "Round: 732 Weight: [2.3830629  1.25978119] Bias: -1.0642161778146821 loss: 0.3346456684543048\n",
            "Round: 733 Weight: [2.38351206 1.26001351] Bias: -1.0643886090136594 loss: 0.33464280171708105\n",
            "Round: 734 Weight: [2.38395995 1.26024518] Bias: -1.0645605408105592 loss: 0.3346399512396153\n",
            "Round: 735 Weight: [2.38440657 1.26047619] Bias: -1.064731974898634 loss: 0.33463711692274717\n",
            "Round: 736 Weight: [2.38485193 1.26070654] Bias: -1.0649029129639154 loss: 0.3346342986679803\n",
            "Round: 737 Weight: [2.38529603 1.26093624] Bias: -1.065073356685255 loss: 0.3346314963774775\n",
            "Round: 738 Weight: [2.38573887 1.26116529] Bias: -1.0652433077343637 loss: 0.33462870995405664\n",
            "Round: 739 Weight: [2.38618047 1.26139369] Bias: -1.0654127677758505 loss: 0.3346259393011845\n",
            "Round: 740 Weight: [2.38662081 1.26162145] Bias: -1.0655817384672623 loss: 0.3346231843229727\n",
            "Round: 741 Weight: [2.38705991 1.26184856] Bias: -1.0657502214591226 loss: 0.33462044492417276\n",
            "Round: 742 Weight: [2.38749778 1.26207503] Bias: -1.0659182183949694 loss: 0.3346177210101713\n",
            "Round: 743 Weight: [2.38793441 1.26230086] Bias: -1.0660857309113947 loss: 0.3346150124869852\n",
            "Round: 744 Weight: [2.3883698  1.26252605] Bias: -1.0662527606380816 loss: 0.33461231926125673\n",
            "Round: 745 Weight: [2.38880397 1.26275061] Bias: -1.0664193091978424 loss: 0.33460964124024967\n",
            "Round: 746 Weight: [2.38923692 1.26297453] Bias: -1.0665853782066559 loss: 0.3346069783318437\n",
            "Round: 747 Weight: [2.38966865 1.26319782] Bias: -1.0667509692737047 loss: 0.33460433044453075\n",
            "Round: 748 Weight: [2.39009916 1.26342048] Bias: -1.0669160840014125 loss: 0.33460169748740964\n",
            "Round: 749 Weight: [2.39052846 1.26364252] Bias: -1.0670807239854803 loss: 0.33459907937018213\n",
            "Round: 750 Weight: [2.39095655 1.26386392] Bias: -1.0672448908149232 loss: 0.3345964760031483\n",
            "Round: 751 Weight: [2.39138344 1.26408471] Bias: -1.0674085860721068 loss: 0.33459388729720196\n",
            "Round: 752 Weight: [2.39180913 1.26430487] Bias: -1.0675718113327826 loss: 0.33459131316382673\n",
            "Round: 753 Weight: [2.39223363 1.26452441] Bias: -1.067734568166124 loss: 0.3345887535150911\n",
            "Round: 754 Weight: [2.39265693 1.26474334] Bias: -1.0678968581347628 loss: 0.33458620826364444\n",
            "Round: 755 Weight: [2.39307904 1.26496165] Bias: -1.0680586827948222 loss: 0.33458367732271277\n",
            "Round: 756 Weight: [2.39349997 1.26517935] Bias: -1.0682200436959537 loss: 0.33458116060609433\n",
            "Round: 757 Weight: [2.39391972 1.26539643] Bias: -1.0683809423813715 loss: 0.33457865802815556\n",
            "Round: 758 Weight: [2.39433829 1.26561291] Bias: -1.0685413803878865 loss: 0.3345761695038269\n",
            "Round: 759 Weight: [2.39475569 1.26582877] Bias: -1.068701359245941 loss: 0.33457369494859834\n",
            "Round: 760 Weight: [2.39517192 1.26604404] Bias: -1.0688608804796425 loss: 0.3345712342785157\n",
            "Round: 761 Weight: [2.39558698 1.26625869] Bias: -1.069019945606798 loss: 0.3345687874101765\n",
            "Round: 762 Weight: [2.39600088 1.26647275] Bias: -1.0691785561389469 loss: 0.33456635426072573\n",
            "Round: 763 Weight: [2.39641362 1.2666862 ] Bias: -1.0693367135813951 loss: 0.33456393474785207\n",
            "Round: 764 Weight: [2.39682521 1.26689906] Bias: -1.0694944194332479 loss: 0.3345615287897836\n",
            "Round: 765 Weight: [2.39723565 1.26711132] Bias: -1.0696516751874423 loss: 0.3345591363052845\n",
            "Round: 766 Weight: [2.39764494 1.26732299] Bias: -1.0698084823307807 loss: 0.33455675721365036\n",
            "Round: 767 Weight: [2.39805308 1.26753407] Bias: -1.0699648423439632 loss: 0.3345543914347047\n",
            "Round: 768 Weight: [2.39846009 1.26774455] Bias: -1.0701207567016189 loss: 0.3345520388887953\n",
            "Round: 769 Weight: [2.39886596 1.26795444] Bias: -1.0702762268723391 loss: 0.33454969949678975\n",
            "Round: 770 Weight: [2.3992707  1.26816375] Bias: -1.0704312543187087 loss: 0.3345473731800728\n",
            "Round: 771 Weight: [2.39967431 1.26837248] Bias: -1.0705858404973378 loss: 0.3345450598605415\n",
            "Round: 772 Weight: [2.40007679 1.26858062] Bias: -1.0707399868588932 loss: 0.33454275946060164\n",
            "Round: 773 Weight: [2.40047815 1.26878818] Bias: -1.0708936948481294 loss: 0.3345404719031649\n",
            "Round: 774 Weight: [2.40087839 1.26899516] Bias: -1.07104696590392 loss: 0.33453819711164434\n",
            "Round: 775 Weight: [2.40127752 1.26920156] Bias: -1.0711998014592878 loss: 0.3345359350099511\n",
            "Round: 776 Weight: [2.40167553 1.26940739] Bias: -1.0713522029414364 loss: 0.3345336855224906\n",
            "Round: 777 Weight: [2.40207244 1.26961264] Bias: -1.0715041717717797 loss: 0.33453144857415945\n",
            "Round: 778 Weight: [2.40246824 1.26981732] Bias: -1.0716557093659727 loss: 0.3345292240903413\n",
            "Round: 779 Weight: [2.40286295 1.27002143] Bias: -1.0718068171339408 loss: 0.33452701199690366\n",
            "Round: 780 Weight: [2.40325655 1.27022497] Bias: -1.0719574964799103 loss: 0.3345248122201946\n",
            "Round: 781 Weight: [2.40364906 1.27042795] Bias: -1.0721077488024378 loss: 0.3345226246870388\n",
            "Round: 782 Weight: [2.40404048 1.27063036] Bias: -1.072257575494439 loss: 0.33452044932473457\n",
            "Round: 783 Weight: [2.40443082 1.2708322 ] Bias: -1.072406977943219 loss: 0.3345182860610502\n",
            "Round: 784 Weight: [2.40482007 1.27103349] Bias: -1.0725559575305006 loss: 0.3345161348242207\n",
            "Round: 785 Weight: [2.40520824 1.27123422] Bias: -1.0727045156324528 loss: 0.3345139955429444\n",
            "Round: 786 Weight: [2.40559533 1.27143438] Bias: -1.0728526536197203 loss: 0.33451186814637973\n",
            "Round: 787 Weight: [2.40598135 1.271634  ] Bias: -1.0730003728574513 loss: 0.33450975256414184\n",
            "Round: 788 Weight: [2.4063663  1.27183305] Bias: -1.0731476747053263 loss: 0.33450764872629907\n",
            "Round: 789 Weight: [2.40675018 1.27203156] Bias: -1.0732945605175859 loss: 0.3345055565633705\n",
            "Round: 790 Weight: [2.407133   1.27222951] Bias: -1.0734410316430583 loss: 0.3345034760063218\n",
            "Round: 791 Weight: [2.40751475 1.27242692] Bias: -1.0735870894251878 loss: 0.3345014069865626\n",
            "Round: 792 Weight: [2.40789546 1.27262378] Bias: -1.0737327352020616 loss: 0.33449934943594345\n",
            "Round: 793 Weight: [2.4082751  1.27282009] Bias: -1.0738779703064378 loss: 0.3344973032867521\n",
            "Round: 794 Weight: [2.4086537  1.27301586] Bias: -1.0740227960657722 loss: 0.33449526847171085\n",
            "Round: 795 Weight: [2.40903125 1.27321108] Bias: -1.0741672138022453 loss: 0.3344932449239733\n",
            "Round: 796 Weight: [2.40940776 1.27340577] Bias: -1.0743112248327895 loss: 0.33449123257712154\n",
            "Round: 797 Weight: [2.40978322 1.27359991] Bias: -1.0744548304691153 loss: 0.33448923136516273\n",
            "Round: 798 Weight: [2.41015765 1.27379352] Bias: -1.074598032017738 loss: 0.33448724122252604\n",
            "Round: 799 Weight: [2.41053105 1.2739866 ] Bias: -1.0747408307800042 loss: 0.3344852620840604\n",
            "Round: 800 Weight: [2.41090341 1.27417914] Bias: -1.0748832280521174 loss: 0.3344832938850307\n",
            "Round: 801 Weight: [2.41127475 1.27437114] Bias: -1.0750252251251649 loss: 0.3344813365611151\n",
            "Round: 802 Weight: [2.41164506 1.27456262] Bias: -1.0751668232851423 loss: 0.3344793900484024\n",
            "Round: 803 Weight: [2.41201435 1.27475357] Bias: -1.0753080238129809 loss: 0.3344774542833887\n",
            "Round: 804 Weight: [2.41238262 1.27494399] Bias: -1.0754488279845715 loss: 0.334475529202975\n",
            "Round: 805 Weight: [2.41274988 1.27513388] Bias: -1.0755892370707907 loss: 0.3344736147444639\n",
            "Round: 806 Weight: [2.41311613 1.27532325] Bias: -1.0757292523375257 loss: 0.33447171084555694\n",
            "Round: 807 Weight: [2.41348137 1.2755121 ] Bias: -1.0758688750456997 loss: 0.3344698174443521\n",
            "Round: 808 Weight: [2.4138456  1.27570043] Bias: -1.0760081064512963 loss: 0.33446793447934053\n",
            "Round: 809 Weight: [2.41420883 1.27588824] Bias: -1.0761469478053844 loss: 0.33446606188940403\n",
            "Round: 810 Weight: [2.41457106 1.27607553] Bias: -1.0762854003541427 loss: 0.3344641996138123\n",
            "Round: 811 Weight: [2.41493229 1.2762623 ] Bias: -1.076423465338884 loss: 0.33446234759222015\n",
            "Round: 812 Weight: [2.41529253 1.27644856] Bias: -1.0765611439960798 loss: 0.3344605057646651\n",
            "Round: 813 Weight: [2.41565178 1.27663431] Bias: -1.0766984375573838 loss: 0.33445867407156404\n",
            "Round: 814 Weight: [2.41601005 1.27681954] Bias: -1.0768353472496563 loss: 0.33445685245371154\n",
            "Round: 815 Weight: [2.41636733 1.27700427] Bias: -1.0769718742949879 loss: 0.3344550408522762\n",
            "Round: 816 Weight: [2.41672363 1.27718849] Bias: -1.0771080199107228 loss: 0.33445323920879866\n",
            "Round: 817 Weight: [2.41707895 1.2773722 ] Bias: -1.0772437853094827 loss: 0.3344514474651892\n",
            "Round: 818 Weight: [2.4174333  1.27755541] Bias: -1.0773791716991898 loss: 0.3344496655637242\n",
            "Round: 819 Weight: [2.41778667 1.27773811] Bias: -1.07751418028309 loss: 0.3344478934470448\n",
            "Round: 820 Weight: [2.41813908 1.27792031] Bias: -1.0776488122597765 loss: 0.33444613105815346\n",
            "Round: 821 Weight: [2.41849051 1.27810202] Bias: -1.077783068823212 loss: 0.3344443783404118\n",
            "Round: 822 Weight: [2.41884099 1.27828322] Bias: -1.0779169511627515 loss: 0.33444263523753825\n",
            "Round: 823 Weight: [2.41919051 1.27846392] Bias: -1.0780504604631655 loss: 0.33444090169360513\n",
            "Round: 824 Weight: [2.41953907 1.27864413] Bias: -1.0781835979046621 loss: 0.33443917765303677\n",
            "Round: 825 Weight: [2.41988667 1.27882385] Bias: -1.078316364662909 loss: 0.3344374630606065\n",
            "Round: 826 Weight: [2.42023333 1.27900307] Bias: -1.0784487619090566 loss: 0.33443575786143465\n",
            "Round: 827 Weight: [2.42057903 1.27918181] Bias: -1.0785807908097589 loss: 0.3344340620009862\n",
            "Round: 828 Weight: [2.42092379 1.27936005] Bias: -1.0787124525271963 loss: 0.33443237542506765\n",
            "Round: 829 Weight: [2.42126761 1.2795378 ] Bias: -1.0788437482190971 loss: 0.3344306980798258\n",
            "Round: 830 Weight: [2.42161049 1.27971507] Bias: -1.0789746790387593 loss: 0.33442902991174434\n",
            "Round: 831 Weight: [2.42195243 1.27989185] Bias: -1.0791052461350719 loss: 0.3344273708676425\n",
            "Round: 832 Weight: [2.42229343 1.28006815] Bias: -1.0792354506525363 loss: 0.334425720894672\n",
            "Round: 833 Weight: [2.42263351 1.28024397] Bias: -1.0793652937312879 loss: 0.3344240799403147\n",
            "Round: 834 Weight: [2.42297266 1.2804193 ] Bias: -1.0794947765071166 loss: 0.3344224479523812\n",
            "Round: 835 Weight: [2.42331088 1.28059416] Bias: -1.0796239001114885 loss: 0.33442082487900776\n",
            "Round: 836 Weight: [2.42364818 1.28076854] Bias: -1.0797526656715661 loss: 0.3344192106686542\n",
            "Round: 837 Weight: [2.42398456 1.28094244] Bias: -1.0798810743102298 loss: 0.334417605270102\n",
            "Round: 838 Weight: [2.42432002 1.28111587] Bias: -1.0800091271460979 loss: 0.33441600863245174\n",
            "Round: 839 Weight: [2.42465457 1.28128882] Bias: -1.080136825293547 loss: 0.33441442070512134\n",
            "Round: 840 Weight: [2.42498821 1.2814613 ] Bias: -1.0802641698627333 loss: 0.33441284143784317\n",
            "Round: 841 Weight: [2.42532094 1.28163332] Bias: -1.080391161959612 loss: 0.33441127078066285\n",
            "Round: 842 Weight: [2.42565276 1.28180486] Bias: -1.0805178026859574 loss: 0.33440970868393616\n",
            "Round: 843 Weight: [2.42598368 1.28197593] Bias: -1.0806440931393833 loss: 0.3344081550983279\n",
            "Round: 844 Weight: [2.4263137  1.28214654] Bias: -1.0807700344133626 loss: 0.3344066099748087\n",
            "Round: 845 Weight: [2.42664282 1.28231668] Bias: -1.0808956275972474 loss: 0.3344050732646539\n",
            "Round: 846 Weight: [2.42697104 1.28248636] Bias: -1.0810208737762883 loss: 0.33440354491944074\n",
            "Round: 847 Weight: [2.42729838 1.28265558] Bias: -1.0811457740316541 loss: 0.334402024891047\n",
            "Round: 848 Weight: [2.42762482 1.28282434] Bias: -1.081270329440451 loss: 0.33440051313164815\n",
            "Round: 849 Weight: [2.42795038 1.28299264] Bias: -1.0813945410757424 loss: 0.33439900959371605\n",
            "Round: 850 Weight: [2.42827505 1.28316048] Bias: -1.0815184100065673 loss: 0.3343975142300167\n",
            "Round: 851 Weight: [2.42859884 1.28332786] Bias: -1.0816419372979602 loss: 0.334396026993608\n",
            "Round: 852 Weight: [2.42892175 1.28349479] Bias: -1.0817651240109694 loss: 0.3343945478378381\n",
            "Round: 853 Weight: [2.42924379 1.28366126] Bias: -1.0818879712026759 loss: 0.3343930767163432\n",
            "Round: 854 Weight: [2.42956495 1.28382729] Bias: -1.0820104799262125 loss: 0.33439161358304587\n",
            "Round: 855 Weight: [2.42988524 1.28399286] Bias: -1.0821326512307823 loss: 0.3343901583921526\n",
            "Round: 856 Weight: [2.43020467 1.28415798] Bias: -1.0822544861616767 loss: 0.33438871109815255\n",
            "Round: 857 Weight: [2.43052322 1.28432265] Bias: -1.0823759857602948 loss: 0.33438727165581533\n",
            "Round: 858 Weight: [2.43084092 1.28448688] Bias: -1.0824971510641603 loss: 0.33438584002018873\n",
            "Round: 859 Weight: [2.43115775 1.28465066] Bias: -1.0826179831069411 loss: 0.3343844161465975\n",
            "Round: 860 Weight: [2.43147373 1.284814  ] Bias: -1.0827384829184665 loss: 0.33438299999064114\n",
            "Round: 861 Weight: [2.43178885 1.28497689] Bias: -1.0828586515247451 loss: 0.33438159150819213\n",
            "Round: 862 Weight: [2.43210311 1.28513934] Bias: -1.082978489947983 loss: 0.334380190655394\n",
            "Round: 863 Weight: [2.43241653 1.28530135] Bias: -1.0830979992066019 loss: 0.3343787973886594\n",
            "Round: 864 Weight: [2.4327291  1.28546293] Bias: -1.0832171803152557 loss: 0.3343774116646688\n",
            "Round: 865 Weight: [2.43304082 1.28562406] Bias: -1.083336034284849 loss: 0.3343760334403682\n",
            "Round: 866 Weight: [2.43335171 1.28578476] Bias: -1.0834545621225542 loss: 0.3343746626729674\n",
            "Round: 867 Weight: [2.43366175 1.28594502] Bias: -1.0835727648318285 loss: 0.33437329931993837\n",
            "Round: 868 Weight: [2.43397095 1.28610485] Bias: -1.0836906434124316 loss: 0.33437194333901343\n",
            "Round: 869 Weight: [2.43427932 1.28626425] Bias: -1.0838081988604429 loss: 0.33437059468818386\n",
            "Round: 870 Weight: [2.43458685 1.28642322] Bias: -1.083925432168278 loss: 0.3343692533256974\n",
            "Round: 871 Weight: [2.43489356 1.28658176] Bias: -1.0840423443247063 loss: 0.3343679192100571\n",
            "Round: 872 Weight: [2.43519944 1.28673986] Bias: -1.084158936314867 loss: 0.3343665923000196\n",
            "Round: 873 Weight: [2.43550449 1.28689754] Bias: -1.0842752091202865 loss: 0.3343652725545933\n",
            "Round: 874 Weight: [2.43580872 1.2870548 ] Bias: -1.0843911637188952 loss: 0.33436395993303647\n",
            "Round: 875 Weight: [2.43611213 1.28721163] Bias: -1.0845068010850432 loss: 0.3343626543948563\n",
            "Round: 876 Weight: [2.43641472 1.28736804] Bias: -1.0846221221895174 loss: 0.3343613558998063\n",
            "Round: 877 Weight: [2.4367165  1.28752402] Bias: -1.084737127999558 loss: 0.33436006440788524\n",
            "Round: 878 Weight: [2.43701746 1.28767958] Bias: -1.0848518194788739 loss: 0.3343587798793358\n",
            "Round: 879 Weight: [2.43731761 1.28783473] Bias: -1.0849661975876599 loss: 0.33435750227464195\n",
            "Round: 880 Weight: [2.43761696 1.28798945] Bias: -1.0850802632826122 loss: 0.3343562315545282\n",
            "Round: 881 Weight: [2.4379155  1.28814376] Bias: -1.085194017516944 loss: 0.3343549676799579\n",
            "Round: 882 Weight: [2.43821323 1.28829765] Bias: -1.0853074612404028 loss: 0.33435371061213137\n",
            "Round: 883 Weight: [2.43851017 1.28845113] Bias: -1.0854205953992841 loss: 0.33435246031248445\n",
            "Round: 884 Weight: [2.4388063 1.2886042] Bias: -1.0855334209364493 loss: 0.334351216742687\n",
            "Round: 885 Weight: [2.43910164 1.28875685] Bias: -1.0856459387913395 loss: 0.3343499798646414\n",
            "Round: 886 Weight: [2.43939619 1.28890909] Bias: -1.0857581498999922 loss: 0.3343487496404806\n",
            "Round: 887 Weight: [2.43968994 1.28906092] Bias: -1.0858700551950562 loss: 0.3343475260325674\n",
            "Round: 888 Weight: [2.43998291 1.28921234] Bias: -1.0859816556058073 loss: 0.33434630900349216\n",
            "Round: 889 Weight: [2.44027508 1.28936336] Bias: -1.0860929520581628 loss: 0.3343450985160715\n",
            "Round: 890 Weight: [2.44056648 1.28951397] Bias: -1.086203945474698 loss: 0.3343438945333472\n",
            "Round: 891 Weight: [2.44085709 1.28966417] Bias: -1.0863146367746597 loss: 0.3343426970185842\n",
            "Round: 892 Weight: [2.44114692 1.28981397] Bias: -1.0864250268739823 loss: 0.3343415059352694\n",
            "Round: 893 Weight: [2.44143597 1.28996337] Bias: -1.086535116685303 loss: 0.33434032124711016\n",
            "Round: 894 Weight: [2.44172425 1.29011237] Bias: -1.0866449071179751 loss: 0.33433914291803274\n",
            "Round: 895 Weight: [2.44201176 1.29026096] Bias: -1.0867543990780844 loss: 0.3343379709121812\n",
            "Round: 896 Weight: [2.44229849 1.29040916] Bias: -1.0868635934684627 loss: 0.3343368051939154\n",
            "Round: 897 Weight: [2.44258446 1.29055696] Bias: -1.0869724911887035 loss: 0.33433564572781016\n",
            "Round: 898 Weight: [2.44286966 1.29070436] Bias: -1.0870810931351753 loss: 0.33433449247865366\n",
            "Round: 899 Weight: [2.44315409 1.29085137] Bias: -1.0871894002010365 loss: 0.33433334541144566\n",
            "Round: 900 Weight: [2.44343777 1.29099798] Bias: -1.0872974132762503 loss: 0.33433220449139656\n",
            "Round: 901 Weight: [2.44372068 1.2911442 ] Bias: -1.0874051332475982 loss: 0.33433106968392623\n",
            "Round: 902 Weight: [2.44400284 1.29129003] Bias: -1.0875125609986946 loss: 0.3343299409546618\n",
            "Round: 903 Weight: [2.44428424 1.29143547] Bias: -1.0876196974100005 loss: 0.33432881826943733\n",
            "Round: 904 Weight: [2.44456489 1.29158051] Bias: -1.0877265433588381 loss: 0.3343277015942915\n",
            "Round: 905 Weight: [2.44484479 1.29172517] Bias: -1.0878330997194041 loss: 0.3343265908954669\n",
            "Round: 906 Weight: [2.44512394 1.29186944] Bias: -1.087939367362784 loss: 0.33432548613940855\n",
            "Round: 907 Weight: [2.44540234 1.29201333] Bias: -1.0880453471569658 loss: 0.33432438729276265\n",
            "Round: 908 Weight: [2.44568    1.29215683] Bias: -1.088151039966854 loss: 0.3343232943223749\n",
            "Round: 909 Weight: [2.44595692 1.29229995] Bias: -1.0882564466542821 loss: 0.33432220719528977\n",
            "Round: 910 Weight: [2.4462331  1.29244268] Bias: -1.0883615680780279 loss: 0.33432112587874857\n",
            "Round: 911 Weight: [2.44650854 1.29258503] Bias: -1.0884664050938253 loss: 0.33432005034018886\n",
            "Round: 912 Weight: [2.44678325 1.292727  ] Bias: -1.088570958554379 loss: 0.3343189805472426\n",
            "Round: 913 Weight: [2.44705722 1.29286859] Bias: -1.088675229309377 loss: 0.33431791646773507\n",
            "Round: 914 Weight: [2.44733046 1.2930098 ] Bias: -1.0887792182055043 loss: 0.33431685806968403\n",
            "Round: 915 Weight: [2.44760297 1.29315064] Bias: -1.0888829260864559 loss: 0.33431580532129773\n",
            "Round: 916 Weight: [2.44787476 1.2932911 ] Bias: -1.0889863537929498 loss: 0.3343147581909742\n",
            "Round: 917 Weight: [2.44814582 1.29343118] Bias: -1.0890895021627405 loss: 0.33431371664729975\n",
            "Round: 918 Weight: [2.44841616 1.29357089] Bias: -1.0891923720306316 loss: 0.33431268065904796\n",
            "Round: 919 Weight: [2.44868578 1.29371023] Bias: -1.0892949642284886 loss: 0.33431165019517856\n",
            "Round: 920 Weight: [2.44895468 1.29384919] Bias: -1.089397279585252 loss: 0.3343106252248358\n",
            "Round: 921 Weight: [2.44922286 1.29398779] Bias: -1.0894993189269502 loss: 0.3343096057173474\n",
            "Round: 922 Weight: [2.44949033 1.29412601] Bias: -1.0896010830767116 loss: 0.334308591642224\n",
            "Round: 923 Weight: [2.44975709 1.29426387] Bias: -1.0897025728547778 loss: 0.3343075829691568\n",
            "Round: 924 Weight: [2.45002314 1.29440136] Bias: -1.089803789078516 loss: 0.33430657966801747\n",
            "Round: 925 Weight: [2.45028848 1.29453848] Bias: -1.089904732562431 loss: 0.33430558170885666\n",
            "Round: 926 Weight: [2.45055311 1.29467524] Bias: -1.0900054041181784 loss: 0.3343045890619023\n",
            "Round: 927 Weight: [2.45081704 1.29481163] Bias: -1.0901058045545764 loss: 0.3343036016975594\n",
            "Round: 928 Weight: [2.45108027 1.29494766] Bias: -1.0902059346776185 loss: 0.33430261958640806\n",
            "Round: 929 Weight: [2.45134279 1.29508333] Bias: -1.0903057952904853 loss: 0.33430164269920304\n",
            "Round: 930 Weight: [2.45160462 1.29521863] Bias: -1.0904053871935566 loss: 0.33430067100687194\n",
            "Round: 931 Weight: [2.45186576 1.29535358] Bias: -1.0905047111844242 loss: 0.3342997044805149\n",
            "Round: 932 Weight: [2.4521262  1.29548817] Bias: -1.0906037680579028 loss: 0.3342987430914027\n",
            "Round: 933 Weight: [2.45238595 1.2956224 ] Bias: -1.0907025586060433 loss: 0.33429778681097605\n",
            "Round: 934 Weight: [2.45264501 1.29575627] Bias: -1.0908010836181432 loss: 0.3342968356108449\n",
            "Round: 935 Weight: [2.45290338 1.29588978] Bias: -1.0908993438807597 loss: 0.3342958894627864\n",
            "Round: 936 Weight: [2.45316107 1.29602295] Bias: -1.0909973401777207 loss: 0.3342949483387448\n",
            "Round: 937 Weight: [2.45341807 1.29615575] Bias: -1.0910950732901366 loss: 0.33429401221082955\n",
            "Round: 938 Weight: [2.45367439 1.29628821] Bias: -1.0911925439964125 loss: 0.33429308105131494\n",
            "Round: 939 Weight: [2.45393003 1.29642031] Bias: -1.0912897530722592 loss: 0.33429215483263863\n",
            "Round: 940 Weight: [2.45418499 1.29655206] Bias: -1.0913867012907046 loss: 0.3342912335274009\n",
            "Round: 941 Weight: [2.45443928 1.29668347] Bias: -1.0914833894221057 loss: 0.3342903171083631\n",
            "Round: 942 Weight: [2.45469289 1.29681452] Bias: -1.0915798182341594 loss: 0.3342894055484473\n",
            "Round: 943 Weight: [2.45494584 1.29694522] Bias: -1.0916759884919143 loss: 0.33428849882073486\n",
            "Round: 944 Weight: [2.45519811 1.29707558] Bias: -1.0917719009577815 loss: 0.3342875968984653\n",
            "Round: 945 Weight: [2.45544971 1.2972056 ] Bias: -1.0918675563915468 loss: 0.33428669975503583\n",
            "Round: 946 Weight: [2.45570065 1.29733526] Bias: -1.0919629555503803 loss: 0.33428580736399965\n",
            "Round: 947 Weight: [2.45595092 1.29746459] Bias: -1.0920580991888487 loss: 0.3342849196990656\n",
            "Round: 948 Weight: [2.45620053 1.29759357] Bias: -1.092152988058926 loss: 0.33428403673409673\n",
            "Round: 949 Weight: [2.45644948 1.29772221] Bias: -1.0922476229100044 loss: 0.3342831584431094\n",
            "Round: 950 Weight: [2.45669777 1.29785051] Bias: -1.0923420044889052 loss: 0.3342822848002726\n",
            "Round: 951 Weight: [2.45694541 1.29797847] Bias: -1.0924361335398893 loss: 0.3342814157799068\n",
            "Round: 952 Weight: [2.45719239 1.29810609] Bias: -1.092530010804669 loss: 0.33428055135648255\n",
            "Round: 953 Weight: [2.45743871 1.29823337] Bias: -1.0926236370224178 loss: 0.33427969150462056\n",
            "Round: 954 Weight: [2.45768439 1.29836032] Bias: -1.0927170129297814 loss: 0.33427883619908955\n",
            "Round: 955 Weight: [2.45792942 1.29848693] Bias: -1.0928101392608884 loss: 0.3342779854148064\n",
            "Round: 956 Weight: [2.4581738 1.2986132] Bias: -1.092903016747361 loss: 0.3342771391268343\n",
            "Round: 957 Weight: [2.45841753 1.29873915] Bias: -1.0929956461183248 loss: 0.3342762973103825\n",
            "Round: 958 Weight: [2.45866062 1.29886475] Bias: -1.0930880281004203 loss: 0.334275459940805\n",
            "Round: 959 Weight: [2.45890307 1.29899003] Bias: -1.0931801634178124 loss: 0.3342746269935998\n",
            "Round: 960 Weight: [2.45914488 1.29911497] Bias: -1.0932720527922015 loss: 0.3342737984444079\n",
            "Round: 961 Weight: [2.45938605 1.29923959] Bias: -1.0933636969428333 loss: 0.3342729742690127\n",
            "Round: 962 Weight: [2.45962659 1.29936387] Bias: -1.093455096586509 loss: 0.3342721544433387\n",
            "Round: 963 Weight: [2.45986649 1.29948783] Bias: -1.0935462524375958 loss: 0.3342713389434505\n",
            "Round: 964 Weight: [2.46010576 1.29961146] Bias: -1.0936371652080372 loss: 0.33427052774555277\n",
            "Round: 965 Weight: [2.46034439 1.29973476] Bias: -1.0937278356073623 loss: 0.33426972082598844\n",
            "Round: 966 Weight: [2.4605824  1.29985774] Bias: -1.0938182643426966 loss: 0.3342689181612381\n",
            "Round: 967 Weight: [2.46081978 1.2999804 ] Bias: -1.0939084521187716 loss: 0.33426811972791937\n",
            "Round: 968 Weight: [2.46105654 1.30010273] Bias: -1.0939983996379352 loss: 0.3342673255027861\n",
            "Round: 969 Weight: [2.46129267 1.30022473] Bias: -1.0940881076001607 loss: 0.33426653546272705\n",
            "Round: 970 Weight: [2.46152818 1.30034642] Bias: -1.0941775767030575 loss: 0.33426574958476524\n",
            "Round: 971 Weight: [2.46176307 1.30046778] Bias: -1.0942668076418804 loss: 0.33426496784605725\n",
            "Round: 972 Weight: [2.46199734 1.30058883] Bias: -1.0943558011095393 loss: 0.3342641902238926\n",
            "Round: 973 Weight: [2.462231   1.30070955] Bias: -1.0944445577966095 loss: 0.33426341669569243\n",
            "Round: 974 Weight: [2.46246404 1.30082996] Bias: -1.0945330783913403 loss: 0.33426264723900856\n",
            "Round: 975 Weight: [2.46269647 1.30095005] Bias: -1.0946213635796653 loss: 0.33426188183152356\n",
            "Round: 976 Weight: [2.46292828 1.30106982] Bias: -1.094709414045212 loss: 0.3342611204510489\n",
            "Round: 977 Weight: [2.46315949 1.30118928] Bias: -1.0947972304693108 loss: 0.3342603630755249\n",
            "Round: 978 Weight: [2.46339009 1.30130843] Bias: -1.0948848135310045 loss: 0.3342596096830196\n",
            "Round: 979 Weight: [2.46362008 1.30142726] Bias: -1.0949721639070584 loss: 0.33425886025172785\n",
            "Round: 980 Weight: [2.46384947 1.30154577] Bias: -1.0950592822719685 loss: 0.3342581147599709\n",
            "Round: 981 Weight: [2.46407825 1.30166398] Bias: -1.0951461692979716 loss: 0.3342573731861951\n",
            "Round: 982 Weight: [2.46430644 1.30178187] Bias: -1.0952328256550543 loss: 0.3342566355089718\n",
            "Round: 983 Weight: [2.46453402 1.30189946] Bias: -1.0953192520109623 loss: 0.33425590170699593\n",
            "Round: 984 Weight: [2.46476101 1.30201674] Bias: -1.095405449031209 loss: 0.3342551717590853\n",
            "Round: 985 Weight: [2.4649874 1.3021337] Bias: -1.0954914173790857 loss: 0.33425444564418055\n",
            "Round: 986 Weight: [2.4652132  1.30225036] Bias: -1.0955771577156694 loss: 0.33425372334134346\n",
            "Round: 987 Weight: [2.46543841 1.30236672] Bias: -1.0956626706998327 loss: 0.3342530048297567\n",
            "Round: 988 Weight: [2.46566302 1.30248276] Bias: -1.0957479569882524 loss: 0.33425229008872304\n",
            "Round: 989 Weight: [2.46588705 1.30259851] Bias: -1.0958330172354187 loss: 0.3342515790976644\n",
            "Round: 990 Weight: [2.46611049 1.30271395] Bias: -1.0959178520936432 loss: 0.3342508718361215\n",
            "Round: 991 Weight: [2.46633334 1.30282908] Bias: -1.096002462213069 loss: 0.33425016828375265\n",
            "Round: 992 Weight: [2.46655561 1.30294392] Bias: -1.0960868482416788 loss: 0.33424946842033343\n",
            "Round: 993 Weight: [2.46677729 1.30305845] Bias: -1.0961710108253033 loss: 0.3342487722257558\n",
            "Round: 994 Weight: [2.4669984  1.30317268] Bias: -1.0962549506076305 loss: 0.3342480796800272\n",
            "Round: 995 Weight: [2.46721892 1.30328661] Bias: -1.096338668230214 loss: 0.3342473907632702\n",
            "Round: 996 Weight: [2.46743887 1.30340025] Bias: -1.0964221643324823 loss: 0.33424670545572144\n",
            "Round: 997 Weight: [2.46765824 1.30351358] Bias: -1.096505439551746 loss: 0.3342460237377314\n",
            "Round: 998 Weight: [2.46787704 1.30362662] Bias: -1.0965884945232074 loss: 0.33424534558976293\n",
            "Round: 999 Weight: [2.46809527 1.30373936] Bias: -1.096671329879969 loss: 0.3342446709923913\n",
            "Round: 1000 Weight: [2.46831292 1.30385181] Bias: -1.0967539462530413 loss: 0.3342439999263032\n",
            "Round: 1001 Weight: [2.46853    1.30396396] Bias: -1.0968363442713516 loss: 0.33424333237229625\n",
            "Round: 1002 Weight: [2.46874652 1.30407582] Bias: -1.0969185245617523 loss: 0.33424266831127775\n",
            "Round: 1003 Weight: [2.46896247 1.30418738] Bias: -1.0970004877490294 loss: 0.3342420077242647\n",
            "Round: 1004 Weight: [2.46917786 1.30429866] Bias: -1.09708223445591 loss: 0.33424135059238275\n",
            "Round: 1005 Weight: [2.46939268 1.30440964] Bias: -1.0971637653030715 loss: 0.3342406968968656\n",
            "Round: 1006 Weight: [2.46960694 1.30452033] Bias: -1.0972450809091494 loss: 0.33424004661905443\n",
            "Round: 1007 Weight: [2.46982064 1.30463073] Bias: -1.0973261818907452 loss: 0.3342393997403969\n",
            "Round: 1008 Weight: [2.47003378 1.30474084] Bias: -1.0974070688624347 loss: 0.33423875624244737\n",
            "Round: 1009 Weight: [2.47024637 1.30485067] Bias: -1.0974877424367764 loss: 0.3342381161068648\n",
            "Round: 1010 Weight: [2.4704584  1.30496021] Bias: -1.0975682032243188 loss: 0.33423747931541353\n",
            "Round: 1011 Weight: [2.47066988 1.30506946] Bias: -1.0976484518336092 loss: 0.334236845849962\n",
            "Round: 1012 Weight: [2.4708808  1.30517842] Bias: -1.097728488871201 loss: 0.33423621569248196\n",
            "Round: 1013 Weight: [2.47109118 1.3052871 ] Bias: -1.0978083149416615 loss: 0.33423558882504806\n",
            "Round: 1014 Weight: [2.471301  1.3053955] Bias: -1.097887930647581 loss: 0.3342349652298375\n",
            "Round: 1015 Weight: [2.47151028 1.30550361] Bias: -1.097967336589579 loss: 0.3342343448891287\n",
            "Round: 1016 Weight: [2.47171901 1.30561144] Bias: -1.098046533366313 loss: 0.33423372778530147\n",
            "Round: 1017 Weight: [2.4719272  1.30571899] Bias: -1.0981255215744858 loss: 0.3342331139008356\n",
            "Round: 1018 Weight: [2.47213485 1.30582626] Bias: -1.0982043018088539 loss: 0.3342325032183112\n",
            "Round: 1019 Weight: [2.47234195 1.30593325] Bias: -1.0982828746622342 loss: 0.33423189572040696\n",
            "Round: 1020 Weight: [2.47254851 1.30603996] Bias: -1.0983612407255121 loss: 0.3342312913899006\n",
            "Round: 1021 Weight: [2.47275454 1.30614639] Bias: -1.0984394005876497 loss: 0.33423069020966756\n",
            "Round: 1022 Weight: [2.47296003 1.30625254] Bias: -1.0985173548356921 loss: 0.33423009216268085\n",
            "Round: 1023 Weight: [2.47316498 1.30635842] Bias: -1.098595104054776 loss: 0.33422949723201006\n",
            "Round: 1024 Weight: [2.4733694  1.30646402] Bias: -1.0986726488281364 loss: 0.33422890540082106\n",
            "Round: 1025 Weight: [2.47357328 1.30656934] Bias: -1.0987499897371154 loss: 0.3342283166523754\n",
            "Round: 1026 Weight: [2.47377664 1.30667439] Bias: -1.0988271273611676 loss: 0.3342277309700296\n",
            "Round: 1027 Weight: [2.47397947 1.30677917] Bias: -1.0989040622778692 loss: 0.3342271483372346\n",
            "Round: 1028 Weight: [2.47418177 1.30688367] Bias: -1.0989807950629247 loss: 0.3342265687375352\n",
            "Round: 1029 Weight: [2.47438354 1.3069879 ] Bias: -1.099057326290174 loss: 0.3342259921545697\n",
            "Round: 1030 Weight: [2.47458478 1.30709186] Bias: -1.0991336565316 loss: 0.3342254185720689\n",
            "Round: 1031 Weight: [2.47478551 1.30719555] Bias: -1.0992097863573356 loss: 0.334224847973856\n",
            "Round: 1032 Weight: [2.47498571 1.30729897] Bias: -1.0992857163356713 loss: 0.3342242803438457\n",
            "Round: 1033 Weight: [2.47518539 1.30740212] Bias: -1.0993614470330622 loss: 0.3342237156660438\n",
            "Round: 1034 Weight: [2.47538455 1.307505  ] Bias: -1.0994369790141347 loss: 0.33422315392454666\n",
            "Round: 1035 Weight: [2.4755832  1.30760761] Bias: -1.0995123128416944 loss: 0.3342225951035405\n",
            "Round: 1036 Weight: [2.47578132 1.30770996] Bias: -1.0995874490767321 loss: 0.3342220391873012\n",
            "Round: 1037 Weight: [2.47597894 1.30781204] Bias: -1.0996623882784322 loss: 0.33422148616019326\n",
            "Round: 1038 Weight: [2.47617604 1.30791385] Bias: -1.0997371310041786 loss: 0.3342209360066698\n",
            "Round: 1039 Weight: [2.47637262 1.3080154 ] Bias: -1.0998116778095621 loss: 0.33422038871127163\n",
            "Round: 1040 Weight: [2.4765687  1.30811669] Bias: -1.0998860292483872 loss: 0.3342198442586267\n",
            "Round: 1041 Weight: [2.47676427 1.30821771] Bias: -1.0999601858726793 loss: 0.33421930263345\n",
            "Round: 1042 Weight: [2.47695933 1.30831847] Bias: -1.100034148232691 loss: 0.3342187638205428\n",
            "Round: 1043 Weight: [2.47715388 1.30841896] Bias: -1.1001079168769095 loss: 0.3342182278047918\n",
            "Round: 1044 Weight: [2.47734793 1.3085192 ] Bias: -1.1001814923520632 loss: 0.3342176945711693\n",
            "Round: 1045 Weight: [2.47754148 1.30861918] Bias: -1.1002548752031285 loss: 0.33421716410473173\n",
            "Round: 1046 Weight: [2.47773452 1.30871889] Bias: -1.1003280659733363 loss: 0.33421663639062027\n",
            "Round: 1047 Weight: [2.47792706 1.30881835] Bias: -1.1004010652041791 loss: 0.33421611141405966\n",
            "Round: 1048 Weight: [2.47811911 1.30891755] Bias: -1.1004738734354171 loss: 0.33421558916035765\n",
            "Round: 1049 Weight: [2.47831065 1.30901649] Bias: -1.1005464912050857 loss: 0.3342150696149048\n",
            "Round: 1050 Weight: [2.4785017  1.30911517] Bias: -1.1006189190495015 loss: 0.33421455276317374\n",
            "Round: 1051 Weight: [2.47869225 1.3092136 ] Bias: -1.1006911575032687 loss: 0.3342140385907191\n",
            "Round: 1052 Weight: [2.47888231 1.30931178] Bias: -1.1007632070992865 loss: 0.33421352708317625\n",
            "Round: 1053 Weight: [2.47907188 1.30940969] Bias: -1.1008350683687547 loss: 0.3342130182262617\n",
            "Round: 1054 Weight: [2.47926096 1.30950736] Bias: -1.1009067418411804 loss: 0.33421251200577207\n",
            "Round: 1055 Weight: [2.47944954 1.30960477] Bias: -1.1009782280443852 loss: 0.3342120084075837\n",
            "Round: 1056 Weight: [2.47963764 1.30970193] Bias: -1.1010495275045105 loss: 0.33421150741765215\n",
            "Round: 1057 Weight: [2.47982525 1.30979883] Bias: -1.1011206407460246 loss: 0.334211009022012\n",
            "Round: 1058 Weight: [2.48001238 1.30989549] Bias: -1.101191568291729 loss: 0.33421051320677586\n",
            "Round: 1059 Weight: [2.48019902 1.30999189] Bias: -1.1012623106627648 loss: 0.33421001995813443\n",
            "Round: 1060 Weight: [2.48038518 1.31008805] Bias: -1.1013328683786185 loss: 0.334209529262356\n",
            "Round: 1061 Weight: [2.48057085 1.31018395] Bias: -1.101403241957129 loss: 0.33420904110578525\n",
            "Round: 1062 Weight: [2.48075605 1.31027961] Bias: -1.101473431914493 loss: 0.33420855547484396\n",
            "Round: 1063 Weight: [2.48094077 1.31037502] Bias: -1.1015434387652723 loss: 0.33420807235602934\n",
            "Round: 1064 Weight: [2.48112501 1.31047018] Bias: -1.101613263022399 loss: 0.3342075917359147\n",
            "Round: 1065 Weight: [2.48130877 1.3105651 ] Bias: -1.101682905197182 loss: 0.33420711360114824\n",
            "Round: 1066 Weight: [2.48149206 1.31065977] Bias: -1.1017523657993133 loss: 0.3342066379384529\n",
            "Round: 1067 Weight: [2.48167487 1.3107542 ] Bias: -1.101821645336874 loss: 0.33420616473462583\n",
            "Round: 1068 Weight: [2.48185721 1.31084838] Bias: -1.1018907443163408 loss: 0.33420569397653793\n",
            "Round: 1069 Weight: [2.48203908 1.31094232] Bias: -1.1019596632425908 loss: 0.3342052256511335\n",
            "Round: 1070 Weight: [2.48222048 1.31103601] Bias: -1.1020284026189087 loss: 0.3342047597454298\n",
            "Round: 1071 Weight: [2.48240142 1.31112946] Bias: -1.1020969629469926 loss: 0.33420429624651643\n",
            "Round: 1072 Weight: [2.48258188 1.31122267] Bias: -1.1021653447269595 loss: 0.3342038351415553\n",
            "Round: 1073 Weight: [2.48276188 1.31131564] Bias: -1.1022335484573516 loss: 0.33420337641777986\n",
            "Round: 1074 Weight: [2.48294141 1.31140837] Bias: -1.1023015746351423 loss: 0.33420292006249447\n",
            "Round: 1075 Weight: [2.48312048 1.31150086] Bias: -1.1023694237557418 loss: 0.3342024660630748\n",
            "Round: 1076 Weight: [2.48329909 1.31159311] Bias: -1.102437096313003 loss: 0.33420201440696656\n",
            "Round: 1077 Weight: [2.48347724 1.31168512] Bias: -1.1025045927992274 loss: 0.33420156508168525\n",
            "Round: 1078 Weight: [2.48365493 1.3117769 ] Bias: -1.102571913705171 loss: 0.3342011180748164\n",
            "Round: 1079 Weight: [2.48383215 1.31186844] Bias: -1.1026390595200501 loss: 0.3342006733740142\n",
            "Round: 1080 Weight: [2.48400893 1.31195974] Bias: -1.1027060307315466 loss: 0.3342002309670019\n",
            "Round: 1081 Weight: [2.48418524 1.3120508 ] Bias: -1.102772827825814 loss: 0.33419979084157075\n",
            "Round: 1082 Weight: [2.4843611  1.31214163] Bias: -1.1028394512874835 loss: 0.3341993529855802\n",
            "Round: 1083 Weight: [2.48453651 1.31223223] Bias: -1.102905901599669 loss: 0.33419891738695684\n",
            "Round: 1084 Weight: [2.48471147 1.31232259] Bias: -1.1029721792439733 loss: 0.3341984840336949\n",
            "Round: 1085 Weight: [2.48488597 1.31241272] Bias: -1.1030382847004931 loss: 0.3341980529138548\n",
            "Round: 1086 Weight: [2.48506003 1.31250262] Bias: -1.1031042184478255 loss: 0.3341976240155637\n",
            "Round: 1087 Weight: [2.48523364 1.31259228] Bias: -1.1031699809630724 loss: 0.33419719732701425\n",
            "Round: 1088 Weight: [2.4854068  1.31268171] Bias: -1.103235572721847 loss: 0.334196772836465\n",
            "Round: 1089 Weight: [2.48557951 1.31277092] Bias: -1.103300994198279 loss: 0.3341963505322396\n",
            "Round: 1090 Weight: [2.48575178 1.31285989] Bias: -1.1033662458650197 loss: 0.3341959304027263\n",
            "Round: 1091 Weight: [2.48592361 1.31294863] Bias: -1.1034313281932484 loss: 0.334195512436378\n",
            "Round: 1092 Weight: [2.48609499 1.31303715] Bias: -1.103496241652677 loss: 0.3341950966217114\n",
            "Round: 1093 Weight: [2.48626593 1.31312543] Bias: -1.1035609867115557 loss: 0.33419468294730675\n",
            "Round: 1094 Weight: [2.48643643 1.31321349] Bias: -1.103625563836678 loss: 0.33419427140180785\n",
            "Round: 1095 Weight: [2.4866065  1.31330133] Bias: -1.1036899734933874 loss: 0.3341938619739212\n",
            "Round: 1096 Weight: [2.48677612 1.31338893] Bias: -1.103754216145581 loss: 0.33419345465241596\n",
            "Round: 1097 Weight: [2.48694531 1.31347631] Bias: -1.1038182922557154 loss: 0.3341930494261232\n",
            "Round: 1098 Weight: [2.48711407 1.31356347] Bias: -1.1038822022848132 loss: 0.33419264628393613\n",
            "Round: 1099 Weight: [2.48728239 1.3136504 ] Bias: -1.1039459466924664 loss: 0.3341922452148092\n",
            "Round: 1100 Weight: [2.48745027 1.31373711] Bias: -1.1040095259368428 loss: 0.33419184620775794\n",
            "Round: 1101 Weight: [2.48761773 1.31382359] Bias: -1.104072940474691 loss: 0.3341914492518583\n",
            "Round: 1102 Weight: [2.48778476 1.31390985] Bias: -1.1041361907613456 loss: 0.3341910543362472\n",
            "Round: 1103 Weight: [2.48795135 1.31399589] Bias: -1.104199277250732 loss: 0.3341906614501212\n",
            "Round: 1104 Weight: [2.48811752 1.31408171] Bias: -1.1042622003953726 loss: 0.33419027058273637\n",
            "Round: 1105 Weight: [2.48828326 1.31416731] Bias: -1.1043249606463903 loss: 0.3341898817234085\n",
            "Round: 1106 Weight: [2.48844858 1.31425268] Bias: -1.104387558453515 loss: 0.33418949486151195\n",
            "Round: 1107 Weight: [2.48861347 1.31433784] Bias: -1.1044499942650883 loss: 0.33418910998648\n",
            "Round: 1108 Weight: [2.48877794 1.31442278] Bias: -1.1045122685280682 loss: 0.33418872708780384\n",
            "Round: 1109 Weight: [2.48894198 1.3145075 ] Bias: -1.1045743816880345 loss: 0.3341883461550329\n",
            "Round: 1110 Weight: [2.48910561 1.314592  ] Bias: -1.1046363341891938 loss: 0.3341879671777742\n",
            "Round: 1111 Weight: [2.48926881 1.31467629] Bias: -1.1046981264743845 loss: 0.3341875901456919\n",
            "Round: 1112 Weight: [2.4894316  1.31476036] Bias: -1.1047597589850813 loss: 0.334187215048507\n",
            "Round: 1113 Weight: [2.48959396 1.31484421] Bias: -1.1048212321614008 loss: 0.33418684187599734\n",
            "Round: 1114 Weight: [2.48975591 1.31492785] Bias: -1.1048825464421064 loss: 0.33418647061799683\n",
            "Round: 1115 Weight: [2.48991745 1.31501127] Bias: -1.1049437022646125 loss: 0.3341861012643954\n",
            "Round: 1116 Weight: [2.49007857 1.31509448] Bias: -1.1050047000649903 loss: 0.3341857338051386\n",
            "Round: 1117 Weight: [2.49023928 1.31517748] Bias: -1.1050655402779719 loss: 0.33418536823022726\n",
            "Round: 1118 Weight: [2.49039957 1.31526026] Bias: -1.1051262233369554 loss: 0.3341850045297171\n",
            "Round: 1119 Weight: [2.49055946 1.31534283] Bias: -1.1051867496740104 loss: 0.33418464269371856\n",
            "Round: 1120 Weight: [2.49071894 1.31542519] Bias: -1.1052471197198814 loss: 0.3341842827123964\n",
            "Round: 1121 Weight: [2.490878   1.31550733] Bias: -1.1053073339039938 loss: 0.3341839245759695\n",
            "Round: 1122 Weight: [2.49103666 1.31558927] Bias: -1.1053673926544583 loss: 0.3341835682747102\n",
            "Round: 1123 Weight: [2.49119491 1.31567099] Bias: -1.1054272963980754 loss: 0.33418321379894445\n",
            "Round: 1124 Weight: [2.49135276 1.31575251] Bias: -1.10548704556034 loss: 0.3341828611390511\n",
            "Round: 1125 Weight: [2.4915102  1.31583382] Bias: -1.105546640565447 loss: 0.33418251028546214\n",
            "Round: 1126 Weight: [2.49166724 1.31591491] Bias: -1.105606081836295 loss: 0.3341821612286614\n",
            "Round: 1127 Weight: [2.49182388 1.3159958 ] Bias: -1.105665369794491 loss: 0.3341818139591855\n",
            "Round: 1128 Weight: [2.49198011 1.31607649] Bias: -1.1057245048603557 loss: 0.33418146846762253\n",
            "Round: 1129 Weight: [2.49213595 1.31615696] Bias: -1.1057834874529278 loss: 0.33418112474461237\n",
            "Round: 1130 Weight: [2.49229139 1.31623723] Bias: -1.1058423179899681 loss: 0.33418078278084606\n",
            "Round: 1131 Weight: [2.49244643 1.3163173 ] Bias: -1.1059009968879652 loss: 0.3341804425670656\n",
            "Round: 1132 Weight: [2.49260107 1.31639716] Bias: -1.1059595245621388 loss: 0.33418010409406357\n",
            "Round: 1133 Weight: [2.49275532 1.31647681] Bias: -1.1060179014264448 loss: 0.3341797673526832\n",
            "Round: 1134 Weight: [2.49290917 1.31655626] Bias: -1.1060761278935802 loss: 0.3341794323338176\n",
            "Round: 1135 Weight: [2.49306263 1.31663551] Bias: -1.106134204374987 loss: 0.3341790990284098\n",
            "Round: 1136 Weight: [2.49321569 1.31671455] Bias: -1.106192131280857 loss: 0.33417876742745223\n",
            "Round: 1137 Weight: [2.49336837 1.3167934 ] Bias: -1.1062499090201354 loss: 0.3341784375219865\n",
            "Round: 1138 Weight: [2.49352065 1.31687204] Bias: -1.1063075380005272 loss: 0.3341781093031034\n",
            "Round: 1139 Weight: [2.49367255 1.31695048] Bias: -1.1063650186284992 loss: 0.3341777827619423\n",
            "Round: 1140 Weight: [2.49382405 1.31702871] Bias: -1.1064223513092866 loss: 0.33417745788969083\n",
            "Round: 1141 Weight: [2.49397517 1.31710675] Bias: -1.1064795364468956 loss: 0.3341771346775848\n",
            "Round: 1142 Weight: [2.49412591 1.31718459] Bias: -1.1065365744441087 loss: 0.33417681311690783\n",
            "Round: 1143 Weight: [2.49427626 1.31726223] Bias: -1.1065934657024892 loss: 0.3341764931989911\n",
            "Round: 1144 Weight: [2.49442622 1.31733967] Bias: -1.1066502106223848 loss: 0.3341761749152132\n",
            "Round: 1145 Weight: [2.4945758  1.31741691] Bias: -1.1067068096029324 loss: 0.33417585825699947\n",
            "Round: 1146 Weight: [2.494725   1.31749396] Bias: -1.1067632630420623 loss: 0.33417554321582216\n",
            "Round: 1147 Weight: [2.49487382 1.31757081] Bias: -1.1068195713365023 loss: 0.33417522978319997\n",
            "Round: 1148 Weight: [2.49502226 1.31764746] Bias: -1.1068757348817824 loss: 0.3341749179506979\n",
            "Round: 1149 Weight: [2.49517032 1.31772392] Bias: -1.1069317540722383 loss: 0.33417460770992674\n",
            "Round: 1150 Weight: [2.495318   1.31780018] Bias: -1.1069876293010166 loss: 0.3341742990525429\n",
            "Round: 1151 Weight: [2.4954653  1.31787624] Bias: -1.1070433609600776 loss: 0.33417399197024833\n",
            "Round: 1152 Weight: [2.49561223 1.31795211] Bias: -1.107098949440201 loss: 0.33417368645479023\n",
            "Round: 1153 Weight: [2.49575878 1.31802779] Bias: -1.107154395130989 loss: 0.3341733824979603\n",
            "Round: 1154 Weight: [2.49590496 1.31810328] Bias: -1.1072096984208708 loss: 0.3341730800915953\n",
            "Round: 1155 Weight: [2.49605077 1.31817857] Bias: -1.1072648596971069 loss: 0.3341727792275764\n",
            "Round: 1156 Weight: [2.4961962  1.31825367] Bias: -1.1073198793457928 loss: 0.3341724798978284\n",
            "Round: 1157 Weight: [2.49634127 1.31832858] Bias: -1.1073747577518633 loss: 0.3341721820943204\n",
            "Round: 1158 Weight: [2.49648596 1.31840329] Bias: -1.107429495299097 loss: 0.3341718858090652\n",
            "Round: 1159 Weight: [2.49663029 1.31847782] Bias: -1.1074840923701195 loss: 0.3341715910341185\n",
            "Round: 1160 Weight: [2.49677425 1.31855215] Bias: -1.1075385493464076 loss: 0.3341712977615796\n",
            "Round: 1161 Weight: [2.49691784 1.3186263 ] Bias: -1.1075928666082944 loss: 0.3341710059835904\n",
            "Round: 1162 Weight: [2.49706106 1.31870026] Bias: -1.1076470445349718 loss: 0.33417071569233564\n",
            "Round: 1163 Weight: [2.49720392 1.31877403] Bias: -1.1077010835044954 loss: 0.3341704268800422\n",
            "Round: 1164 Weight: [2.49734642 1.31884761] Bias: -1.1077549838937881 loss: 0.33417013953897945\n",
            "Round: 1165 Weight: [2.49748855 1.318921  ] Bias: -1.1078087460786443 loss: 0.33416985366145835\n",
            "Round: 1166 Weight: [2.49763032 1.3189942 ] Bias: -1.1078623704337338 loss: 0.33416956923983177\n",
            "Round: 1167 Weight: [2.49777173 1.31906722] Bias: -1.1079158573326056 loss: 0.3341692862664937\n",
            "Round: 1168 Weight: [2.49791278 1.31914005] Bias: -1.1079692071476916 loss: 0.33416900473387984\n",
            "Round: 1169 Weight: [2.49805347 1.3192127 ] Bias: -1.108022420250311 loss: 0.33416872463446634\n",
            "Round: 1170 Weight: [2.4981938  1.31928516] Bias: -1.1080754970106739 loss: 0.3341684459607704\n",
            "Round: 1171 Weight: [2.49833377 1.31935744] Bias: -1.1081284377978846 loss: 0.33416816870534943\n",
            "Round: 1172 Weight: [2.49847339 1.31942953] Bias: -1.1081812429799467 loss: 0.33416789286080145\n",
            "Round: 1173 Weight: [2.49861265 1.31950144] Bias: -1.108233912923766 loss: 0.3341676184197644\n",
            "Round: 1174 Weight: [2.49875156 1.31957317] Bias: -1.108286447995154 loss: 0.334167345374916\n",
            "Round: 1175 Weight: [2.49889012 1.31964471] Bias: -1.1083388485588326 loss: 0.33416707371897336\n",
            "Round: 1176 Weight: [2.49902832 1.31971607] Bias: -1.1083911149784376 loss: 0.33416680344469346\n",
            "Round: 1177 Weight: [2.49916617 1.31978725] Bias: -1.1084432476165218 loss: 0.33416653454487183\n",
            "Round: 1178 Weight: [2.49930367 1.31985825] Bias: -1.10849524683456 loss: 0.3341662670123434\n",
            "Round: 1179 Weight: [2.49944082 1.31992907] Bias: -1.108547112992951 loss: 0.33416600083998144\n",
            "Round: 1180 Weight: [2.49957763 1.31999971] Bias: -1.1085988464510232 loss: 0.33416573602069793\n",
            "Round: 1181 Weight: [2.49971408 1.32007017] Bias: -1.108650447567037 loss: 0.334165472547443\n",
            "Round: 1182 Weight: [2.49985019 1.32014044] Bias: -1.1087019166981884 loss: 0.3341652104132049\n",
            "Round: 1183 Weight: [2.49998595 1.32021054] Bias: -1.108753254200614 loss: 0.33416494961100957\n",
            "Round: 1184 Weight: [2.50012137 1.32028047] Bias: -1.1088044604293932 loss: 0.33416469013392064\n",
            "Round: 1185 Weight: [2.50025644 1.32035021] Bias: -1.1088555357385526 loss: 0.3341644319750394\n",
            "Round: 1186 Weight: [2.50039117 1.32041977] Bias: -1.108906480481069 loss: 0.33416417512750374\n",
            "Round: 1187 Weight: [2.50052556 1.32048916] Bias: -1.1089572950088742 loss: 0.33416391958448904\n",
            "Round: 1188 Weight: [2.5006596  1.32055838] Bias: -1.109007979672857 loss: 0.3341636653392074\n",
            "Round: 1189 Weight: [2.50079331 1.32062741] Bias: -1.1090585348228679 loss: 0.33416341238490704\n",
            "Round: 1190 Weight: [2.50092667 1.32069628] Bias: -1.1091089608077225 loss: 0.334163160714873\n",
            "Round: 1191 Weight: [2.5010597  1.32076496] Bias: -1.1091592579752048 loss: 0.3341629103224265\n",
            "Round: 1192 Weight: [2.50119239 1.32083347] Bias: -1.1092094266720707 loss: 0.3341626612009243\n",
            "Round: 1193 Weight: [2.50132474 1.32090181] Bias: -1.1092594672440517 loss: 0.33416241334375923\n",
            "Round: 1194 Weight: [2.50145676 1.32096998] Bias: -1.1093093800358582 loss: 0.33416216674435956\n",
            "Round: 1195 Weight: [2.50158844 1.32103797] Bias: -1.1093591653911832 loss: 0.33416192139618883\n",
            "Round: 1196 Weight: [2.50171979 1.32110578] Bias: -1.1094088236527055 loss: 0.3341616772927459\n",
            "Round: 1197 Weight: [2.5018508  1.32117343] Bias: -1.1094583551620938 loss: 0.33416143442756435\n",
            "Round: 1198 Weight: [2.50198148 1.3212409 ] Bias: -1.1095077602600092 loss: 0.3341611927942128\n",
            "Round: 1199 Weight: [2.50211183 1.32130821] Bias: -1.1095570392861092 loss: 0.33416095238629406\n",
            "Round: 1200 Weight: [2.50224185 1.32137534] Bias: -1.1096061925790512 loss: 0.33416071319744567\n",
            "Round: 1201 Weight: [2.50237154 1.3214423 ] Bias: -1.1096552204764956 loss: 0.3341604752213389\n",
            "Round: 1202 Weight: [2.5025009  1.32150909] Bias: -1.1097041233151093 loss: 0.3341602384516795\n",
            "Round: 1203 Weight: [2.50262994 1.32157571] Bias: -1.109752901430569 loss: 0.33416000288220665\n",
            "Round: 1204 Weight: [2.50275864 1.32164217] Bias: -1.1098015551575646 loss: 0.33415976850669316\n",
            "Round: 1205 Weight: [2.50288702 1.32170845] Bias: -1.109850084829803 loss: 0.3341595353189453\n",
            "Round: 1206 Weight: [2.50301508 1.32177457] Bias: -1.1098984907800102 loss: 0.3341593033128026\n",
            "Round: 1207 Weight: [2.50314281 1.32184052] Bias: -1.1099467733399364 loss: 0.33415907248213755\n",
            "Round: 1208 Weight: [2.50327021 1.3219063 ] Bias: -1.1099949328403578 loss: 0.33415884282085556\n",
            "Round: 1209 Weight: [2.5033973  1.32197191] Bias: -1.1100429696110803 loss: 0.33415861432289434\n",
            "Round: 1210 Weight: [2.50352406 1.32203736] Bias: -1.110090883980943 loss: 0.33415838698222494\n",
            "Round: 1211 Weight: [2.5036505  1.32210264] Bias: -1.1101386762778216 loss: 0.3341581607928495\n",
            "Round: 1212 Weight: [2.50377662 1.32216776] Bias: -1.110186346828631 loss: 0.33415793574880337\n",
            "Round: 1213 Weight: [2.50390242 1.32223271] Bias: -1.1102338959593296 loss: 0.33415771184415327\n",
            "Round: 1214 Weight: [2.5040279 1.3222975] Bias: -1.1102813239949212 loss: 0.33415748907299764\n",
            "Round: 1215 Weight: [2.50415306 1.32236212] Bias: -1.1103286312594594 loss: 0.33415726742946666\n",
            "Round: 1216 Weight: [2.50427791 1.32242658] Bias: -1.1103758180760497 loss: 0.3341570469077219\n",
            "Round: 1217 Weight: [2.50440244 1.32249088] Bias: -1.1104228847668538 loss: 0.3341568275019563\n",
            "Round: 1218 Weight: [2.50452666 1.32255501] Bias: -1.110469831653092 loss: 0.33415660920639345\n",
            "Round: 1219 Weight: [2.50465056 1.32261898] Bias: -1.110516659055047 loss: 0.33415639201528824\n",
            "Round: 1220 Weight: [2.50477415 1.32268279] Bias: -1.110563367292066 loss: 0.33415617592292585\n",
            "Round: 1221 Weight: [2.50489742 1.32274643] Bias: -1.110609956682565 loss: 0.3341559609236225\n",
            "Round: 1222 Weight: [2.50502039 1.32280992] Bias: -1.110656427544031 loss: 0.334155747011724\n",
            "Round: 1223 Weight: [2.50514304 1.32287325] Bias: -1.1107027801930258 loss: 0.3341555341816075\n",
            "Round: 1224 Weight: [2.50526538 1.32293641] Bias: -1.1107490149451889 loss: 0.334155322427679\n",
            "Round: 1225 Weight: [2.50538741 1.32299941] Bias: -1.11079513211524 loss: 0.33415511174437496\n",
            "Round: 1226 Weight: [2.50550914 1.32306226] Bias: -1.1108411320169835 loss: 0.3341549021261616\n",
            "Round: 1227 Weight: [2.50563055 1.32312495] Bias: -1.1108870149633097 loss: 0.3341546935675344\n",
            "Round: 1228 Weight: [2.50575166 1.32318747] Bias: -1.110932781266199 loss: 0.3341544860630183\n",
            "Round: 1229 Weight: [2.50587247 1.32324984] Bias: -1.1109784312367252 loss: 0.33415427960716737\n",
            "Round: 1230 Weight: [2.50599297 1.32331205] Bias: -1.1110239651850575 loss: 0.3341540741945648\n",
            "Round: 1231 Weight: [2.50611316 1.32337411] Bias: -1.1110693834204644 loss: 0.3341538698198225\n",
            "Round: 1232 Weight: [2.50623305 1.32343601] Bias: -1.111114686251316 loss: 0.33415366647758143\n",
            "Round: 1233 Weight: [2.50635263 1.32349775] Bias: -1.1111598739850874 loss: 0.33415346416251074\n",
            "Round: 1234 Weight: [2.50647192 1.32355933] Bias: -1.111204946928362 loss: 0.3341532628693082\n",
            "Round: 1235 Weight: [2.5065909  1.32362076] Bias: -1.1112499053868339 loss: 0.3341530625926996\n",
            "Round: 1236 Weight: [2.50670959 1.32368203] Bias: -1.1112947496653107 loss: 0.33415286332743915\n",
            "Round: 1237 Weight: [2.50682797 1.32374315] Bias: -1.1113394800677172 loss: 0.3341526650683086\n",
            "Round: 1238 Weight: [2.50694605 1.32380412] Bias: -1.1113840968970976 loss: 0.3341524678101177\n",
            "Round: 1239 Weight: [2.50706384 1.32386493] Bias: -1.1114286004556189 loss: 0.33415227154770366\n",
            "Round: 1240 Weight: [2.50718133 1.32392558] Bias: -1.1114729910445733 loss: 0.33415207627593124\n",
            "Round: 1241 Weight: [2.50729852 1.32398608] Bias: -1.111517268964382 loss: 0.3341518819896926\n",
            "Round: 1242 Weight: [2.50741541 1.32404643] Bias: -1.1115614345145968 loss: 0.3341516886839068\n",
            "Round: 1243 Weight: [2.50753201 1.32410663] Bias: -1.1116054879939044 loss: 0.3341514963535202\n",
            "Round: 1244 Weight: [2.50764832 1.32416668] Bias: -1.1116494297001278 loss: 0.33415130499350576\n",
            "Round: 1245 Weight: [2.50776433 1.32422657] Bias: -1.1116932599302303 loss: 0.3341511145988632\n",
            "Round: 1246 Weight: [2.50788005 1.32428632] Bias: -1.111736978980318 loss: 0.3341509251646191\n",
            "Round: 1247 Weight: [2.50799548 1.32434591] Bias: -1.111780587145642 loss: 0.33415073668582596\n",
            "Round: 1248 Weight: [2.50811062 1.32440535] Bias: -1.1118240847206027 loss: 0.33415054915756276\n",
            "Round: 1249 Weight: [2.50822546 1.32446464] Bias: -1.1118674719987505 loss: 0.3341503625749348\n",
            "Round: 1250 Weight: [2.50834002 1.32452378] Bias: -1.1119107492727904 loss: 0.3341501769330731\n",
            "Round: 1251 Weight: [2.50845429 1.32458277] Bias: -1.1119539168345842 loss: 0.33414999222713465\n",
            "Round: 1252 Weight: [2.50856827 1.32464162] Bias: -1.111996974975153 loss: 0.3341498084523018\n",
            "Round: 1253 Weight: [2.50868196 1.32470031] Bias: -1.1120399239846803 loss: 0.33414962560378303\n",
            "Round: 1254 Weight: [2.50879537 1.32475886] Bias: -1.1120827641525146 loss: 0.3341494436768117\n",
            "Round: 1255 Weight: [2.50890849 1.32481726] Bias: -1.1121254957671718 loss: 0.3341492626666468\n",
            "Round: 1256 Weight: [2.50902132 1.32487551] Bias: -1.1121681191163386 loss: 0.3341490825685722\n",
            "Round: 1257 Weight: [2.50913387 1.32493362] Bias: -1.112210634486875 loss: 0.3341489033778967\n",
            "Round: 1258 Weight: [2.50924614 1.32499157] Bias: -1.1122530421648167 loss: 0.33414872508995425\n",
            "Round: 1259 Weight: [2.50935812 1.32504939] Bias: -1.1122953424353779 loss: 0.3341485477001033\n",
            "Round: 1260 Weight: [2.50946982 1.32510705] Bias: -1.1123375355829543 loss: 0.3341483712037269\n",
            "Round: 1261 Weight: [2.50958124 1.32516457] Bias: -1.1123796218911257 loss: 0.33414819559623254\n",
            "Round: 1262 Weight: [2.50969238 1.32522195] Bias: -1.112421601642658 loss: 0.3341480208730522\n",
            "Round: 1263 Weight: [2.50980324 1.32527918] Bias: -1.1124634751195068 loss: 0.3341478470296416\n",
            "Round: 1264 Weight: [2.50991382 1.32533627] Bias: -1.1125052426028195 loss: 0.3341476740614808\n",
            "Round: 1265 Weight: [2.51002413 1.32539321] Bias: -1.112546904372938 loss: 0.33414750196407383\n",
            "Round: 1266 Weight: [2.51013415 1.32545001] Bias: -1.1125884607094014 loss: 0.3341473307329485\n",
            "Round: 1267 Weight: [2.5102439  1.32550667] Bias: -1.1126299118909488 loss: 0.3341471603636558\n",
            "Round: 1268 Weight: [2.51035337 1.32556318] Bias: -1.1126712581955214 loss: 0.33414699085177085\n",
            "Round: 1269 Weight: [2.51046256 1.32561955] Bias: -1.1127124999002656 loss: 0.3341468221928918\n",
            "Round: 1270 Weight: [2.51057148 1.32567578] Bias: -1.112753637281535 loss: 0.3341466543826402\n",
            "Round: 1271 Weight: [2.51068013 1.32573187] Bias: -1.112794670614894 loss: 0.3341464874166605\n",
            "Round: 1272 Weight: [2.5107885  1.32578782] Bias: -1.112835600175119 loss: 0.33414632129062044\n",
            "Round: 1273 Weight: [2.5108966  1.32584362] Bias: -1.112876426236202 loss: 0.3341461560002104\n",
            "Round: 1274 Weight: [2.51100443 1.32589929] Bias: -1.1129171490713532 loss: 0.3341459915411437\n",
            "Round: 1275 Weight: [2.51111199 1.32595481] Bias: -1.1129577689530024 loss: 0.3341458279091562\n",
            "Round: 1276 Weight: [2.51121927 1.3260102 ] Bias: -1.1129982861528027 loss: 0.33414566510000626\n",
            "Round: 1277 Weight: [2.51132629 1.32606544] Bias: -1.1130387009416325 loss: 0.3341455031094745\n",
            "Round: 1278 Weight: [2.51143304 1.32612055] Bias: -1.113079013589598 loss: 0.3341453419333639\n",
            "Round: 1279 Weight: [2.51153951 1.32617552] Bias: -1.113119224366036 loss: 0.33414518156749956\n",
            "Round: 1280 Weight: [2.51164572 1.32623035] Bias: -1.1131593335395158 loss: 0.33414502200772883\n",
            "Round: 1281 Weight: [2.51175167 1.32628504] Bias: -1.1131993413778423 loss: 0.33414486324992043\n",
            "Round: 1282 Weight: [2.51185735 1.32633959] Bias: -1.113239248148058 loss: 0.3341447052899652\n",
            "Round: 1283 Weight: [2.51196276 1.32639401] Bias: -1.113279054116446 loss: 0.33414454812377564\n",
            "Round: 1284 Weight: [2.5120679  1.32644829] Bias: -1.1133187595485319 loss: 0.33414439174728555\n",
            "Round: 1285 Weight: [2.51217279 1.32650243] Bias: -1.1133583647090863 loss: 0.33414423615645045\n",
            "Round: 1286 Weight: [2.51227741 1.32655644] Bias: -1.1133978698621279 loss: 0.3341440813472468\n",
            "Round: 1287 Weight: [2.51238176 1.32661031] Bias: -1.1134372752709247 loss: 0.3341439273156726\n",
            "Round: 1288 Weight: [2.51248586 1.32666405] Bias: -1.1134765811979976 loss: 0.3341437740577467\n",
            "Round: 1289 Weight: [2.51258969 1.32671765] Bias: -1.113515787905122 loss: 0.3341436215695089\n",
            "Round: 1290 Weight: [2.51269326 1.32677111] Bias: -1.113554895653331 loss: 0.33414346984701987\n",
            "Round: 1291 Weight: [2.51279657 1.32682444] Bias: -1.1135939047029166 loss: 0.33414331888636106\n",
            "Round: 1292 Weight: [2.51289962 1.32687764] Bias: -1.1136328153134332 loss: 0.3341431686836343\n",
            "Round: 1293 Weight: [2.51300242 1.32693071] Bias: -1.1136716277436993 loss: 0.33414301923496237\n",
            "Round: 1294 Weight: [2.51310495 1.32698364] Bias: -1.1137103422518004 loss: 0.33414287053648795\n",
            "Round: 1295 Weight: [2.51320723 1.32703643] Bias: -1.1137489590950909 loss: 0.3341427225843741\n",
            "Round: 1296 Weight: [2.51330925 1.3270891 ] Bias: -1.1137874785301962 loss: 0.3341425753748044\n",
            "Round: 1297 Weight: [2.51341101 1.32714163] Bias: -1.113825900813016 loss: 0.334142428903982\n",
            "Round: 1298 Weight: [2.51351252 1.32719403] Bias: -1.1138642261987257 loss: 0.33414228316813016\n",
            "Round: 1299 Weight: [2.51361378 1.3272463 ] Bias: -1.1139024549417789 loss: 0.33414213816349203\n",
            "Round: 1300 Weight: [2.51371478 1.32729844] Bias: -1.11394058729591 loss: 0.3341419938863306\n",
            "Round: 1301 Weight: [2.51381552 1.32735044] Bias: -1.1139786235141365 loss: 0.33414185033292804\n",
            "Round: 1302 Weight: [2.51391602 1.32740232] Bias: -1.1140165638487605 loss: 0.33414170749958666\n",
            "Round: 1303 Weight: [2.51401626 1.32745407] Bias: -1.1140544085513724 loss: 0.33414156538262757\n",
            "Round: 1304 Weight: [2.51411625 1.32750568] Bias: -1.1140921578728518 loss: 0.33414142397839164\n",
            "Round: 1305 Weight: [2.51421599 1.32755717] Bias: -1.1141298120633705 loss: 0.3341412832832385\n",
            "Round: 1306 Weight: [2.51431548 1.32760852] Bias: -1.1141673713723945 loss: 0.3341411432935472\n",
            "Round: 1307 Weight: [2.51441471 1.32765975] Bias: -1.1142048360486865 loss: 0.33414100400571584\n",
            "Round: 1308 Weight: [2.5145137  1.32771085] Bias: -1.1142422063403077 loss: 0.33414086541616095\n",
            "Round: 1309 Weight: [2.51461245 1.32776182] Bias: -1.1142794824946205 loss: 0.3341407275213182\n",
            "Round: 1310 Weight: [2.51471094 1.32781267] Bias: -1.1143166647582903 loss: 0.3341405903176421\n",
            "Round: 1311 Weight: [2.51480919 1.32786338] Bias: -1.1143537533772878 loss: 0.3341404538016051\n",
            "Round: 1312 Weight: [2.51490719 1.32791397] Bias: -1.1143907485968918 loss: 0.33414031796969873\n",
            "Round: 1313 Weight: [2.51500495 1.32796443] Bias: -1.1144276506616906 loss: 0.3341401828184328\n",
            "Round: 1314 Weight: [2.51510246 1.32801477] Bias: -1.1144644598155842 loss: 0.3341400483443349\n",
            "Round: 1315 Weight: [2.51519972 1.32806498] Bias: -1.1145011763017874 loss: 0.3341399145439515\n",
            "Round: 1316 Weight: [2.51529675 1.32811506] Bias: -1.1145378003628306 loss: 0.33413978141384654\n",
            "Round: 1317 Weight: [2.51539352 1.32816502] Bias: -1.1145743322405632 loss: 0.3341396489506024\n",
            "Round: 1318 Weight: [2.51549006 1.32821485] Bias: -1.1146107721761553 loss: 0.33413951715081897\n",
            "Round: 1319 Weight: [2.51558636 1.32826455] Bias: -1.1146471204100994 loss: 0.33413938601111437\n",
            "Round: 1320 Weight: [2.51568241 1.32831414] Bias: -1.114683377182213 loss: 0.33413925552812385\n",
            "Round: 1321 Weight: [2.51577822 1.3283636 ] Bias: -1.114719542731641 loss: 0.3341391256985007\n",
            "Round: 1322 Weight: [2.5158738  1.32841293] Bias: -1.1147556172968571 loss: 0.33413899651891543\n",
            "Round: 1323 Weight: [2.51596913 1.32846214] Bias: -1.1147916011156664 loss: 0.33413886798605613\n",
            "Round: 1324 Weight: [2.51606422 1.32851123] Bias: -1.1148274944252077 loss: 0.33413874009662803\n",
            "Round: 1325 Weight: [2.51615908 1.32856019] Bias: -1.1148632974619546 loss: 0.3341386128473537\n",
            "Round: 1326 Weight: [2.5162537  1.32860903] Bias: -1.114899010461719 loss: 0.33413848623497294\n",
            "Round: 1327 Weight: [2.51634808 1.32865775] Bias: -1.114934633659652 loss: 0.3341383602562422\n",
            "Round: 1328 Weight: [2.51644223 1.32870635] Bias: -1.1149701672902468 loss: 0.3341382349079352\n",
            "Round: 1329 Weight: [2.51653614 1.32875482] Bias: -1.11500561158734 loss: 0.3341381101868425\n",
            "Round: 1330 Weight: [2.51662981 1.32880318] Bias: -1.1150409667841144 loss: 0.3341379860897711\n",
            "Round: 1331 Weight: [2.51672325 1.32885141] Bias: -1.1150762331131003 loss: 0.334137862613545\n",
            "Round: 1332 Weight: [2.51681646 1.32889952] Bias: -1.1151114108061786 loss: 0.3341377397550047\n",
            "Round: 1333 Weight: [2.51690943 1.32894751] Bias: -1.1151465000945817 loss: 0.3341376175110069\n",
            "Round: 1334 Weight: [2.51700218 1.32899538] Bias: -1.1151815012088961 loss: 0.3341374958784252\n",
            "Round: 1335 Weight: [2.51709468 1.32904314] Bias: -1.1152164143790646 loss: 0.33413737485414896\n",
            "Round: 1336 Weight: [2.51718696 1.32909077] Bias: -1.1152512398343877 loss: 0.3341372544350842\n",
            "Round: 1337 Weight: [2.51727901 1.32913828] Bias: -1.115285977803526 loss: 0.33413713461815275\n",
            "Round: 1338 Weight: [2.51737082 1.32918567] Bias: -1.1153206285145025 loss: 0.3341370154002928\n",
            "Round: 1339 Weight: [2.51746241 1.32923295] Bias: -1.115355192194704 loss: 0.33413689677845815\n",
            "Round: 1340 Weight: [2.51755377 1.3292801 ] Bias: -1.1153896690708833 loss: 0.33413677874961856\n",
            "Round: 1341 Weight: [2.5176449  1.32932714] Bias: -1.1154240593691616 loss: 0.33413666131075986\n",
            "Round: 1342 Weight: [2.5177358  1.32937406] Bias: -1.1154583633150295 loss: 0.3341365444588833\n",
            "Round: 1343 Weight: [2.51782647 1.32942087] Bias: -1.1154925811333498 loss: 0.33413642819100575\n",
            "Round: 1344 Weight: [2.51791692 1.32946755] Bias: -1.1155267130483597 loss: 0.33413631250415954\n",
            "Round: 1345 Weight: [2.51800714 1.32951412] Bias: -1.1155607592836714 loss: 0.33413619739539274\n",
            "Round: 1346 Weight: [2.51809714 1.32956058] Bias: -1.1155947200622756 loss: 0.33413608286176877\n",
            "Round: 1347 Weight: [2.51818691 1.32960691] Bias: -1.1156285956065422 loss: 0.3341359689003658\n",
            "Round: 1348 Weight: [2.51827645 1.32965313] Bias: -1.115662386138223 loss: 0.33413585550827796\n",
            "Round: 1349 Weight: [2.51836577 1.32969924] Bias: -1.1156960918784538 loss: 0.3341357426826137\n",
            "Round: 1350 Weight: [2.51845487 1.32974523] Bias: -1.1157297130477553 loss: 0.3341356304204972\n",
            "Round: 1351 Weight: [2.51854375 1.32979111] Bias: -1.1157632498660357 loss: 0.3341355187190672\n",
            "Round: 1352 Weight: [2.5186324  1.32983687] Bias: -1.1157967025525926 loss: 0.33413540757547755\n",
            "Round: 1353 Weight: [2.51872084 1.32988251] Bias: -1.115830071326115 loss: 0.33413529698689665\n",
            "Round: 1354 Weight: [2.51880905 1.32992804] Bias: -1.1158633564046843 loss: 0.33413518695050776\n",
            "Round: 1355 Weight: [2.51889704 1.32997346] Bias: -1.1158965580057778 loss: 0.3341350774635086\n",
            "Round: 1356 Weight: [2.51898481 1.33001877] Bias: -1.115929676346269 loss: 0.33413496852311186\n",
            "Round: 1357 Weight: [2.51907237 1.33006396] Bias: -1.1159627116424302 loss: 0.33413486012654425\n",
            "Round: 1358 Weight: [2.5191597  1.33010904] Bias: -1.1159956641099344 loss: 0.334134752271047\n",
            "Round: 1359 Weight: [2.51924682 1.330154  ] Bias: -1.116028533963857 loss: 0.33413464495387607\n",
            "Round: 1360 Weight: [2.51933371 1.33019886] Bias: -1.1160613214186774 loss: 0.3341345381723011\n",
            "Round: 1361 Weight: [2.51942039 1.3302436 ] Bias: -1.1160940266882815 loss: 0.334134431923606\n",
            "Round: 1362 Weight: [2.51950686 1.33028823] Bias: -1.1161266499859626 loss: 0.3341343262050892\n",
            "Round: 1363 Weight: [2.51959311 1.33033274] Bias: -1.1161591915244242 loss: 0.3341342210140625\n",
            "Round: 1364 Weight: [2.51967914 1.33037715] Bias: -1.1161916515157813 loss: 0.33413411634785223\n",
            "Round: 1365 Weight: [2.51976496 1.33042145] Bias: -1.116224030171562 loss: 0.33413401220379846\n",
            "Round: 1366 Weight: [2.51985057 1.33046563] Bias: -1.11625632770271 loss: 0.33413390857925473\n",
            "Round: 1367 Weight: [2.51993596 1.33050971] Bias: -1.1162885443195856 loss: 0.3341338054715885\n",
            "Round: 1368 Weight: [2.52002114 1.33055367] Bias: -1.116320680231968 loss: 0.3341337028781811\n",
            "Round: 1369 Weight: [2.5201061  1.33059753] Bias: -1.1163527356490572 loss: 0.3341336007964271\n",
            "Round: 1370 Weight: [2.52019085 1.33064127] Bias: -1.1163847107794753 loss: 0.3341334992237348\n",
            "Round: 1371 Weight: [2.5202754  1.33068491] Bias: -1.1164166058312686 loss: 0.33413339815752574\n",
            "Round: 1372 Weight: [2.52035973 1.33072844] Bias: -1.1164484210119092 loss: 0.3341332975952348\n",
            "Round: 1373 Weight: [2.52044385 1.33077186] Bias: -1.116480156528297 loss: 0.3341331975343104\n",
            "Round: 1374 Weight: [2.52052776 1.33081517] Bias: -1.116511812586761 loss: 0.33413309797221413\n",
            "Round: 1375 Weight: [2.52061146 1.33085837] Bias: -1.1165433893930616 loss: 0.33413299890642045\n",
            "Round: 1376 Weight: [2.52069495 1.33090146] Bias: -1.1165748871523924 loss: 0.334132900334417\n",
            "Round: 1377 Weight: [2.52077824 1.33094445] Bias: -1.116606306069381 loss: 0.33413280225370473\n",
            "Round: 1378 Weight: [2.52086132 1.33098733] Bias: -1.1166376463480916 loss: 0.33413270466179706\n",
            "Round: 1379 Weight: [2.52094419 1.3310301 ] Bias: -1.1166689081920267 loss: 0.3341326075562206\n",
            "Round: 1380 Weight: [2.52102685 1.33107277] Bias: -1.1167000918041283 loss: 0.33413251093451474\n",
            "Round: 1381 Weight: [2.52110931 1.33111533] Bias: -1.1167311973867802 loss: 0.3341324147942314\n",
            "Round: 1382 Weight: [2.52119156 1.33115778] Bias: -1.1167622251418092 loss: 0.33413231913293534\n",
            "Round: 1383 Weight: [2.5212736  1.33120013] Bias: -1.1167931752704872 loss: 0.33413222394820363\n",
            "Round: 1384 Weight: [2.52135545 1.33124237] Bias: -1.1168240479735323 loss: 0.3341321292376264\n",
            "Round: 1385 Weight: [2.52143709 1.33128451] Bias: -1.1168548434511114 loss: 0.3341320349988057\n",
            "Round: 1386 Weight: [2.52151852 1.33132654] Bias: -1.116885561902841 loss: 0.33413194122935647\n",
            "Round: 1387 Weight: [2.52159975 1.33136847] Bias: -1.1169162035277898 loss: 0.33413184792690537\n",
            "Round: 1388 Weight: [2.52168078 1.33141029] Bias: -1.116946768524479 loss: 0.33413175508909176\n",
            "Round: 1389 Weight: [2.52176161 1.33145201] Bias: -1.1169772570908854 loss: 0.33413166271356726\n",
            "Round: 1390 Weight: [2.52184223 1.33149362] Bias: -1.1170076694244424 loss: 0.33413157079799516\n",
            "Round: 1391 Weight: [2.52192266 1.33153513] Bias: -1.1170380057220415 loss: 0.3341314793400515\n",
            "Round: 1392 Weight: [2.52200288 1.33157654] Bias: -1.1170682661800342 loss: 0.3341313883374234\n",
            "Round: 1393 Weight: [2.52208291 1.33161784] Bias: -1.1170984509942337 loss: 0.33413129778781087\n",
            "Round: 1394 Weight: [2.52216274 1.33165904] Bias: -1.1171285603599161 loss: 0.33413120768892524\n",
            "Round: 1395 Weight: [2.52224236 1.33170014] Bias: -1.117158594471823 loss: 0.33413111803848977\n",
            "Round: 1396 Weight: [2.52232179 1.33174114] Bias: -1.1171885535241617 loss: 0.33413102883423934\n",
            "Round: 1397 Weight: [2.52240102 1.33178203] Bias: -1.117218437710608 loss: 0.33413094007392097\n",
            "Round: 1398 Weight: [2.52248006 1.33182282] Bias: -1.1172482472243073 loss: 0.3341308517552927\n",
            "Round: 1399 Weight: [2.52255889 1.33186351] Bias: -1.1172779822578764 loss: 0.33413076387612456\n",
            "Round: 1400 Weight: [2.52263753 1.3319041 ] Bias: -1.117307643003405 loss: 0.33413067643419786\n",
            "Round: 1401 Weight: [2.52271598 1.33194459] Bias: -1.117337229652457 loss: 0.3341305894273055\n",
            "Round: 1402 Weight: [2.52279423 1.33198497] Bias: -1.117366742396073 loss: 0.3341305028532516\n",
            "Round: 1403 Weight: [2.52287228 1.33202526] Bias: -1.1173961814247704 loss: 0.3341304167098518\n",
            "Round: 1404 Weight: [2.52295014 1.33206545] Bias: -1.1174255469285468 loss: 0.3341303309949328\n",
            "Round: 1405 Weight: [2.52302781 1.33210553] Bias: -1.11745483909688 loss: 0.33413024570633254\n",
            "Round: 1406 Weight: [2.52310528 1.33214552] Bias: -1.1174840581187302 loss: 0.33413016084190034\n",
            "Round: 1407 Weight: [2.52318256 1.3321854 ] Bias: -1.117513204182542 loss: 0.33413007639949605\n",
            "Round: 1408 Weight: [2.52325965 1.33222519] Bias: -1.1175422774762451 loss: 0.33412999237699115\n",
            "Round: 1409 Weight: [2.52333655 1.33226488] Bias: -1.1175712781872564 loss: 0.3341299087722679\n",
            "Round: 1410 Weight: [2.52341325 1.33230447] Bias: -1.1176002065024813 loss: 0.3341298255832191\n",
            "Round: 1411 Weight: [2.52348977 1.33234396] Bias: -1.1176290626083154 loss: 0.3341297428077488\n",
            "Round: 1412 Weight: [2.52356609 1.33238335] Bias: -1.1176578466906462 loss: 0.33412966044377196\n",
            "Round: 1413 Weight: [2.52364223 1.33242264] Bias: -1.117686558934854 loss: 0.3341295784892136\n",
            "Round: 1414 Weight: [2.52371817 1.33246184] Bias: -1.117715199525814 loss: 0.33412949694201016\n",
            "Round: 1415 Weight: [2.52379393 1.33250094] Bias: -1.1177437686478982 loss: 0.33412941580010824\n",
            "Round: 1416 Weight: [2.5238695  1.33253994] Bias: -1.1177722664849752 loss: 0.33412933506146536\n",
            "Round: 1417 Weight: [2.52394488 1.33257885] Bias: -1.1178006932204139 loss: 0.334129254724049\n",
            "Round: 1418 Weight: [2.52402007 1.33261765] Bias: -1.1178290490370832 loss: 0.3341291747858376\n",
            "Round: 1419 Weight: [2.52409507 1.33265637] Bias: -1.1178573341173552 loss: 0.3341290952448198\n",
            "Round: 1420 Weight: [2.52416989 1.33269498] Bias: -1.1178855486431047 loss: 0.3341290160989947\n",
            "Round: 1421 Weight: [2.52424453 1.3327335 ] Bias: -1.1179136927957127 loss: 0.3341289373463715\n",
            "Round: 1422 Weight: [2.52431897 1.33277192] Bias: -1.1179417667560663 loss: 0.3341288589849697\n",
            "Round: 1423 Weight: [2.52439324 1.33281025] Bias: -1.117969770704561 loss: 0.3341287810128189\n",
            "Round: 1424 Weight: [2.52446731 1.33284848] Bias: -1.117997704821102 loss: 0.3341287034279592\n",
            "Round: 1425 Weight: [2.52454121 1.33288662] Bias: -1.1180255692851058 loss: 0.33412862622844014\n",
            "Round: 1426 Weight: [2.52461492 1.33292466] Bias: -1.118053364275501 loss: 0.33412854941232184\n",
            "Round: 1427 Weight: [2.52468845 1.33296261] Bias: -1.118081089970731 loss: 0.3341284729776741\n",
            "Round: 1428 Weight: [2.52476179 1.33300046] Bias: -1.118108746548754 loss: 0.3341283969225768\n",
            "Round: 1429 Weight: [2.52483495 1.33303822] Bias: -1.1181363341870458 loss: 0.3341283212451194\n",
            "Round: 1430 Weight: [2.52490793 1.33307589] Bias: -1.1181638530626001 loss: 0.3341282459434014\n",
            "Round: 1431 Weight: [2.52498073 1.33311346] Bias: -1.1181913033519308 loss: 0.3341281710155321\n",
            "Round: 1432 Weight: [2.52505335 1.33315094] Bias: -1.118218685231073 loss: 0.33412809645963026\n",
            "Round: 1433 Weight: [2.52512579 1.33318833] Bias: -1.1182459988755842 loss: 0.33412802227382454\n",
            "Round: 1434 Weight: [2.52519805 1.33322562] Bias: -1.1182732444605463 loss: 0.3341279484562531\n",
            "Round: 1435 Weight: [2.52527012 1.33326282] Bias: -1.1183004221605668 loss: 0.33412787500506347\n",
            "Round: 1436 Weight: [2.52534202 1.33329992] Bias: -1.1183275321497799 loss: 0.33412780191841296\n",
            "Round: 1437 Weight: [2.52541374 1.33333694] Bias: -1.1183545746018484 loss: 0.33412772919446826\n",
            "Round: 1438 Weight: [2.52548529 1.33337386] Bias: -1.1183815496899647 loss: 0.3341276568314053\n",
            "Round: 1439 Weight: [2.52555665 1.33341069] Bias: -1.1184084575868525 loss: 0.3341275848274097\n",
            "Round: 1440 Weight: [2.52562784 1.33344743] Bias: -1.1184352984647679 loss: 0.334127513180676\n",
            "Round: 1441 Weight: [2.52569885 1.33348408] Bias: -1.118462072495501 loss: 0.3341274418894082\n",
            "Round: 1442 Weight: [2.52576969 1.33352064] Bias: -1.1184887798503773 loss: 0.3341273709518194\n",
            "Round: 1443 Weight: [2.52584035 1.33355711] Bias: -1.118515420700259 loss: 0.33412730036613203\n",
            "Round: 1444 Weight: [2.52591083 1.33359348] Bias: -1.1185419952155464 loss: 0.3341272301305774\n",
            "Round: 1445 Weight: [2.52598114 1.33362977] Bias: -1.1185685035661792 loss: 0.33412716024339606\n",
            "Round: 1446 Weight: [2.52605127 1.33366597] Bias: -1.1185949459216378 loss: 0.3341270907028374\n",
            "Round: 1447 Weight: [2.52612123 1.33370207] Bias: -1.1186213224509447 loss: 0.3341270215071601\n",
            "Round: 1448 Weight: [2.52619102 1.33373809] Bias: -1.1186476333226663 loss: 0.3341269526546314\n",
            "Round: 1449 Weight: [2.52626063 1.33377402] Bias: -1.1186738787049135 loss: 0.3341268841435273\n",
            "Round: 1450 Weight: [2.52633007 1.33380985] Bias: -1.1187000587653437 loss: 0.3341268159721334\n",
            "Round: 1451 Weight: [2.52639934 1.3338456 ] Bias: -1.118726173671162 loss: 0.33412674813874305\n",
            "Round: 1452 Weight: [2.52646844 1.33388126] Bias: -1.1187522235891219 loss: 0.334126680641659\n",
            "Round: 1453 Weight: [2.52653736 1.33391683] Bias: -1.1187782086855274 loss: 0.33412661347919276\n",
            "Round: 1454 Weight: [2.52660612 1.33395232] Bias: -1.118804129126234 loss: 0.3341265466496638\n",
            "Round: 1455 Weight: [2.5266747  1.33398771] Bias: -1.1188299850766505 loss: 0.3341264801514008\n",
            "Round: 1456 Weight: [2.52674312 1.33402302] Bias: -1.1188557767017395 loss: 0.33412641398274084\n",
            "Round: 1457 Weight: [2.52681136 1.33405824] Bias: -1.118881504166019 loss: 0.33412634814202946\n",
            "Round: 1458 Weight: [2.52687943 1.33409337] Bias: -1.118907167633564 loss: 0.3341262826276205\n",
            "Round: 1459 Weight: [2.52694734 1.33412842] Bias: -1.118932767268008 loss: 0.3341262174378766\n",
            "Round: 1460 Weight: [2.52701508 1.33416338] Bias: -1.1189583032325434 loss: 0.3341261525711685\n",
            "Round: 1461 Weight: [2.52708265 1.33419825] Bias: -1.1189837756899235 loss: 0.3341260880258752\n",
            "Round: 1462 Weight: [2.52715005 1.33423303] Bias: -1.1190091848024637 loss: 0.3341260238003842\n",
            "Round: 1463 Weight: [2.52721728 1.33426773] Bias: -1.1190345307320428 loss: 0.3341259598930911\n",
            "Round: 1464 Weight: [2.52728435 1.33430234] Bias: -1.1190598136401042 loss: 0.3341258963023997\n",
            "Round: 1465 Weight: [2.52735125 1.33433687] Bias: -1.1190850336876568 loss: 0.33412583302672205\n",
            "Round: 1466 Weight: [2.52741799 1.33437131] Bias: -1.119110191035277 loss: 0.3341257700644782\n",
            "Round: 1467 Weight: [2.52748456 1.33440567] Bias: -1.1191352858431098 loss: 0.3341257074140963\n",
            "Round: 1468 Weight: [2.52755097 1.33443994] Bias: -1.1191603182708696 loss: 0.33412564507401254\n",
            "Round: 1469 Weight: [2.52761721 1.33447413] Bias: -1.1191852884778417 loss: 0.3341255830426712\n",
            "Round: 1470 Weight: [2.52768329 1.33450823] Bias: -1.1192101966228838 loss: 0.33412552131852435\n",
            "Round: 1471 Weight: [2.5277492  1.33454224] Bias: -1.1192350428644269 loss: 0.33412545990003195\n",
            "Round: 1472 Weight: [2.52781495 1.33457618] Bias: -1.119259827360477 loss: 0.3341253987856618\n",
            "Round: 1473 Weight: [2.52788054 1.33461002] Bias: -1.119284550268616 loss: 0.33412533797388977\n",
            "Round: 1474 Weight: [2.52794596 1.33464379] Bias: -1.1193092117460026 loss: 0.3341252774631992\n",
            "Round: 1475 Weight: [2.52801122 1.33467747] Bias: -1.1193338119493745 loss: 0.33412521725208144\n",
            "Round: 1476 Weight: [2.52807632 1.33471106] Bias: -1.1193583510350489 loss: 0.33412515733903525\n",
            "Round: 1477 Weight: [2.52814126 1.33474458] Bias: -1.1193828291589236 loss: 0.3341250977225672\n",
            "Round: 1478 Weight: [2.52820604 1.33477801] Bias: -1.119407246476479 loss: 0.3341250384011915\n",
            "Round: 1479 Weight: [2.52827066 1.33481136] Bias: -1.1194316031427787 loss: 0.3341249793734299\n",
            "Round: 1480 Weight: [2.52833512 1.33484462] Bias: -1.1194558993124706 loss: 0.33412492063781174\n",
            "Round: 1481 Weight: [2.52839942 1.3348778 ] Bias: -1.1194801351397885 loss: 0.33412486219287374\n",
            "Round: 1482 Weight: [2.52846356 1.3349109 ] Bias: -1.1195043107785536 loss: 0.3341248040371601\n",
            "Round: 1483 Weight: [2.52852754 1.33494392] Bias: -1.1195284263821748 loss: 0.33412474616922255\n",
            "Round: 1484 Weight: [2.52859136 1.33497686] Bias: -1.1195524821036504 loss: 0.33412468858762\n",
            "Round: 1485 Weight: [2.52865502 1.33500972] Bias: -1.11957647809557 loss: 0.33412463129091896\n",
            "Round: 1486 Weight: [2.52871853 1.33504249] Bias: -1.119600414510114 loss: 0.33412457427769304\n",
            "Round: 1487 Weight: [2.52878188 1.33507518] Bias: -1.1196242914990564 loss: 0.3341245175465232\n",
            "Round: 1488 Weight: [2.52884507 1.33510779] Bias: -1.1196481092137653 loss: 0.33412446109599764\n",
            "Round: 1489 Weight: [2.52890811 1.33514032] Bias: -1.119671867805204 loss: 0.3341244049247117\n",
            "Round: 1490 Weight: [2.52897099 1.33517277] Bias: -1.1196955674239322 loss: 0.3341243490312678\n",
            "Round: 1491 Weight: [2.52903371 1.33520514] Bias: -1.1197192082201075 loss: 0.3341242934142758\n",
            "Round: 1492 Weight: [2.52909628 1.33523743] Bias: -1.1197427903434864 loss: 0.3341242380723522\n",
            "Round: 1493 Weight: [2.5291587  1.33526964] Bias: -1.1197663139434255 loss: 0.3341241830041207\n",
            "Round: 1494 Weight: [2.52922096 1.33530177] Bias: -1.1197897791688822 loss: 0.3341241282082122\n",
            "Round: 1495 Weight: [2.52928306 1.33533382] Bias: -1.1198131861684169 loss: 0.3341240736832644\n",
            "Round: 1496 Weight: [2.52934501 1.3353658 ] Bias: -1.1198365350901927 loss: 0.3341240194279219\n",
            "Round: 1497 Weight: [2.52940681 1.33539769] Bias: -1.1198598260819776 loss: 0.3341239654408362\n",
            "Round: 1498 Weight: [2.52946846 1.3354295 ] Bias: -1.119883059291146 loss: 0.3341239117206657\n",
            "Round: 1499 Weight: [2.52952995 1.33546123] Bias: -1.1199062348646784 loss: 0.3341238582660757\n",
            "Round: 1500 Weight: [2.52959129 1.33549289] Bias: -1.119929352949164 loss: 0.3341238050757381\n",
            "Round: 1501 Weight: [2.52965248 1.33552447] Bias: -1.119952413690801 loss: 0.33412375214833173\n",
            "Round: 1502 Weight: [2.52971352 1.33555597] Bias: -1.119975417235398 loss: 0.33412369948254206\n",
            "Round: 1503 Weight: [2.52977441 1.33558739] Bias: -1.1199983637283748 loss: 0.33412364707706116\n",
            "Round: 1504 Weight: [2.52983515 1.33561873] Bias: -1.120021253314764 loss: 0.334123594930588\n",
            "Round: 1505 Weight: [2.52989573 1.33565   ] Bias: -1.120044086139212 loss: 0.334123543041828\n",
            "Round: 1506 Weight: [2.52995617 1.33568119] Bias: -1.12006686234598 loss: 0.3341234914094929\n",
            "Round: 1507 Weight: [2.53001646 1.3357123 ] Bias: -1.1200895820789447 loss: 0.3341234400323015\n",
            "Round: 1508 Weight: [2.53007659 1.33574333] Bias: -1.1201122454816008 loss: 0.33412338890897864\n",
            "Round: 1509 Weight: [2.53013658 1.33577429] Bias: -1.1201348526970603 loss: 0.3341233380382559\n",
            "Round: 1510 Weight: [2.53019642 1.33580517] Bias: -1.1201574038680548 loss: 0.3341232874188714\n",
            "Round: 1511 Weight: [2.53025612 1.33583598] Bias: -1.1201798991369363 loss: 0.3341232370495695\n",
            "Round: 1512 Weight: [2.53031566 1.33586671] Bias: -1.120202338645678 loss: 0.33412318692910065\n",
            "Round: 1513 Weight: [2.53037506 1.33589736] Bias: -1.1202247225358763 loss: 0.33412313705622215\n",
            "Round: 1514 Weight: [2.53043431 1.33592794] Bias: -1.1202470509487505 loss: 0.3341230874296976\n",
            "Round: 1515 Weight: [2.53049342 1.33595844] Bias: -1.120269324025145 loss: 0.33412303804829635\n",
            "Round: 1516 Weight: [2.53055238 1.33598886] Bias: -1.1202915419055295 loss: 0.3341229889107943\n",
            "Round: 1517 Weight: [2.53061119 1.33601921] Bias: -1.1203137047300014 loss: 0.33412294001597403\n",
            "Round: 1518 Weight: [2.53066986 1.33604949] Bias: -1.1203358126382854 loss: 0.33412289136262335\n",
            "Round: 1519 Weight: [2.53072838 1.33607969] Bias: -1.1203578657697357 loss: 0.33412284294953687\n",
            "Round: 1520 Weight: [2.53078676 1.33610982] Bias: -1.1203798642633362 loss: 0.3341227947755154\n",
            "Round: 1521 Weight: [2.53084499 1.33613987] Bias: -1.120401808257702 loss: 0.33412274683936516\n",
            "Round: 1522 Weight: [2.53090308 1.33616985] Bias: -1.1204236978910806 loss: 0.33412269913989934\n",
            "Round: 1523 Weight: [2.53096103 1.33619975] Bias: -1.1204455333013525 loss: 0.3341226516759363\n",
            "Round: 1524 Weight: [2.53101883 1.33622958] Bias: -1.1204673146260329 loss: 0.33412260444630104\n",
            "Round: 1525 Weight: [2.5310765  1.33625933] Bias: -1.1204890420022722 loss: 0.33412255744982405\n",
            "Round: 1526 Weight: [2.53113401 1.33628902] Bias: -1.1205107155668568 loss: 0.3341225106853421\n",
            "Round: 1527 Weight: [2.53119139 1.33631862] Bias: -1.1205323354562111 loss: 0.3341224641516973\n",
            "Round: 1528 Weight: [2.53124862 1.33634816] Bias: -1.1205539018063981 loss: 0.3341224178477385\n",
            "Round: 1529 Weight: [2.53130572 1.33637762] Bias: -1.1205754147531197 loss: 0.3341223717723195\n",
            "Round: 1530 Weight: [2.53136267 1.33640701] Bias: -1.120596874431719 loss: 0.3341223259243008\n",
            "Round: 1531 Weight: [2.53141948 1.33643633] Bias: -1.12061828097718 loss: 0.33412228030254776\n",
            "Round: 1532 Weight: [2.53147615 1.33646557] Bias: -1.12063963452413 loss: 0.334122234905932\n",
            "Round: 1533 Weight: [2.53153268 1.33649475] Bias: -1.1206609352068397 loss: 0.33412218973333085\n",
            "Round: 1534 Weight: [2.53158907 1.33652385] Bias: -1.1206821831592242 loss: 0.3341221447836272\n",
            "Round: 1535 Weight: [2.53164533 1.33655287] Bias: -1.1207033785148446 loss: 0.3341221000557095\n",
            "Round: 1536 Weight: [2.53170144 1.33658183] Bias: -1.1207245214069086 loss: 0.33412205554847224\n",
            "Round: 1537 Weight: [2.53175742 1.33661072] Bias: -1.1207456119682717 loss: 0.3341220112608151\n",
            "Round: 1538 Weight: [2.53181325 1.33663953] Bias: -1.120766650331438 loss: 0.33412196719164344\n",
            "Round: 1539 Weight: [2.53186895 1.33666827] Bias: -1.120787636628561 loss: 0.3341219233398682\n",
            "Round: 1540 Weight: [2.53192451 1.33669695] Bias: -1.1208085709914455 loss: 0.33412187970440577\n",
            "Round: 1541 Weight: [2.53197994 1.33672555] Bias: -1.1208294535515475 loss: 0.33412183628417824\n",
            "Round: 1542 Weight: [2.53203522 1.33675408] Bias: -1.1208502844399761 loss: 0.33412179307811274\n",
            "Round: 1543 Weight: [2.53209038 1.33678254] Bias: -1.1208710637874937 loss: 0.33412175008514217\n",
            "Round: 1544 Weight: [2.53214539 1.33681093] Bias: -1.1208917917245176 loss: 0.3341217073042048\n",
            "Round: 1545 Weight: [2.53220027 1.33683925] Bias: -1.120912468381121 loss: 0.33412166473424415\n",
            "Round: 1546 Weight: [2.53225501 1.3368675 ] Bias: -1.120933093887033 loss: 0.33412162237420906\n",
            "Round: 1547 Weight: [2.53230962 1.33689568] Bias: -1.120953668371641 loss: 0.3341215802230539\n",
            "Round: 1548 Weight: [2.5323641  1.33692379] Bias: -1.1209741919639908 loss: 0.33412153827973806\n",
            "Round: 1549 Weight: [2.53241844 1.33695183] Bias: -1.1209946647927875 loss: 0.3341214965432263\n",
            "Round: 1550 Weight: [2.53247264 1.3369798 ] Bias: -1.1210150869863973 loss: 0.3341214550124888\n",
            "Round: 1551 Weight: [2.53252671 1.3370077 ] Bias: -1.1210354586728473 loss: 0.3341214136865006\n",
            "Round: 1552 Weight: [2.53258065 1.33703553] Bias: -1.121055779979827 loss: 0.33412137256424224\n",
            "Round: 1553 Weight: [2.53263446 1.3370633 ] Bias: -1.1210760510346902 loss: 0.3341213316446991\n",
            "Round: 1554 Weight: [2.53268813 1.337091  ] Bias: -1.1210962719644542 loss: 0.33412129092686194\n",
            "Round: 1555 Weight: [2.53274167 1.33711862] Bias: -1.1211164428958016 loss: 0.33412125040972657\n",
            "Round: 1556 Weight: [2.53279508 1.33714618] Bias: -1.1211365639550819 loss: 0.3341212100922938\n",
            "Round: 1557 Weight: [2.53284835 1.33717368] Bias: -1.1211566352683113 loss: 0.33412116997356944\n",
            "Round: 1558 Weight: [2.5329015 1.3372011] Bias: -1.1211766569611745 loss: 0.3341211300525646\n",
            "Round: 1559 Weight: [2.53295451 1.33722846] Bias: -1.121196629159025 loss: 0.33412109032829496\n",
            "Round: 1560 Weight: [2.53300739 1.33725575] Bias: -1.1212165519868864 loss: 0.33412105079978155\n",
            "Round: 1561 Weight: [2.53306015 1.33728297] Bias: -1.1212364255694536 loss: 0.3341210114660502\n",
            "Round: 1562 Weight: [2.53311277 1.33731012] Bias: -1.121256250031093 loss: 0.33412097232613147\n",
            "Round: 1563 Weight: [2.53316526 1.33733721] Bias: -1.121276025495844 loss: 0.3341209333790613\n",
            "Round: 1564 Weight: [2.53321763 1.33736423] Bias: -1.1212957520874198 loss: 0.33412089462388006\n",
            "Round: 1565 Weight: [2.53326986 1.33739119] Bias: -1.121315429929208 loss: 0.33412085605963293\n",
            "Round: 1566 Weight: [2.53332197 1.33741807] Bias: -1.1213350591442723 loss: 0.33412081768537016\n",
            "Round: 1567 Weight: [2.53337394 1.33744489] Bias: -1.1213546398553524 loss: 0.3341207795001468\n",
            "Round: 1568 Weight: [2.53342579 1.33747165] Bias: -1.1213741721848658 loss: 0.3341207415030225\n",
            "Round: 1569 Weight: [2.53347751 1.33749834] Bias: -1.1213936562549083 loss: 0.3341207036930619\n",
            "Round: 1570 Weight: [2.53352911 1.33752496] Bias: -1.1214130921872547 loss: 0.3341206660693338\n",
            "Round: 1571 Weight: [2.53358057 1.33755152] Bias: -1.1214324801033602 loss: 0.3341206286309124\n",
            "Round: 1572 Weight: [2.53363191 1.33757801] Bias: -1.1214518201243608 loss: 0.3341205913768763\n",
            "Round: 1573 Weight: [2.53368313 1.33760444] Bias: -1.1214711123710748 loss: 0.3341205543063084\n",
            "Round: 1574 Weight: [2.53373421 1.3376308 ] Bias: -1.1214903569640031 loss: 0.33412051741829674\n",
            "Round: 1575 Weight: [2.53378517 1.3376571 ] Bias: -1.1215095540233306 loss: 0.3341204807119337\n",
            "Round: 1576 Weight: [2.53383601 1.33768333] Bias: -1.1215287036689265 loss: 0.33412044418631615\n",
            "Round: 1577 Weight: [2.53388672 1.3377095 ] Bias: -1.1215478060203459 loss: 0.33412040784054575\n",
            "Round: 1578 Weight: [2.5339373 1.3377356] Bias: -1.12156686119683 loss: 0.33412037167372877\n",
            "Round: 1579 Weight: [2.53398776 1.33776164] Bias: -1.1215858693173073 loss: 0.33412033568497546\n",
            "Round: 1580 Weight: [2.5340381  1.33778761] Bias: -1.121604830500395 loss: 0.33412029987340097\n",
            "Round: 1581 Weight: [2.53408831 1.33781352] Bias: -1.1216237448643984 loss: 0.3341202642381251\n",
            "Round: 1582 Weight: [2.5341384  1.33783937] Bias: -1.1216426125273138 loss: 0.33412022877827124\n",
            "Round: 1583 Weight: [2.53418837 1.33786515] Bias: -1.1216614336068274 loss: 0.33412019349296834\n",
            "Round: 1584 Weight: [2.53423821 1.33789087] Bias: -1.1216802082203174 loss: 0.33412015838134884\n",
            "Round: 1585 Weight: [2.53428793 1.33791653] Bias: -1.1216989364848549 loss: 0.33412012344255\n",
            "Round: 1586 Weight: [2.53433752 1.33794212] Bias: -1.1217176185172038 loss: 0.3341200886757132\n",
            "Round: 1587 Weight: [2.534387   1.33796765] Bias: -1.1217362544338225 loss: 0.33412005407998424\n",
            "Round: 1588 Weight: [2.53443635 1.33799312] Bias: -1.1217548443508647 loss: 0.3341200196545134\n",
            "Round: 1589 Weight: [2.53448558 1.33801852] Bias: -1.1217733883841798 loss: 0.33411998539845494\n",
            "Round: 1590 Weight: [2.53453469 1.33804386] Bias: -1.1217918866493144 loss: 0.33411995131096733\n",
            "Round: 1591 Weight: [2.53458368 1.33806914] Bias: -1.1218103392615122 loss: 0.3341199173912136\n",
            "Round: 1592 Weight: [2.53463255 1.33809436] Bias: -1.1218287463357157 loss: 0.33411988363836087\n",
            "Round: 1593 Weight: [2.5346813  1.33811951] Bias: -1.121847107986567 loss: 0.33411985005158035\n",
            "Round: 1594 Weight: [2.53472993 1.3381446 ] Bias: -1.1218654243284083 loss: 0.33411981663004764\n",
            "Round: 1595 Weight: [2.53477843 1.33816964] Bias: -1.1218836954752824 loss: 0.33411978337294207\n",
            "Round: 1596 Weight: [2.53482682 1.3381946 ] Bias: -1.1219019215409347 loss: 0.33411975027944746\n",
            "Round: 1597 Weight: [2.53487509 1.33821951] Bias: -1.1219201026388128 loss: 0.3341197173487518\n",
            "Round: 1598 Weight: [2.53492324 1.33824436] Bias: -1.1219382388820678 loss: 0.33411968458004676\n",
            "Round: 1599 Weight: [2.53497128 1.33826914] Bias: -1.1219563303835556 loss: 0.3341196519725285\n",
            "Round: 1600 Weight: [2.53501919 1.33829387] Bias: -1.121974377255837 loss: 0.3341196195253969\n",
            "Round: 1601 Weight: [2.53506699 1.33831853] Bias: -1.121992379611179 loss: 0.3341195872378562\n",
            "Round: 1602 Weight: [2.53511467 1.33834313] Bias: -1.1220103375615553 loss: 0.3341195551091143\n",
            "Round: 1603 Weight: [2.53516223 1.33836767] Bias: -1.1220282512186475 loss: 0.3341195231383831\n",
            "Round: 1604 Weight: [2.53520967 1.33839216] Bias: -1.1220461206938452 loss: 0.33411949132487895\n",
            "Round: 1605 Weight: [2.535257   1.33841658] Bias: -1.1220639460982478 loss: 0.3341194596678215\n",
            "Round: 1606 Weight: [2.53530421 1.33844094] Bias: -1.1220817275426647 loss: 0.3341194281664347\n",
            "Round: 1607 Weight: [2.5353513  1.33846524] Bias: -1.122099465137616 loss: 0.33411939681994623\n",
            "Round: 1608 Weight: [2.53539828 1.33848948] Bias: -1.1221171589933336 loss: 0.3341193656275878\n",
            "Round: 1609 Weight: [2.53544515 1.33851366] Bias: -1.122134809219762 loss: 0.3341193345885949\n",
            "Round: 1610 Weight: [2.53549189 1.33853778] Bias: -1.1221524159265592 loss: 0.3341193037022069\n",
            "Round: 1611 Weight: [2.53553853 1.33856185] Bias: -1.122169979223097 loss: 0.33411927296766675\n",
            "Round: 1612 Weight: [2.53558504 1.33858585] Bias: -1.1221874992184624 loss: 0.3341192423842217\n",
            "Round: 1613 Weight: [2.53563145 1.3386098 ] Bias: -1.1222049760214579 loss: 0.33411921195112226\n",
            "Round: 1614 Weight: [2.53567774 1.33863368] Bias: -1.1222224097406024 loss: 0.3341191816676231\n",
            "Round: 1615 Weight: [2.53572391 1.33865751] Bias: -1.1222398004841325 loss: 0.3341191515329824\n",
            "Round: 1616 Weight: [2.53576998 1.33868128] Bias: -1.1222571483600026 loss: 0.33411912154646217\n",
            "Round: 1617 Weight: [2.53581592 1.33870498] Bias: -1.122274453475886 loss: 0.3341190917073279\n",
            "Round: 1618 Weight: [2.53586176 1.33872864] Bias: -1.1222917159391756 loss: 0.3341190620148492\n",
            "Round: 1619 Weight: [2.53590748 1.33875223] Bias: -1.122308935856985 loss: 0.33411903246829905\n",
            "Round: 1620 Weight: [2.53595309 1.33877576] Bias: -1.122326113336149 loss: 0.33411900306695397\n",
            "Round: 1621 Weight: [2.53599859 1.33879924] Bias: -1.1223432484832239 loss: 0.33411897381009437\n",
            "Round: 1622 Weight: [2.53604398 1.33882266] Bias: -1.122360341404489 loss: 0.33411894469700426\n",
            "Round: 1623 Weight: [2.53608925 1.33884602] Bias: -1.122377392205947 loss: 0.3341189157269711\n",
            "Round: 1624 Weight: [2.53613442 1.33886933] Bias: -1.1223944009933253 loss: 0.33411888689928587\n",
            "Round: 1625 Weight: [2.53617947 1.33889257] Bias: -1.122411367872076 loss: 0.33411885821324355\n",
            "Round: 1626 Weight: [2.53622441 1.33891576] Bias: -1.122428292947377 loss: 0.33411882966814194\n",
            "Round: 1627 Weight: [2.53626924 1.3389389 ] Bias: -1.122445176324133 loss: 0.33411880126328297\n",
            "Round: 1628 Weight: [2.53631396 1.33896197] Bias: -1.122462018106976 loss: 0.3341187729979717\n",
            "Round: 1629 Weight: [2.53635858 1.33898499] Bias: -1.1224788184002656 loss: 0.334118744871517\n",
            "Round: 1630 Weight: [2.53640308 1.33900795] Bias: -1.1224955773080911 loss: 0.3341187168832309\n",
            "Round: 1631 Weight: [2.53644747 1.33903086] Bias: -1.1225122949342705 loss: 0.33411868903242914\n",
            "Round: 1632 Weight: [2.53649175 1.33905371] Bias: -1.1225289713823527 loss: 0.33411866131843065\n",
            "Round: 1633 Weight: [2.53653593 1.3390765 ] Bias: -1.1225456067556177 loss: 0.33411863374055784\n",
            "Round: 1634 Weight: [2.53657999 1.33909924] Bias: -1.1225622011570768 loss: 0.33411860629813667\n",
            "Round: 1635 Weight: [2.53662395 1.33912192] Bias: -1.1225787546894743 loss: 0.33411857899049646\n",
            "Round: 1636 Weight: [2.5366678  1.33914455] Bias: -1.122595267455288 loss: 0.33411855181696964\n",
            "Round: 1637 Weight: [2.53671154 1.33916712] Bias: -1.122611739556729 loss: 0.33411852477689225\n",
            "Round: 1638 Weight: [2.53675517 1.33918963] Bias: -1.122628171095744 loss: 0.33411849786960335\n",
            "Round: 1639 Weight: [2.5367987  1.33921209] Bias: -1.1226445621740149 loss: 0.3341184710944458\n",
            "Round: 1640 Weight: [2.53684212 1.33923449] Bias: -1.1226609128929597 loss: 0.33411844445076533\n",
            "Round: 1641 Weight: [2.53688543 1.33925684] Bias: -1.1226772233537332 loss: 0.3341184179379112\n",
            "Round: 1642 Weight: [2.53692864 1.33927914] Bias: -1.1226934936572286 loss: 0.33411839155523565\n",
            "Round: 1643 Weight: [2.53697174 1.33930138] Bias: -1.1227097239040769 loss: 0.33411836530209454\n",
            "Round: 1644 Weight: [2.53701473 1.33932356] Bias: -1.1227259141946482 loss: 0.33411833917784645\n",
            "Round: 1645 Weight: [2.53705762 1.33934569] Bias: -1.122742064629053 loss: 0.3341183131818538\n",
            "Round: 1646 Weight: [2.5371004  1.33936777] Bias: -1.1227581753071418 loss: 0.3341182873134816\n",
            "Round: 1647 Weight: [2.53714308 1.33938979] Bias: -1.1227742463285069 loss: 0.3341182615720987\n",
            "Round: 1648 Weight: [2.53718566 1.33941176] Bias: -1.122790277792482 loss: 0.3341182359570763\n",
            "Round: 1649 Weight: [2.53722813 1.33943367] Bias: -1.1228062697981442 loss: 0.3341182104677894\n",
            "Round: 1650 Weight: [2.53727049 1.33945553] Bias: -1.1228222224443136 loss: 0.3341181851036158\n",
            "Round: 1651 Weight: [2.53731275 1.33947733] Bias: -1.1228381358295545 loss: 0.3341181598639367\n",
            "Round: 1652 Weight: [2.53735491 1.33949909] Bias: -1.122854010052176 loss: 0.334118134748136\n",
            "Round: 1653 Weight: [2.53739696 1.33952079] Bias: -1.1228698452102328 loss: 0.3341181097556011\n",
            "Round: 1654 Weight: [2.53743891 1.33954243] Bias: -1.1228856414015258 loss: 0.33411808488572203\n",
            "Round: 1655 Weight: [2.53748076 1.33956402] Bias: -1.1229013987236027 loss: 0.3341180601378923\n",
            "Round: 1656 Weight: [2.5375225  1.33958556] Bias: -1.1229171172737593 loss: 0.33411803551150815\n",
            "Round: 1657 Weight: [2.53756414 1.33960705] Bias: -1.122932797149039 loss: 0.3341180110059691\n",
            "Round: 1658 Weight: [2.53760568 1.33962848] Bias: -1.122948438446235 loss: 0.3341179866206773\n",
            "Round: 1659 Weight: [2.53764712 1.33964986] Bias: -1.1229640412618893 loss: 0.33411796235503827\n",
            "Round: 1660 Weight: [2.53768845 1.33967119] Bias: -1.1229796056922952 loss: 0.33411793820846036\n",
            "Round: 1661 Weight: [2.53772969 1.33969247] Bias: -1.1229951318334963 loss: 0.33411791418035486\n",
            "Round: 1662 Weight: [2.53777082 1.33971369] Bias: -1.1230106197812886 loss: 0.334117890270136\n",
            "Round: 1663 Weight: [2.53781185 1.33973486] Bias: -1.1230260696312202 loss: 0.3341178664772209\n",
            "Round: 1664 Weight: [2.53785278 1.33975598] Bias: -1.1230414814785923 loss: 0.3341178428010296\n",
            "Round: 1665 Weight: [2.53789361 1.33977705] Bias: -1.12305685541846 loss: 0.33411781924098527\n",
            "Round: 1666 Weight: [2.53793434 1.33979807] Bias: -1.1230721915456325 loss: 0.3341177957965138\n",
            "Round: 1667 Weight: [2.53797497 1.33981903] Bias: -1.1230874899546748 loss: 0.33411777246704366\n",
            "Round: 1668 Weight: [2.5380155  1.33983994] Bias: -1.1231027507399072 loss: 0.3341177492520066\n",
            "Round: 1669 Weight: [2.53805593 1.3398608 ] Bias: -1.1231179739954067 loss: 0.334117726150837\n",
            "Round: 1670 Weight: [2.53809627 1.33988161] Bias: -1.1231331598150074 loss: 0.33411770316297235\n",
            "Round: 1671 Weight: [2.5381365  1.33990237] Bias: -1.123148308292301 loss: 0.3341176802878525\n",
            "Round: 1672 Weight: [2.53817663 1.33992308] Bias: -1.1231634195206381 loss: 0.33411765752492034\n",
            "Round: 1673 Weight: [2.53821667 1.33994374] Bias: -1.1231784935931282 loss: 0.3341176348736216\n",
            "Round: 1674 Weight: [2.53825661 1.33996435] Bias: -1.1231935306026402 loss: 0.3341176123334046\n",
            "Round: 1675 Weight: [2.53829645 1.3399849 ] Bias: -1.123208530641804 loss: 0.33411758990372076\n",
            "Round: 1676 Weight: [2.53833619 1.34000541] Bias: -1.1232234938030106 loss: 0.33411756758402383\n",
            "Round: 1677 Weight: [2.53837583 1.34002586] Bias: -1.1232384201784125 loss: 0.3341175453737704\n",
            "Round: 1678 Weight: [2.53841538 1.34004627] Bias: -1.1232533098599244 loss: 0.3341175232724199\n",
            "Round: 1679 Weight: [2.53845483 1.34006662] Bias: -1.1232681629392247 loss: 0.3341175012794345\n",
            "Round: 1680 Weight: [2.53849418 1.34008693] Bias: -1.123282979507755 loss: 0.3341174793942789\n",
            "Round: 1681 Weight: [2.53853344 1.34010718] Bias: -1.1232977596567213 loss: 0.3341174576164203\n",
            "Round: 1682 Weight: [2.5385726  1.34012739] Bias: -1.1233125034770948 loss: 0.33411743594532917\n",
            "Round: 1683 Weight: [2.53861166 1.34014754] Bias: -1.123327211059612 loss: 0.33411741438047793\n",
            "Round: 1684 Weight: [2.53865063 1.34016765] Bias: -1.1233418824947758 loss: 0.334117392921342\n",
            "Round: 1685 Weight: [2.5386895  1.34018771] Bias: -1.1233565178728564 loss: 0.33411737156739957\n",
            "Round: 1686 Weight: [2.53872828 1.34020771] Bias: -1.123371117283891 loss: 0.334117350318131\n",
            "Round: 1687 Weight: [2.53876696 1.34022767] Bias: -1.123385680817685 loss: 0.33411732917301945\n",
            "Round: 1688 Weight: [2.53880555 1.34024758] Bias: -1.123400208563813 loss: 0.3341173081315509\n",
            "Round: 1689 Weight: [2.53884404 1.34026744] Bias: -1.1234147006116189 loss: 0.33411728719321343\n",
            "Round: 1690 Weight: [2.53888244 1.34028726] Bias: -1.1234291570502162 loss: 0.33411726635749806\n",
            "Round: 1691 Weight: [2.53892074 1.34030702] Bias: -1.1234435779684897 loss: 0.33411724562389816\n",
            "Round: 1692 Weight: [2.53895895 1.34032673] Bias: -1.1234579634550952 loss: 0.3341172249919097\n",
            "Round: 1693 Weight: [2.53899706 1.3403464 ] Bias: -1.1234723135984606 loss: 0.3341172044610311\n",
            "Round: 1694 Weight: [2.53903509 1.34036602] Bias: -1.123486628486786 loss: 0.33411718403076324\n",
            "Round: 1695 Weight: [2.53907302 1.34038559] Bias: -1.1235009082080452 loss: 0.3341171637006099\n",
            "Round: 1696 Weight: [2.53911085 1.34040511] Bias: -1.1235151528499852 loss: 0.3341171434700766\n",
            "Round: 1697 Weight: [2.5391486  1.34042459] Bias: -1.123529362500128 loss: 0.334117123338672\n",
            "Round: 1698 Weight: [2.53918625 1.34044401] Bias: -1.12354353724577 loss: 0.33411710330590677\n",
            "Round: 1699 Weight: [2.53922381 1.34046339] Bias: -1.123557677173984 loss: 0.33411708337129425\n",
            "Round: 1700 Weight: [2.53926127 1.34048272] Bias: -1.123571782371618 loss: 0.3341170635343502\n",
            "Round: 1701 Weight: [2.53929865 1.34050201] Bias: -1.123585852925298 loss: 0.3341170437945928\n",
            "Round: 1702 Weight: [2.53933593 1.34052124] Bias: -1.1235998889214265 loss: 0.3341170241515424\n",
            "Round: 1703 Weight: [2.53937312 1.34054043] Bias: -1.1236138904461845 loss: 0.3341170046047219\n",
            "Round: 1704 Weight: [2.53941022 1.34055958] Bias: -1.1236278575855316 loss: 0.3341169851536568\n",
            "Round: 1705 Weight: [2.53944723 1.34057867] Bias: -1.1236417904252067 loss: 0.33411696579787453\n",
            "Round: 1706 Weight: [2.53948415 1.34059772] Bias: -1.1236556890507283 loss: 0.3341169465369052\n",
            "Round: 1707 Weight: [2.53952098 1.34061672] Bias: -1.1236695535473957 loss: 0.3341169273702813\n",
            "Round: 1708 Weight: [2.53955772 1.34063568] Bias: -1.123683384000289 loss: 0.3341169082975373\n",
            "Round: 1709 Weight: [2.53959436 1.34065459] Bias: -1.1236971804942701 loss: 0.3341168893182103\n",
            "Round: 1710 Weight: [2.53963092 1.34067345] Bias: -1.123710943113983 loss: 0.33411687043183963\n",
            "Round: 1711 Weight: [2.53966739 1.34069227] Bias: -1.1237246719438543 loss: 0.3341168516379668\n",
            "Round: 1712 Weight: [2.53970377 1.34071104] Bias: -1.1237383670680945 loss: 0.3341168329361358\n",
            "Round: 1713 Weight: [2.53974006 1.34072976] Bias: -1.123752028570698 loss: 0.3341168143258927\n",
            "Round: 1714 Weight: [2.53977626 1.34074844] Bias: -1.1237656565354432 loss: 0.33411679580678605\n",
            "Round: 1715 Weight: [2.53981237 1.34076707] Bias: -1.1237792510458944 loss: 0.3341167773783662\n",
            "Round: 1716 Weight: [2.5398484  1.34078566] Bias: -1.1237928121854013 loss: 0.33411675904018656\n",
            "Round: 1717 Weight: [2.53988433 1.3408042 ] Bias: -1.1238063400370997 loss: 0.3341167407918018\n",
            "Round: 1718 Weight: [2.53992018 1.34082269] Bias: -1.1238198346839128 loss: 0.3341167226327695\n",
            "Round: 1719 Weight: [2.53995594 1.34084115] Bias: -1.1238332962085509 loss: 0.33411670456264925\n",
            "Round: 1720 Weight: [2.53999161 1.34085955] Bias: -1.1238467246935124 loss: 0.3341166865810026\n",
            "Round: 1721 Weight: [2.54002719 1.34087791] Bias: -1.1238601202210845 loss: 0.3341166686873936\n",
            "Round: 1722 Weight: [2.54006269 1.34089623] Bias: -1.1238734828733432 loss: 0.33411665088138826\n",
            "Round: 1723 Weight: [2.5400981 1.3409145] Bias: -1.1238868127321548 loss: 0.3341166331625551\n",
            "Round: 1724 Weight: [2.54013343 1.34093272] Bias: -1.1239001098791754 loss: 0.3341166155304642\n",
            "Round: 1725 Weight: [2.54016866 1.3409509 ] Bias: -1.1239133743958525 loss: 0.33411659798468824\n",
            "Round: 1726 Weight: [2.54020381 1.34096904] Bias: -1.1239266063634243 loss: 0.33411658052480175\n",
            "Round: 1727 Weight: [2.54023888 1.34098713] Bias: -1.123939805862922 loss: 0.33411656315038185\n",
            "Round: 1728 Weight: [2.54027386 1.34100518] Bias: -1.1239529729751685 loss: 0.33411654586100714\n",
            "Round: 1729 Weight: [2.54030875 1.34102318] Bias: -1.1239661077807805 loss: 0.33411652865625874\n",
            "Round: 1730 Weight: [2.54034356 1.34104114] Bias: -1.123979210360168 loss: 0.3341165115357196\n",
            "Round: 1731 Weight: [2.54037828 1.34105905] Bias: -1.1239922807935352 loss: 0.3341164944989749\n",
            "Round: 1732 Weight: [2.54041292 1.34107693] Bias: -1.1240053191608814 loss: 0.33411647754561186\n",
            "Round: 1733 Weight: [2.54044747 1.34109475] Bias: -1.124018325542001 loss: 0.33411646067521983\n",
            "Round: 1734 Weight: [2.54048194 1.34111254] Bias: -1.1240313000164848 loss: 0.3341164438873902\n",
            "Round: 1735 Weight: [2.54051632 1.34113028] Bias: -1.1240442426637192 loss: 0.33411642718171597\n",
            "Round: 1736 Weight: [2.54055062 1.34114797] Bias: -1.1240571535628883 loss: 0.3341164105577927\n",
            "Round: 1737 Weight: [2.54058483 1.34116563] Bias: -1.1240700327929734 loss: 0.3341163940152177\n",
            "Round: 1738 Weight: [2.54061896 1.34118324] Bias: -1.1240828804327538 loss: 0.33411637755359047\n",
            "Round: 1739 Weight: [2.54065301 1.3412008 ] Bias: -1.1240956965608082 loss: 0.3341163611725123\n",
            "Round: 1740 Weight: [2.54068698 1.34121833] Bias: -1.1241084812555135 loss: 0.3341163448715865\n",
            "Round: 1741 Weight: [2.54072086 1.34123581] Bias: -1.1241212345950469 loss: 0.3341163286504184\n",
            "Round: 1742 Weight: [2.54075466 1.34125325] Bias: -1.1241339566573856 loss: 0.3341163125086153\n",
            "Round: 1743 Weight: [2.54078837 1.34127064] Bias: -1.1241466475203077 loss: 0.3341162964457864\n",
            "Round: 1744 Weight: [2.540822 1.341288] Bias: -1.1241593072613927 loss: 0.33411628046154285\n",
            "Round: 1745 Weight: [2.54085555 1.34130531] Bias: -1.1241719359580218 loss: 0.33411626455549803\n",
            "Round: 1746 Weight: [2.54088902 1.34132257] Bias: -1.1241845336873788 loss: 0.33411624872726664\n",
            "Round: 1747 Weight: [2.54092241 1.3413398 ] Bias: -1.1241971005264502 loss: 0.3341162329764656\n",
            "Round: 1748 Weight: [2.54095571 1.34135698] Bias: -1.124209636552026 loss: 0.33411621730271385\n",
            "Round: 1749 Weight: [2.54098894 1.34137412] Bias: -1.1242221418407004 loss: 0.33411620170563244\n",
            "Round: 1750 Weight: [2.54102208 1.34139122] Bias: -1.1242346164688717 loss: 0.33411618618484346\n",
            "Round: 1751 Weight: [2.54105514 1.34140828] Bias: -1.1242470605127435 loss: 0.3341161707399717\n",
            "Round: 1752 Weight: [2.54108812 1.3414253 ] Bias: -1.124259474048325 loss: 0.3341161553706435\n",
            "Round: 1753 Weight: [2.54112102 1.34144227] Bias: -1.124271857151431 loss: 0.33411614007648704\n",
            "Round: 1754 Weight: [2.54115384 1.3414592 ] Bias: -1.1242842098976835 loss: 0.3341161248571324\n",
            "Round: 1755 Weight: [2.54118657 1.3414761 ] Bias: -1.1242965323625116 loss: 0.33411610971221156\n",
            "Round: 1756 Weight: [2.54121923 1.34149294] Bias: -1.1243088246211514 loss: 0.33411609464135805\n",
            "Round: 1757 Weight: [2.54125181 1.34150975] Bias: -1.124321086748648 loss: 0.33411607964420764\n",
            "Round: 1758 Weight: [2.54128431 1.34152652] Bias: -1.124333318819854 loss: 0.33411606472039757\n",
            "Round: 1759 Weight: [2.54131673 1.34154325] Bias: -1.1243455209094324 loss: 0.334116049869567\n",
            "Round: 1760 Weight: [2.54134907 1.34155993] Bias: -1.124357693091855 loss: 0.3341160350913569\n",
            "Round: 1761 Weight: [2.54138133 1.34157658] Bias: -1.1243698354414045 loss: 0.33411602038541\n",
            "Round: 1762 Weight: [2.54141351 1.34159318] Bias: -1.1243819480321735 loss: 0.33411600575137074\n",
            "Round: 1763 Weight: [2.54144561 1.34160974] Bias: -1.1243940309380664 loss: 0.3341159911888856\n",
            "Round: 1764 Weight: [2.54147763 1.34162627] Bias: -1.124406084232799 loss: 0.3341159766976023\n",
            "Round: 1765 Weight: [2.54150958 1.34164275] Bias: -1.1244181079898994 loss: 0.3341159622771709\n",
            "Round: 1766 Weight: [2.54154145 1.34165919] Bias: -1.1244301022827086 loss: 0.3341159479272427\n",
            "Round: 1767 Weight: [2.54157324 1.34167559] Bias: -1.1244420671843804 loss: 0.334115933647471\n",
            "Round: 1768 Weight: [2.54160495 1.34169195] Bias: -1.1244540027678827 loss: 0.33411591943751073\n",
            "Round: 1769 Weight: [2.54163658 1.34170827] Bias: -1.1244659091059972 loss: 0.3341159052970187\n",
            "Round: 1770 Weight: [2.54166814 1.34172456] Bias: -1.1244777862713207 loss: 0.3341158912256532\n",
            "Round: 1771 Weight: [2.54169962 1.3417408 ] Bias: -1.124489634336265 loss: 0.33411587722307434\n",
            "Round: 1772 Weight: [2.54173102 1.341757  ] Bias: -1.1245014533730575 loss: 0.3341158632889438\n",
            "Round: 1773 Weight: [2.54176235 1.34177316] Bias: -1.1245132434537422 loss: 0.33411584942292505\n",
            "Round: 1774 Weight: [2.54179359 1.34178928] Bias: -1.1245250046501791 loss: 0.33411583562468333\n",
            "Round: 1775 Weight: [2.54182477 1.34180537] Bias: -1.124536737034046 loss: 0.33411582189388495\n",
            "Round: 1776 Weight: [2.54185586 1.34182141] Bias: -1.1245484406768378 loss: 0.3341158082301989\n",
            "Round: 1777 Weight: [2.54188688 1.34183742] Bias: -1.124560115649868 loss: 0.3341157946332948\n",
            "Round: 1778 Weight: [2.54191783 1.34185338] Bias: -1.1245717620242681 loss: 0.33411578110284473\n",
            "Round: 1779 Weight: [2.5419487  1.34186931] Bias: -1.1245833798709897 loss: 0.33411576763852174\n",
            "Round: 1780 Weight: [2.54197949 1.34188519] Bias: -1.124594969260803 loss: 0.334115754240001\n",
            "Round: 1781 Weight: [2.54201021 1.34190104] Bias: -1.124606530264299 loss: 0.3341157409069587\n",
            "Round: 1782 Weight: [2.54204085 1.34191685] Bias: -1.1246180629518883 loss: 0.3341157276390733\n",
            "Round: 1783 Weight: [2.54207142 1.34193262] Bias: -1.1246295673938036 loss: 0.3341157144360245\n",
            "Round: 1784 Weight: [2.54210191 1.34194836] Bias: -1.1246410436600984 loss: 0.3341157012974936\n",
            "Round: 1785 Weight: [2.54213233 1.34196405] Bias: -1.1246524918206484 loss: 0.3341156882231636\n",
            "Round: 1786 Weight: [2.54216267 1.34197971] Bias: -1.1246639119451518 loss: 0.33411567521271895\n",
            "Round: 1787 Weight: [2.54219294 1.34199532] Bias: -1.1246753041031294 loss: 0.33411566226584566\n",
            "Round: 1788 Weight: [2.54222314 1.3420109 ] Bias: -1.1246866683639258 loss: 0.3341156493822313\n",
            "Round: 1789 Weight: [2.54225326 1.34202644] Bias: -1.1246980047967092 loss: 0.3341156365615653\n",
            "Round: 1790 Weight: [2.54228331 1.34204195] Bias: -1.1247093134704722 loss: 0.3341156238035381\n",
            "Round: 1791 Weight: [2.54231328 1.34205741] Bias: -1.1247205944540322 loss: 0.33411561110784194\n",
            "Round: 1792 Weight: [2.54234318 1.34207284] Bias: -1.1247318478160317 loss: 0.3341155984741708\n",
            "Round: 1793 Weight: [2.54237301 1.34208823] Bias: -1.1247430736249393 loss: 0.33411558590221974\n",
            "Round: 1794 Weight: [2.54240277 1.34210358] Bias: -1.1247542719490493 loss: 0.33411557339168546\n",
            "Round: 1795 Weight: [2.54243245 1.34211889] Bias: -1.1247654428564828 loss: 0.3341155609422666\n",
            "Round: 1796 Weight: [2.54246206 1.34213417] Bias: -1.1247765864151884 loss: 0.3341155485536627\n",
            "Round: 1797 Weight: [2.5424916  1.34214941] Bias: -1.1247877026929416 loss: 0.334115536225575\n",
            "Round: 1798 Weight: [2.54252106 1.34216461] Bias: -1.1247987917573463 loss: 0.33411552395770644\n",
            "Round: 1799 Weight: [2.54255046 1.34217978] Bias: -1.124809853675835 loss: 0.33411551174976106\n",
            "Round: 1800 Weight: [2.54257978 1.34219491] Bias: -1.124820888515669 loss: 0.33411549960144454\n",
            "Round: 1801 Weight: [2.54260903 1.34221   ] Bias: -1.1248318963439385 loss: 0.3341154875124641\n",
            "Round: 1802 Weight: [2.54263821 1.34222505] Bias: -1.1248428772275645 loss: 0.33411547548252846\n",
            "Round: 1803 Weight: [2.54266731 1.34224007] Bias: -1.1248538312332974 loss: 0.33411546351134735\n",
            "Round: 1804 Weight: [2.54269635 1.34225505] Bias: -1.1248647584277187 loss: 0.3341154515986326\n",
            "Round: 1805 Weight: [2.54272532 1.34226999] Bias: -1.1248756588772413 loss: 0.3341154397440968\n",
            "Round: 1806 Weight: [2.54275421 1.3422849 ] Bias: -1.1248865326481092 loss: 0.3341154279474544\n",
            "Round: 1807 Weight: [2.54278303 1.34229977] Bias: -1.1248973798063993 loss: 0.3341154162084211\n",
            "Round: 1808 Weight: [2.54281179 1.34231461] Bias: -1.12490820041802 loss: 0.3341154045267141\n",
            "Round: 1809 Weight: [2.54284047 1.3423294 ] Bias: -1.1249189945487132 loss: 0.3341153929020519\n",
            "Round: 1810 Weight: [2.54286908 1.34234417] Bias: -1.1249297622640546 loss: 0.33411538133415447\n",
            "Round: 1811 Weight: [2.54289762 1.34235889] Bias: -1.124940503629453 loss: 0.33411536982274315\n",
            "Round: 1812 Weight: [2.5429261  1.34237358] Bias: -1.124951218710152 loss: 0.3341153583675405\n",
            "Round: 1813 Weight: [2.5429545  1.34238824] Bias: -1.1249619075712294 loss: 0.3341153469682708\n",
            "Round: 1814 Weight: [2.54298283 1.34240285] Bias: -1.1249725702775988 loss: 0.33411533562465934\n",
            "Round: 1815 Weight: [2.5430111  1.34241744] Bias: -1.1249832068940089 loss: 0.3341153243364329\n",
            "Round: 1816 Weight: [2.5430393  1.34243198] Bias: -1.1249938174850447 loss: 0.33411531310331966\n",
            "Round: 1817 Weight: [2.54306742 1.3424465 ] Bias: -1.1250044021151278 loss: 0.3341153019250492\n",
            "Round: 1818 Weight: [2.54309548 1.34246097] Bias: -1.1250149608485163 loss: 0.33411529080135227\n",
            "Round: 1819 Weight: [2.54312347 1.34247541] Bias: -1.1250254937493058 loss: 0.3341152797319609\n",
            "Round: 1820 Weight: [2.54315139 1.34248982] Bias: -1.1250360008814297 loss: 0.33411526871660885\n",
            "Round: 1821 Weight: [2.54317924 1.34250419] Bias: -1.1250464823086597 loss: 0.33411525775503087\n",
            "Round: 1822 Weight: [2.54320703 1.34251852] Bias: -1.1250569380946056 loss: 0.3341152468469629\n",
            "Round: 1823 Weight: [2.54323475 1.34253282] Bias: -1.125067368302717 loss: 0.33411523599214255\n",
            "Round: 1824 Weight: [2.54326239 1.34254709] Bias: -1.1250777729962824 loss: 0.3341152251903083\n",
            "Round: 1825 Weight: [2.54328998 1.34256132] Bias: -1.1250881522384304 loss: 0.3341152144412005\n",
            "Round: 1826 Weight: [2.54331749 1.34257551] Bias: -1.12509850609213 loss: 0.33411520374456016\n",
            "Round: 1827 Weight: [2.54334494 1.34258967] Bias: -1.1251088346201905 loss: 0.33411519310012994\n",
            "Round: 1828 Weight: [2.54337232 1.3426038 ] Bias: -1.125119137885263 loss: 0.33411518250765376\n",
            "Round: 1829 Weight: [2.54339963 1.34261789] Bias: -1.1251294159498397 loss: 0.33411517196687673\n",
            "Round: 1830 Weight: [2.54342688 1.34263195] Bias: -1.125139668876255 loss: 0.33411516147754505\n",
            "Round: 1831 Weight: [2.54345406 1.34264597] Bias: -1.1251498967266853 loss: 0.33411515103940653\n",
            "Round: 1832 Weight: [2.54348117 1.34265996] Bias: -1.1251600995631506 loss: 0.3341151406522101\n",
            "Round: 1833 Weight: [2.54350822 1.34267391] Bias: -1.1251702774475132 loss: 0.33411513031570556\n",
            "Round: 1834 Weight: [2.5435352  1.34268783] Bias: -1.1251804304414799 loss: 0.33411512002964466\n",
            "Round: 1835 Weight: [2.54356211 1.34270172] Bias: -1.1251905586066009 loss: 0.33411510979377973\n",
            "Round: 1836 Weight: [2.54358896 1.34271557] Bias: -1.1252006620042712 loss: 0.33411509960786473\n",
            "Round: 1837 Weight: [2.54361575 1.34272939] Bias: -1.1252107406957306 loss: 0.33411508947165447\n",
            "Round: 1838 Weight: [2.54364247 1.34274318] Bias: -1.1252207947420643 loss: 0.3341150793849054\n",
            "Round: 1839 Weight: [2.54366912 1.34275693] Bias: -1.1252308242042028 loss: 0.3341150693473747\n",
            "Round: 1840 Weight: [2.54369571 1.34277064] Bias: -1.1252408291429234 loss: 0.33411505935882135\n",
            "Round: 1841 Weight: [2.54372223 1.34278433] Bias: -1.1252508096188494 loss: 0.3341150494190049\n",
            "Round: 1842 Weight: [2.54374869 1.34279798] Bias: -1.1252607656924507 loss: 0.3341150395276864\n",
            "Round: 1843 Weight: [2.54377508 1.3428116 ] Bias: -1.1252706974240452 loss: 0.3341150296846282\n",
            "Round: 1844 Weight: [2.54380141 1.34282518] Bias: -1.1252806048737982 loss: 0.3341150198895935\n",
            "Round: 1845 Weight: [2.54382768 1.34283873] Bias: -1.1252904881017232 loss: 0.334115010142347\n",
            "Round: 1846 Weight: [2.54385388 1.34285225] Bias: -1.125300347167682 loss: 0.33411500044265424\n",
            "Round: 1847 Weight: [2.54388002 1.34286573] Bias: -1.1253101821313853 loss: 0.3341149907902822\n",
            "Round: 1848 Weight: [2.54390609 1.34287918] Bias: -1.1253199930523936 loss: 0.33411498118499877\n",
            "Round: 1849 Weight: [2.5439321 1.3428926] Bias: -1.1253297799901165 loss: 0.33411497162657317\n",
            "Round: 1850 Weight: [2.54395804 1.34290599] Bias: -1.125339543003814 loss: 0.33411496211477565\n",
            "Round: 1851 Weight: [2.54398393 1.34291934] Bias: -1.1253492821525963 loss: 0.3341149526493778\n",
            "Round: 1852 Weight: [2.54400975 1.34293266] Bias: -1.125358997495425 loss: 0.33411494323015184\n",
            "Round: 1853 Weight: [2.5440355  1.34294595] Bias: -1.1253686890911125 loss: 0.3341149338568718\n",
            "Round: 1854 Weight: [2.5440612  1.34295921] Bias: -1.1253783569983231 loss: 0.33411492452931246\n",
            "Round: 1855 Weight: [2.54408683 1.34297243] Bias: -1.125388001275573 loss: 0.33411491524724946\n",
            "Round: 1856 Weight: [2.54411239 1.34298562] Bias: -1.125397621981231 loss: 0.33411490601045996\n",
            "Round: 1857 Weight: [2.5441379  1.34299878] Bias: -1.1254072191735185 loss: 0.33411489681872214\n",
            "Round: 1858 Weight: [2.54416334 1.34301191] Bias: -1.1254167929105103 loss: 0.3341148876718151\n",
            "Round: 1859 Weight: [2.54418873 1.343025  ] Bias: -1.125426343250135 loss: 0.3341148785695192\n",
            "Round: 1860 Weight: [2.54421405 1.34303806] Bias: -1.1254358702501746 loss: 0.33411486951161595\n",
            "Round: 1861 Weight: [2.5442393 1.3430511] Bias: -1.1254453739682657 loss: 0.3341148604978876\n",
            "Round: 1862 Weight: [2.5442645  1.34306409] Bias: -1.1254548544619 loss: 0.33411485152811765\n",
            "Round: 1863 Weight: [2.54428963 1.34307706] Bias: -1.1254643117884242 loss: 0.33411484260209107\n",
            "Round: 1864 Weight: [2.54431471 1.34309   ] Bias: -1.12547374600504 loss: 0.3341148337195932\n",
            "Round: 1865 Weight: [2.54433972 1.3431029 ] Bias: -1.1254831571688053 loss: 0.3341148248804108\n",
            "Round: 1866 Weight: [2.54436467 1.34311577] Bias: -1.1254925453366345 loss: 0.3341148160843317\n",
            "Round: 1867 Weight: [2.54438956 1.34312862] Bias: -1.1255019105652984 loss: 0.33411480733114474\n",
            "Round: 1868 Weight: [2.54441439 1.34314143] Bias: -1.1255112529114246 loss: 0.3341147986206397\n",
            "Round: 1869 Weight: [2.54443916 1.3431542 ] Bias: -1.1255205724314987 loss: 0.33411478995260774\n",
            "Round: 1870 Weight: [2.54446387 1.34316695] Bias: -1.1255298691818634 loss: 0.3341147813268405\n",
            "Round: 1871 Weight: [2.54448851 1.34317967] Bias: -1.1255391432187198 loss: 0.3341147727431311\n",
            "Round: 1872 Weight: [2.5445131  1.34319235] Bias: -1.1255483945981277 loss: 0.33411476420127345\n",
            "Round: 1873 Weight: [2.54453763 1.34320501] Bias: -1.1255576233760054 loss: 0.33411475570106264\n",
            "Round: 1874 Weight: [2.5445621  1.34321763] Bias: -1.1255668296081305 loss: 0.33411474724229456\n",
            "Round: 1875 Weight: [2.5445865  1.34323022] Bias: -1.1255760133501405 loss: 0.3341147388247663\n",
            "Round: 1876 Weight: [2.54461085 1.34324278] Bias: -1.1255851746575325 loss: 0.33411473044827583\n",
            "Round: 1877 Weight: [2.54463514 1.34325532] Bias: -1.1255943135856643 loss: 0.33411472211262216\n",
            "Round: 1878 Weight: [2.54465937 1.34326782] Bias: -1.1256034301897542 loss: 0.3341147138176054\n",
            "Round: 1879 Weight: [2.54468354 1.34328029] Bias: -1.1256125245248816 loss: 0.3341147055630265\n",
            "Round: 1880 Weight: [2.54470766 1.34329273] Bias: -1.1256215966459873 loss: 0.3341146973486874\n",
            "Round: 1881 Weight: [2.54473171 1.34330513] Bias: -1.1256306466078738 loss: 0.33411468917439097\n",
            "Round: 1882 Weight: [2.5447557  1.34331751] Bias: -1.125639674465206 loss: 0.3341146810399413\n",
            "Round: 1883 Weight: [2.54477964 1.34332986] Bias: -1.125648680272511 loss: 0.33411467294514313\n",
            "Round: 1884 Weight: [2.54480352 1.34334218] Bias: -1.125657664084179 loss: 0.3341146648898023\n",
            "Round: 1885 Weight: [2.54482734 1.34335447] Bias: -1.1256666259544637 loss: 0.3341146568737258\n",
            "Round: 1886 Weight: [2.5448511  1.34336673] Bias: -1.1256755659374815 loss: 0.33411464889672116\n",
            "Round: 1887 Weight: [2.5448748  1.34337896] Bias: -1.1256844840872136 loss: 0.33411464095859733\n",
            "Round: 1888 Weight: [2.54489844 1.34339116] Bias: -1.125693380457505 loss: 0.3341146330591638\n",
            "Round: 1889 Weight: [2.54492203 1.34340332] Bias: -1.125702255102066 loss: 0.3341146251982311\n",
            "Round: 1890 Weight: [2.54494556 1.34341546] Bias: -1.1257111080744708 loss: 0.33411461737561077\n",
            "Round: 1891 Weight: [2.54496903 1.34342757] Bias: -1.12571993942816 loss: 0.3341146095911154\n",
            "Round: 1892 Weight: [2.54499245 1.34343965] Bias: -1.1257287492164394 loss: 0.3341146018445582\n",
            "Round: 1893 Weight: [2.54501581 1.3434517 ] Bias: -1.125737537492481 loss: 0.3341145941357535\n",
            "Round: 1894 Weight: [2.54503911 1.34346373] Bias: -1.125746304309323 loss: 0.33411458646451664\n",
            "Round: 1895 Weight: [2.54506235 1.34347572] Bias: -1.1257550497198707 loss: 0.33411457883066353\n",
            "Round: 1896 Weight: [2.54508554 1.34348768] Bias: -1.1257637737768962 loss: 0.3341145712340114\n",
            "Round: 1897 Weight: [2.54510867 1.34349961] Bias: -1.125772476533039 loss: 0.3341145636743781\n",
            "Round: 1898 Weight: [2.54513175 1.34351152] Bias: -1.1257811580408068 loss: 0.33411455615158225\n",
            "Round: 1899 Weight: [2.54515477 1.34352339] Bias: -1.125789818352575 loss: 0.33411454866544393\n",
            "Round: 1900 Weight: [2.54517773 1.34353524] Bias: -1.1257984575205875 loss: 0.33411454121578343\n",
            "Round: 1901 Weight: [2.54520063 1.34354706] Bias: -1.1258070755969574 loss: 0.3341145338024224\n",
            "Round: 1902 Weight: [2.54522348 1.34355885] Bias: -1.1258156726336666 loss: 0.3341145264251831\n",
            "Round: 1903 Weight: [2.54524628 1.34357061] Bias: -1.1258242486825667 loss: 0.3341145190838889\n",
            "Round: 1904 Weight: [2.54526902 1.34358234] Bias: -1.1258328037953789 loss: 0.33411451177836377\n",
            "Round: 1905 Weight: [2.5452917  1.34359404] Bias: -1.125841338023695 loss: 0.3341145045084327\n",
            "Round: 1906 Weight: [2.54531433 1.34360572] Bias: -1.1258498514189765 loss: 0.33411449727392173\n",
            "Round: 1907 Weight: [2.5453369  1.34361736] Bias: -1.125858344032557 loss: 0.3341144900746573\n",
            "Round: 1908 Weight: [2.54535942 1.34362898] Bias: -1.12586681591564 loss: 0.33411448291046714\n",
            "Round: 1909 Weight: [2.54538189 1.34364057] Bias: -1.1258752671193013 loss: 0.3341144757811796\n",
            "Round: 1910 Weight: [2.54540429 1.34365213] Bias: -1.1258836976944884 loss: 0.33411446868662376\n",
            "Round: 1911 Weight: [2.54542665 1.34366366] Bias: -1.125892107692021 loss: 0.33411446162662994\n",
            "Round: 1912 Weight: [2.54544895 1.34367516] Bias: -1.125900497162591 loss: 0.3341144546010289\n",
            "Round: 1913 Weight: [2.54547119 1.34368664] Bias: -1.1259088661567636 loss: 0.3341144476096524\n",
            "Round: 1914 Weight: [2.54549338 1.34369809] Bias: -1.125917214724977 loss: 0.33411444065233314\n",
            "Round: 1915 Weight: [2.54551552 1.34370951] Bias: -1.1259255429175428 loss: 0.3341144337289045\n",
            "Round: 1916 Weight: [2.5455376 1.3437209] Bias: -1.1259338507846466 loss: 0.3341144268392007\n",
            "Round: 1917 Weight: [2.54555963 1.34373227] Bias: -1.125942138376348 loss: 0.3341144199830566\n",
            "Round: 1918 Weight: [2.54558161 1.3437436 ] Bias: -1.125950405742581 loss: 0.3341144131603082\n",
            "Round: 1919 Weight: [2.54560353 1.34375491] Bias: -1.1259586529331551 loss: 0.33411440637079215\n",
            "Round: 1920 Weight: [2.54562539 1.34376619] Bias: -1.1259668799977542 loss: 0.334114399614346\n",
            "Round: 1921 Weight: [2.54564721 1.34377745] Bias: -1.125975086985938 loss: 0.3341143928908079\n",
            "Round: 1922 Weight: [2.54566897 1.34378868] Bias: -1.1259832739471416 loss: 0.3341143862000169\n",
            "Round: 1923 Weight: [2.54569068 1.34379988] Bias: -1.1259914409306768 loss: 0.3341143795418129\n",
            "Round: 1924 Weight: [2.54571234 1.34381105] Bias: -1.1259995879857314 loss: 0.33411437291603646\n",
            "Round: 1925 Weight: [2.54573394 1.34382219] Bias: -1.12600771516137 loss: 0.3341143663225292\n",
            "Round: 1926 Weight: [2.54575549 1.34383331] Bias: -1.1260158225065346 loss: 0.33411435976113313\n",
            "Round: 1927 Weight: [2.54577699 1.3438444 ] Bias: -1.1260239100700442 loss: 0.33411435323169125\n",
            "Round: 1928 Weight: [2.54579843 1.34385546] Bias: -1.1260319779005956 loss: 0.33411434673404755\n",
            "Round: 1929 Weight: [2.54581982 1.3438665 ] Bias: -1.1260400260467638 loss: 0.3341143402680462\n",
            "Round: 1930 Weight: [2.54584116 1.34387751] Bias: -1.126048054557002 loss: 0.3341143338335327\n",
            "Round: 1931 Weight: [2.54586245 1.34388849] Bias: -1.126056063479642 loss: 0.33411432743035296\n",
            "Round: 1932 Weight: [2.54588369 1.34389945] Bias: -1.1260640528628947 loss: 0.33411432105835387\n",
            "Round: 1933 Weight: [2.54590488 1.34391038] Bias: -1.1260720227548502 loss: 0.33411431471738307\n",
            "Round: 1934 Weight: [2.54592601 1.34392128] Bias: -1.126079973203478 loss: 0.3341143084072886\n",
            "Round: 1935 Weight: [2.54594709 1.34393216] Bias: -1.126087904256628 loss: 0.3341143021279198\n",
            "Round: 1936 Weight: [2.54596812 1.34394301] Bias: -1.12609581596203 loss: 0.33411429587912644\n",
            "Round: 1937 Weight: [2.5459891  1.34395383] Bias: -1.126103708367294 loss: 0.33411428966075896\n",
            "Round: 1938 Weight: [2.54601003 1.34396463] Bias: -1.1261115815199116 loss: 0.3341142834726686\n",
            "Round: 1939 Weight: [2.54603091 1.3439754 ] Bias: -1.126119435467255 loss: 0.33411427731470733\n",
            "Round: 1940 Weight: [2.54605173 1.34398614] Bias: -1.1261272702565779 loss: 0.33411427118672793\n",
            "Round: 1941 Weight: [2.54607251 1.34399686] Bias: -1.1261350859350157 loss: 0.33411426508858405\n",
            "Round: 1942 Weight: [2.54609323 1.34400755] Bias: -1.1261428825495863 loss: 0.33411425902012953\n",
            "Round: 1943 Weight: [2.54611391 1.34401822] Bias: -1.1261506601471893 loss: 0.3341142529812194\n",
            "Round: 1944 Weight: [2.54613453 1.34402886] Bias: -1.1261584187746077 loss: 0.3341142469717094\n",
            "Round: 1945 Weight: [2.5461551  1.34403947] Bias: -1.1261661584785068 loss: 0.33411424099145554\n",
            "Round: 1946 Weight: [2.54617563 1.34405006] Bias: -1.1261738793054357 loss: 0.3341142350403152\n",
            "Round: 1947 Weight: [2.5461961  1.34406062] Bias: -1.1261815813018266 loss: 0.33411422911814576\n",
            "Round: 1948 Weight: [2.54621653 1.34407116] Bias: -1.126189264513996 loss: 0.33411422322480594\n",
            "Round: 1949 Weight: [2.5462369  1.34408167] Bias: -1.1261969289881444 loss: 0.33411421736015456\n",
            "Round: 1950 Weight: [2.54625722 1.34409216] Bias: -1.1262045747703566 loss: 0.33411421152405174\n",
            "Round: 1951 Weight: [2.5462775  1.34410262] Bias: -1.1262122019066025 loss: 0.33411420571635775\n",
            "Round: 1952 Weight: [2.54629772 1.34411305] Bias: -1.126219810442737 loss: 0.3341141999369338\n",
            "Round: 1953 Weight: [2.5463179  1.34412346] Bias: -1.1262274004245 loss: 0.33411419418564187\n",
            "Round: 1954 Weight: [2.54633803 1.34413384] Bias: -1.1262349718975178 loss: 0.3341141884623445\n",
            "Round: 1955 Weight: [2.54635811 1.3441442 ] Bias: -1.1262425249073018 loss: 0.33411418276690474\n",
            "Round: 1956 Weight: [2.54637813 1.34415453] Bias: -1.1262500594992502 loss: 0.33411417709918667\n",
            "Round: 1957 Weight: [2.54639811 1.34416484] Bias: -1.1262575757186475 loss: 0.3341141714590547\n",
            "Round: 1958 Weight: [2.54641805 1.34417512] Bias: -1.1262650736106654 loss: 0.33411416584637416\n",
            "Round: 1959 Weight: [2.54643793 1.34418538] Bias: -1.1262725532203623 loss: 0.3341141602610109\n",
            "Round: 1960 Weight: [2.54645776 1.34419561] Bias: -1.1262800145926841 loss: 0.33411415470283135\n",
            "Round: 1961 Weight: [2.54647755 1.34420582] Bias: -1.1262874577724646 loss: 0.334114149171703\n",
            "Round: 1962 Weight: [2.54649729 1.344216  ] Bias: -1.1262948828044257 loss: 0.3341141436674935\n",
            "Round: 1963 Weight: [2.54651698 1.34422616] Bias: -1.126302289733177 loss: 0.33411413819007135\n",
            "Round: 1964 Weight: [2.54653662 1.3442363 ] Bias: -1.1263096786032172 loss: 0.33411413273930574\n",
            "Round: 1965 Weight: [2.54655621 1.3442464 ] Bias: -1.1263170494589338 loss: 0.3341141273150665\n",
            "Round: 1966 Weight: [2.54657576 1.34425649] Bias: -1.1263244023446035 loss: 0.33411412191722406\n",
            "Round: 1967 Weight: [2.54659526 1.34426655] Bias: -1.126331737304392 loss: 0.3341141165456495\n",
            "Round: 1968 Weight: [2.54661471 1.34427658] Bias: -1.1263390543823553 loss: 0.3341141112002144\n",
            "Round: 1969 Weight: [2.54663411 1.34428659] Bias: -1.126346353622439 loss: 0.3341141058807911\n",
            "Round: 1970 Weight: [2.54665347 1.34429658] Bias: -1.126353635068479 loss: 0.3341141005872528\n",
            "Round: 1971 Weight: [2.54667278 1.34430654] Bias: -1.1263608987642022 loss: 0.33411409531947284\n",
            "Round: 1972 Weight: [2.54669204 1.34431648] Bias: -1.1263681447532257 loss: 0.33411409007732557\n",
            "Round: 1973 Weight: [2.54671126 1.34432639] Bias: -1.1263753730790582 loss: 0.3341140848606856\n",
            "Round: 1974 Weight: [2.54673043 1.34433628] Bias: -1.1263825837850996 loss: 0.33411407966942863\n",
            "Round: 1975 Weight: [2.54674955 1.34434614] Bias: -1.1263897769146416 loss: 0.33411407450343045\n",
            "Round: 1976 Weight: [2.54676863 1.34435599] Bias: -1.126396952510868 loss: 0.33411406936256793\n",
            "Round: 1977 Weight: [2.54678765 1.3443658 ] Bias: -1.1264041106168543 loss: 0.3341140642467182\n",
            "Round: 1978 Weight: [2.54680664 1.3443756 ] Bias: -1.1264112512755693 loss: 0.3341140591557593\n",
            "Round: 1979 Weight: [2.54682557 1.34438536] Bias: -1.126418374529874 loss: 0.33411405408956946\n",
            "Round: 1980 Weight: [2.54684446 1.34439511] Bias: -1.1264254804225227 loss: 0.334114049048028\n",
            "Round: 1981 Weight: [2.54686331 1.34440483] Bias: -1.126432568996163 loss: 0.33411404403101425\n",
            "Round: 1982 Weight: [2.54688211 1.34441453] Bias: -1.126439640293336 loss: 0.33411403903840864\n",
            "Round: 1983 Weight: [2.54690086 1.3444242 ] Bias: -1.1264466943564773 loss: 0.3341140340700921\n",
            "Round: 1984 Weight: [2.54691957 1.34443385] Bias: -1.1264537312279157 loss: 0.33411402912594584\n",
            "Round: 1985 Weight: [2.54693823 1.34444348] Bias: -1.1264607509498752 loss: 0.33411402420585196\n",
            "Round: 1986 Weight: [2.54695684 1.34445309] Bias: -1.1264677535644743 loss: 0.33411401930969314\n",
            "Round: 1987 Weight: [2.54697542 1.34446267] Bias: -1.1264747391137262 loss: 0.3341140144373523\n",
            "Round: 1988 Weight: [2.54699394 1.34447222] Bias: -1.1264817076395397 loss: 0.33411400958871335\n",
            "Round: 1989 Weight: [2.54701242 1.34448176] Bias: -1.126488659183719 loss: 0.33411400476366054\n",
            "Round: 1990 Weight: [2.54703086 1.34449127] Bias: -1.1264955937879642 loss: 0.33411399996207874\n",
            "Round: 1991 Weight: [2.54704925 1.34450076] Bias: -1.1265025114938712 loss: 0.33411399518385343\n",
            "Round: 1992 Weight: [2.54706759 1.34451022] Bias: -1.1265094123429324 loss: 0.3341139904288705\n",
            "Round: 1993 Weight: [2.54708589 1.34451966] Bias: -1.126516296376537 loss: 0.3341139856970164\n",
            "Round: 1994 Weight: [2.54710415 1.34452908] Bias: -1.1265231636359705 loss: 0.3341139809881786\n",
            "Round: 1995 Weight: [2.54712236 1.34453847] Bias: -1.126530014162416 loss: 0.33411397630224443\n",
            "Round: 1996 Weight: [2.54714053 1.34454785] Bias: -1.1265368479969535 loss: 0.33411397163910217\n",
            "Round: 1997 Weight: [2.54715865 1.3445572 ] Bias: -1.1265436651805614 loss: 0.3341139669986409\n",
            "Round: 1998 Weight: [2.54717673 1.34456652] Bias: -1.1265504657541154 loss: 0.3341139623807495\n",
            "Round: 1999 Weight: [2.54719477 1.34457583] Bias: -1.1265572497583896 loss: 0.33411395778531794\n",
            "Round: 2000 Weight: [2.54721276 1.34458511] Bias: -1.1265640172340563 loss: 0.33411395321223675\n",
            "Round: 2001 Weight: [2.54723071 1.34459437] Bias: -1.1265707682216868 loss: 0.3341139486613967\n",
            "Round: 2002 Weight: [2.54724861 1.3446036 ] Bias: -1.126577502761751 loss: 0.3341139441326893\n",
            "Round: 2003 Weight: [2.54726647 1.34461282] Bias: -1.1265842208946184 loss: 0.3341139396260067\n",
            "Round: 2004 Weight: [2.54728429 1.34462201] Bias: -1.1265909226605577 loss: 0.3341139351412412\n",
            "Round: 2005 Weight: [2.54730206 1.34463118] Bias: -1.1265976080997373 loss: 0.334113930678286\n",
            "Round: 2006 Weight: [2.54731979 1.34464033] Bias: -1.1266042772522258 loss: 0.33411392623703456\n",
            "Round: 2007 Weight: [2.54733748 1.34464945] Bias: -1.1266109301579919 loss: 0.33411392181738103\n",
            "Round: 2008 Weight: [2.54735512 1.34465855] Bias: -1.1266175668569047 loss: 0.3341139174192202\n",
            "Round: 2009 Weight: [2.54737272 1.34466763] Bias: -1.1266241873887344 loss: 0.33411391304244686\n",
            "Round: 2010 Weight: [2.54739028 1.34467669] Bias: -1.1266307917931517 loss: 0.33411390868695695\n",
            "Round: 2011 Weight: [2.5474078  1.34468573] Bias: -1.1266373801097291 loss: 0.3341139043526465\n",
            "Round: 2012 Weight: [2.54742527 1.34469474] Bias: -1.1266439523779401 loss: 0.3341139000394123\n",
            "Round: 2013 Weight: [2.5474427  1.34470373] Bias: -1.12665050863716 loss: 0.3341138957471513\n",
            "Round: 2014 Weight: [2.54746009 1.3447127 ] Bias: -1.1266570489266667 loss: 0.33411389147576137\n",
            "Round: 2015 Weight: [2.54747744 1.34472165] Bias: -1.1266635732856396 loss: 0.33411388722514074\n",
            "Round: 2016 Weight: [2.54749474 1.34473058] Bias: -1.126670081753161 loss: 0.3341138829951878\n",
            "Round: 2017 Weight: [2.547512   1.34473948] Bias: -1.1266765743682159 loss: 0.3341138787858021\n",
            "Round: 2018 Weight: [2.54752922 1.34474837] Bias: -1.1266830511696924 loss: 0.3341138745968831\n",
            "Round: 2019 Weight: [2.5475464  1.34475723] Bias: -1.1266895121963818 loss: 0.3341138704283309\n",
            "Round: 2020 Weight: [2.54756353 1.34476607] Bias: -1.1266959574869788 loss: 0.33411386628004636\n",
            "Round: 2021 Weight: [2.54758063 1.34477489] Bias: -1.126702387080082 loss: 0.33411386215193045\n",
            "Round: 2022 Weight: [2.54759768 1.34478368] Bias: -1.126708801014194 loss: 0.3341138580438848\n",
            "Round: 2023 Weight: [2.54761469 1.34479246] Bias: -1.1267151993277211 loss: 0.3341138539558117\n",
            "Round: 2024 Weight: [2.54763166 1.34480121] Bias: -1.126721582058975 loss: 0.3341138498876137\n",
            "Round: 2025 Weight: [2.54764859 1.34480995] Bias: -1.1267279492461717 loss: 0.3341138458391936\n",
            "Round: 2026 Weight: [2.54766547 1.34481866] Bias: -1.1267343009274318 loss: 0.3341138418104552\n",
            "Round: 2027 Weight: [2.54768232 1.34482735] Bias: -1.1267406371407815 loss: 0.33411383780130244\n",
            "Round: 2028 Weight: [2.54769912 1.34483602] Bias: -1.1267469579241527 loss: 0.3341138338116398\n",
            "Round: 2029 Weight: [2.54771589 1.34484467] Bias: -1.1267532633153825 loss: 0.3341138298413721\n",
            "Round: 2030 Weight: [2.54773261 1.34485329] Bias: -1.1267595533522143 loss: 0.3341138258904049\n",
            "Round: 2031 Weight: [2.54774929 1.3448619 ] Bias: -1.1267658280722976 loss: 0.3341138219586442\n",
            "Round: 2032 Weight: [2.54776594 1.34487048] Bias: -1.1267720875131881 loss: 0.33411381804599605\n",
            "Round: 2033 Weight: [2.54778254 1.34487905] Bias: -1.1267783317123483 loss: 0.3341138141523675\n",
            "Round: 2034 Weight: [2.5477991  1.34488759] Bias: -1.1267845607071476 loss: 0.33411381027766573\n",
            "Round: 2035 Weight: [2.54781562 1.34489612] Bias: -1.1267907745348626 loss: 0.33411380642179833\n",
            "Round: 2036 Weight: [2.5478321  1.34490462] Bias: -1.1267969732326772 loss: 0.33411380258467366\n",
            "Round: 2037 Weight: [2.54784854 1.3449131 ] Bias: -1.1268031568376828 loss: 0.33411379876620023\n",
            "Round: 2038 Weight: [2.54786494 1.34492156] Bias: -1.126809325386879 loss: 0.334113794966287\n",
            "Round: 2039 Weight: [2.5478813 1.34493  ] Bias: -1.126815478917173 loss: 0.3341137911848437\n",
            "Round: 2040 Weight: [2.54789762 1.34493842] Bias: -1.1268216174653807 loss: 0.33411378742178\n",
            "Round: 2041 Weight: [2.5479139  1.34494682] Bias: -1.1268277410682261 loss: 0.3341137836770066\n",
            "Round: 2042 Weight: [2.54793014 1.3449552 ] Bias: -1.1268338497623427 loss: 0.3341137799504341\n",
            "Round: 2043 Weight: [2.54794634 1.34496355] Bias: -1.1268399435842722 loss: 0.3341137762419739\n",
            "Round: 2044 Weight: [2.54796251 1.34497189] Bias: -1.1268460225704662 loss: 0.3341137725515377\n",
            "Round: 2045 Weight: [2.54797863 1.34498021] Bias: -1.1268520867572853 loss: 0.3341137688790375\n",
            "Round: 2046 Weight: [2.54799471 1.34498851] Bias: -1.1268581361810002 loss: 0.33411376522438596\n",
            "Round: 2047 Weight: [2.54801076 1.34499678] Bias: -1.1268641708777911 loss: 0.334113761587496\n",
            "Round: 2048 Weight: [2.54802676 1.34500504] Bias: -1.1268701908837488 loss: 0.33411375796828113\n",
            "Round: 2049 Weight: [2.54804273 1.34501328] Bias: -1.1268761962348741 loss: 0.3341137543666551\n",
            "Round: 2050 Weight: [2.54805866 1.3450215 ] Bias: -1.1268821869670786 loss: 0.33411375078253236\n",
            "Round: 2051 Weight: [2.54807455 1.34502969] Bias: -1.126888163116185 loss: 0.3341137472158274\n",
            "Round: 2052 Weight: [2.5480904  1.34503787] Bias: -1.1268941247179265 loss: 0.3341137436664553\n",
            "Round: 2053 Weight: [2.54810621 1.34504603] Bias: -1.126900071807948 loss: 0.33411374013433165\n",
            "Round: 2054 Weight: [2.54812198 1.34505416] Bias: -1.126906004421806 loss: 0.33411373661937255\n",
            "Round: 2055 Weight: [2.54813772 1.34506228] Bias: -1.1269119225949686 loss: 0.334113733121494\n",
            "Round: 2056 Weight: [2.54815342 1.34507038] Bias: -1.126917826362816 loss: 0.3341137296406129\n",
            "Round: 2057 Weight: [2.54816908 1.34507846] Bias: -1.12692371576064 loss: 0.3341137261766466\n",
            "Round: 2058 Weight: [2.5481847  1.34508651] Bias: -1.1269295908236456 loss: 0.33411372272951234\n",
            "Round: 2059 Weight: [2.54820028 1.34509455] Bias: -1.1269354515869503 loss: 0.3341137192991283\n",
            "Round: 2060 Weight: [2.54821582 1.34510257] Bias: -1.1269412980855842 loss: 0.33411371588541283\n",
            "Round: 2061 Weight: [2.54823133 1.34511057] Bias: -1.1269471303544905 loss: 0.3341137124882847\n",
            "Round: 2062 Weight: [2.5482468  1.34511855] Bias: -1.126952948428526 loss: 0.334113709107663\n",
            "Round: 2063 Weight: [2.54826223 1.34512651] Bias: -1.1269587523424605 loss: 0.3341137057434673\n",
            "Round: 2064 Weight: [2.54827762 1.34513445] Bias: -1.1269645421309782 loss: 0.3341137023956177\n",
            "Round: 2065 Weight: [2.54829298 1.34514238] Bias: -1.126970317828677 loss: 0.3341136990640343\n",
            "Round: 2066 Weight: [2.5483083  1.34515028] Bias: -1.1269760794700687 loss: 0.33411369574863803\n",
            "Round: 2067 Weight: [2.54832358 1.34515816] Bias: -1.1269818270895802 loss: 0.3341136924493499\n",
            "Round: 2068 Weight: [2.54833883 1.34516603] Bias: -1.1269875607215523 loss: 0.3341136891660917\n",
            "Round: 2069 Weight: [2.54835403 1.34517387] Bias: -1.126993280400241 loss: 0.33411368589878493\n",
            "Round: 2070 Weight: [2.54836921 1.3451817 ] Bias: -1.126998986159817 loss: 0.33411368264735203\n",
            "Round: 2071 Weight: [2.54838434 1.34518951] Bias: -1.127004678034367 loss: 0.3341136794117156\n",
            "Round: 2072 Weight: [2.54839944 1.34519729] Bias: -1.1270103560578926 loss: 0.33411367619179894\n",
            "Round: 2073 Weight: [2.5484145  1.34520506] Bias: -1.1270160202643111 loss: 0.3341136729875252\n",
            "Round: 2074 Weight: [2.54842952 1.34521281] Bias: -1.127021670687456 loss: 0.3341136697988183\n",
            "Round: 2075 Weight: [2.54844451 1.34522055] Bias: -1.1270273073610768 loss: 0.3341136666256021\n",
            "Round: 2076 Weight: [2.54845946 1.34522826] Bias: -1.1270329303188393 loss: 0.3341136634678016\n",
            "Round: 2077 Weight: [2.54847437 1.34523595] Bias: -1.127038539594326 loss: 0.3341136603253414\n",
            "Round: 2078 Weight: [2.54848925 1.34524363] Bias: -1.127044135221036 loss: 0.3341136571981469\n",
            "Round: 2079 Weight: [2.54850409 1.34525128] Bias: -1.1270497172323855 loss: 0.3341136540861435\n",
            "Round: 2080 Weight: [2.5485189  1.34525892] Bias: -1.1270552856617078 loss: 0.33411365098925755\n",
            "Round: 2081 Weight: [2.54853367 1.34526654] Bias: -1.1270608405422535 loss: 0.33411364790741516\n",
            "Round: 2082 Weight: [2.5485484  1.34527414] Bias: -1.127066381907191 loss: 0.33411364484054307\n",
            "Round: 2083 Weight: [2.5485631  1.34528173] Bias: -1.1270719097896067 loss: 0.33411364178856845\n",
            "Round: 2084 Weight: [2.54857776 1.34528929] Bias: -1.1270774242225046 loss: 0.3341136387514187\n",
            "Round: 2085 Weight: [2.54859239 1.34529683] Bias: -1.127082925238807 loss: 0.3341136357290216\n",
            "Round: 2086 Weight: [2.54860698 1.34530436] Bias: -1.1270884128713552 loss: 0.3341136327213053\n",
            "Round: 2087 Weight: [2.54862154 1.34531187] Bias: -1.1270938871529084 loss: 0.3341136297281983\n",
            "Round: 2088 Weight: [2.54863606 1.34531936] Bias: -1.1270993481161449 loss: 0.33411362674962947\n",
            "Round: 2089 Weight: [2.54865054 1.34532683] Bias: -1.1271047957936622 loss: 0.3341136237855278\n",
            "Round: 2090 Weight: [2.54866499 1.34533429] Bias: -1.127110230217977 loss: 0.33411362083582313\n",
            "Round: 2091 Weight: [2.54867941 1.34534172] Bias: -1.1271156514215255 loss: 0.33411361790044525\n",
            "Round: 2092 Weight: [2.54869379 1.34534914] Bias: -1.1271210594366634 loss: 0.3341136149793241\n",
            "Round: 2093 Weight: [2.54870813 1.34535654] Bias: -1.1271264542956665 loss: 0.3341136120723908\n",
            "Round: 2094 Weight: [2.54872244 1.34536392] Bias: -1.1271318360307305 loss: 0.3341136091795758\n",
            "Round: 2095 Weight: [2.54873672 1.34537129] Bias: -1.1271372046739718 loss: 0.33411360630081044\n",
            "Round: 2096 Weight: [2.54875096 1.34537863] Bias: -1.1271425602574268 loss: 0.33411360343602636\n",
            "Round: 2097 Weight: [2.54876516 1.34538596] Bias: -1.1271479028130524 loss: 0.33411360058515566\n",
            "Round: 2098 Weight: [2.54877933 1.34539327] Bias: -1.1271532323727271 loss: 0.3341135977481301\n",
            "Round: 2099 Weight: [2.54879347 1.34540057] Bias: -1.12715854896825 loss: 0.3341135949248827\n",
            "Round: 2100 Weight: [2.54880757 1.34540784] Bias: -1.1271638526313417 loss: 0.33411359211534614\n",
            "Round: 2101 Weight: [2.54882164 1.3454151 ] Bias: -1.1271691433936442 loss: 0.33411358931945384\n",
            "Round: 2102 Weight: [2.54883567 1.34542234] Bias: -1.127174421286721 loss: 0.3341135865371393\n",
            "Round: 2103 Weight: [2.54884967 1.34542956] Bias: -1.1271796863420578 loss: 0.3341135837683363\n",
            "Round: 2104 Weight: [2.54886364 1.34543676] Bias: -1.1271849385910622 loss: 0.334113581012979\n",
            "Round: 2105 Weight: [2.54887757 1.34544395] Bias: -1.127190178065064 loss: 0.33411357827100213\n",
            "Round: 2106 Weight: [2.54889147 1.34545112] Bias: -1.1271954047953157 loss: 0.3341135755423406\n",
            "Round: 2107 Weight: [2.54890533 1.34545827] Bias: -1.1272006188129924 loss: 0.3341135728269293\n",
            "Round: 2108 Weight: [2.54891916 1.34546541] Bias: -1.1272058201491921 loss: 0.3341135701247039\n",
            "Round: 2109 Weight: [2.54893296 1.34547253] Bias: -1.1272110088349356 loss: 0.33411356743560017\n",
            "Round: 2110 Weight: [2.54894672 1.34547963] Bias: -1.1272161849011673 loss: 0.3341135647595543\n",
            "Round: 2111 Weight: [2.54896045 1.34548671] Bias: -1.1272213483787548 loss: 0.3341135620965025\n",
            "Round: 2112 Weight: [2.54897415 1.34549377] Bias: -1.1272264992984895 loss: 0.33411355944638177\n",
            "Round: 2113 Weight: [2.54898781 1.34550082] Bias: -1.1272316376910865 loss: 0.3341135568091289\n",
            "Round: 2114 Weight: [2.54900144 1.34550785] Bias: -1.127236763587185 loss: 0.3341135541846815\n",
            "Round: 2115 Weight: [2.54901504 1.34551487] Bias: -1.1272418770173485 loss: 0.3341135515729772\n",
            "Round: 2116 Weight: [2.5490286  1.34552186] Bias: -1.1272469780120649 loss: 0.33411354897395373\n",
            "Round: 2117 Weight: [2.54904213 1.34552884] Bias: -1.1272520666017465 loss: 0.33411354638754964\n",
            "Round: 2118 Weight: [2.54905563 1.34553581] Bias: -1.1272571428167306 loss: 0.33411354381370323\n",
            "Round: 2119 Weight: [2.5490691  1.34554275] Bias: -1.1272622066872795 loss: 0.33411354125235365\n",
            "Round: 2120 Weight: [2.54908253 1.34554968] Bias: -1.1272672582435803 loss: 0.33411353870343985\n",
            "Round: 2121 Weight: [2.54909593 1.3455566 ] Bias: -1.127272297515746 loss: 0.33411353616690154\n",
            "Round: 2122 Weight: [2.5491093  1.34556349] Bias: -1.127277324533815 loss: 0.3341135336426783\n",
            "Round: 2123 Weight: [2.54912263 1.34557037] Bias: -1.1272823393277511 loss: 0.3341135311307101\n",
            "Round: 2124 Weight: [2.54913593 1.34557723] Bias: -1.1272873419274445 loss: 0.3341135286309375\n",
            "Round: 2125 Weight: [2.5491492  1.34558408] Bias: -1.127292332362711 loss: 0.3341135261433011\n",
            "Round: 2126 Weight: [2.54916244 1.34559091] Bias: -1.1272973106632933 loss: 0.3341135236677418\n",
            "Round: 2127 Weight: [2.54917565 1.34559772] Bias: -1.12730227685886 loss: 0.3341135212042008\n",
            "Round: 2128 Weight: [2.54918882 1.34560452] Bias: -1.1273072309790069 loss: 0.3341135187526195\n",
            "Round: 2129 Weight: [2.54920196 1.34561129] Bias: -1.127312173053256 loss: 0.3341135163129399\n",
            "Round: 2130 Weight: [2.54921507 1.34561806] Bias: -1.1273171031110572 loss: 0.334113513885104\n",
            "Round: 2131 Weight: [2.54922815 1.3456248 ] Bias: -1.127322021181787 loss: 0.33411351146905416\n",
            "Round: 2132 Weight: [2.54924119 1.34563153] Bias: -1.1273269272947493 loss: 0.33411350906473314\n",
            "Round: 2133 Weight: [2.54925421 1.34563825] Bias: -1.1273318214791759 loss: 0.3341135066720836\n",
            "Round: 2134 Weight: [2.54926719 1.34564494] Bias: -1.1273367037642263 loss: 0.3341135042910488\n",
            "Round: 2135 Weight: [2.54928014 1.34565163] Bias: -1.1273415741789878 loss: 0.3341135019215724\n",
            "Round: 2136 Weight: [2.54929306 1.34565829] Bias: -1.127346432752476 loss: 0.3341134995635982\n",
            "Round: 2137 Weight: [2.54930595 1.34566494] Bias: -1.127351279513635 loss: 0.33411349721706984\n",
            "Round: 2138 Weight: [2.54931881 1.34567157] Bias: -1.1273561144913367 loss: 0.334113494881932\n",
            "Round: 2139 Weight: [2.54933163 1.34567819] Bias: -1.1273609377143823 loss: 0.3341134925581291\n",
            "Round: 2140 Weight: [2.54934443 1.34568479] Bias: -1.127365749211502 loss: 0.3341134902456061\n",
            "Round: 2141 Weight: [2.54935719 1.34569137] Bias: -1.1273705490113541 loss: 0.33411348794430795\n",
            "Round: 2142 Weight: [2.54936992 1.34569794] Bias: -1.1273753371425275 loss: 0.33411348565418014\n",
            "Round: 2143 Weight: [2.54938262 1.34570449] Bias: -1.1273801136335393 loss: 0.3341134833751682\n",
            "Round: 2144 Weight: [2.54939529 1.34571103] Bias: -1.1273848785128366 loss: 0.33411348110721834\n",
            "Round: 2145 Weight: [2.54940793 1.34571755] Bias: -1.1273896318087966 loss: 0.3341134788502763\n",
            "Round: 2146 Weight: [2.54942054 1.34572405] Bias: -1.1273943735497258 loss: 0.33411347660428903\n",
            "Round: 2147 Weight: [2.54943312 1.34573054] Bias: -1.1273991037638613 loss: 0.33411347436920275\n",
            "Round: 2148 Weight: [2.54944567 1.34573702] Bias: -1.1274038224793703 loss: 0.33411347214496456\n",
            "Round: 2149 Weight: [2.54945819 1.34574347] Bias: -1.1274085297243506 loss: 0.33411346993152186\n",
            "Round: 2150 Weight: [2.54947067 1.34574991] Bias: -1.12741322552683 loss: 0.3341134677288221\n",
            "Round: 2151 Weight: [2.54948313 1.34575634] Bias: -1.127417909914768 loss: 0.3341134655368129\n",
            "Round: 2152 Weight: [2.54949556 1.34576275] Bias: -1.127422582916055 loss: 0.3341134633554424\n",
            "Round: 2153 Weight: [2.54950795 1.34576915] Bias: -1.1274272445585114 loss: 0.33411346118465857\n",
            "Round: 2154 Weight: [2.54952032 1.34577552] Bias: -1.1274318948698905 loss: 0.33411345902441014\n",
            "Round: 2155 Weight: [2.54953265 1.34578189] Bias: -1.127436533877876 loss: 0.33411345687464583\n",
            "Round: 2156 Weight: [2.54954496 1.34578824] Bias: -1.1274411616100837 loss: 0.3341134547353146\n",
            "Round: 2157 Weight: [2.54955724 1.34579457] Bias: -1.1274457780940612 loss: 0.3341134526063658\n",
            "Round: 2158 Weight: [2.54956948 1.34580089] Bias: -1.1274503833572882 loss: 0.33411345048774865\n",
            "Round: 2159 Weight: [2.5495817  1.34580719] Bias: -1.1274549774271765 loss: 0.33411344837941326\n",
            "Round: 2160 Weight: [2.54959389 1.34581348] Bias: -1.1274595603310702 loss: 0.33411344628130935\n",
            "Round: 2161 Weight: [2.54960604 1.34581975] Bias: -1.127464132096246 loss: 0.33411344419338734\n",
            "Round: 2162 Weight: [2.54961817 1.345826  ] Bias: -1.1274686927499131 loss: 0.33411344211559746\n",
            "Round: 2163 Weight: [2.54963027 1.34583224] Bias: -1.1274732423192142 loss: 0.33411344004789073\n",
            "Round: 2164 Weight: [2.54964234 1.34583847] Bias: -1.1274777808312242 loss: 0.33411343799021787\n",
            "Round: 2165 Weight: [2.54965438 1.34584468] Bias: -1.1274823083129517 loss: 0.33411343594253007\n",
            "Round: 2166 Weight: [2.54966639 1.34585088] Bias: -1.1274868247913388 loss: 0.33411343390477904\n",
            "Round: 2167 Weight: [2.54967837 1.34585706] Bias: -1.1274913302932605 loss: 0.33411343187691633\n",
            "Round: 2168 Weight: [2.54969032 1.34586322] Bias: -1.1274958248455262 loss: 0.3341134298588936\n",
            "Round: 2169 Weight: [2.54970224 1.34586937] Bias: -1.127500308474879 loss: 0.3341134278506632\n",
            "Round: 2170 Weight: [2.54971414 1.34587551] Bias: -1.1275047812079957 loss: 0.3341134258521776\n",
            "Round: 2171 Weight: [2.549726   1.34588163] Bias: -1.1275092430714877 loss: 0.33411342386338927\n",
            "Round: 2172 Weight: [2.54973784 1.34588774] Bias: -1.1275136940919006 loss: 0.33411342188425114\n",
            "Round: 2173 Weight: [2.54974965 1.34589383] Bias: -1.1275181342957146 loss: 0.33411341991471605\n",
            "Round: 2174 Weight: [2.54976143 1.3458999 ] Bias: -1.1275225637093444 loss: 0.3341134179547376\n",
            "Round: 2175 Weight: [2.54977318 1.34590596] Bias: -1.1275269823591398 loss: 0.3341134160042691\n",
            "Round: 2176 Weight: [2.5497849  1.34591201] Bias: -1.1275313902713857 loss: 0.3341134140632645\n",
            "Round: 2177 Weight: [2.54979659 1.34591804] Bias: -1.127535787472302 loss: 0.33411341213167756\n",
            "Round: 2178 Weight: [2.54980826 1.34592406] Bias: -1.127540173988044 loss: 0.3341134102094626\n",
            "Round: 2179 Weight: [2.54981989 1.34593006] Bias: -1.1275445498447023 loss: 0.3341134082965741\n",
            "Round: 2180 Weight: [2.5498315  1.34593605] Bias: -1.1275489150683038 loss: 0.33411340639296666\n",
            "Round: 2181 Weight: [2.54984308 1.34594203] Bias: -1.1275532696848105 loss: 0.3341134044985952\n",
            "Round: 2182 Weight: [2.54985463 1.34594799] Bias: -1.1275576137201209 loss: 0.3341134026134145\n",
            "Round: 2183 Weight: [2.54986616 1.34595393] Bias: -1.1275619472000695 loss: 0.3341134007373804\n",
            "Round: 2184 Weight: [2.54987765 1.34595986] Bias: -1.1275662701504272 loss: 0.33411339887044805\n",
            "Round: 2185 Weight: [2.54988912 1.34596578] Bias: -1.1275705825969013 loss: 0.33411339701257325\n",
            "Round: 2186 Weight: [2.54990056 1.34597168] Bias: -1.1275748845651359 loss: 0.334113395163712\n",
            "Round: 2187 Weight: [2.54991197 1.34597757] Bias: -1.1275791760807115 loss: 0.33411339332382056\n",
            "Round: 2188 Weight: [2.54992336 1.34598344] Bias: -1.1275834571691459 loss: 0.33411339149285535\n",
            "Round: 2189 Weight: [2.54993471 1.3459893 ] Bias: -1.1275877278558941 loss: 0.33411338967077275\n",
            "Round: 2190 Weight: [2.54994604 1.34599514] Bias: -1.127591988166348 loss: 0.33411338785752953\n",
            "Round: 2191 Weight: [2.54995735 1.34600097] Bias: -1.1275962381258375 loss: 0.33411338605308316\n",
            "Round: 2192 Weight: [2.54996862 1.34600679] Bias: -1.1276004777596296 loss: 0.33411338425739046\n",
            "Round: 2193 Weight: [2.54997987 1.34601259] Bias: -1.1276047070929291 loss: 0.33411338247040895\n",
            "Round: 2194 Weight: [2.54999109 1.34601838] Bias: -1.1276089261508788 loss: 0.3341133806920963\n",
            "Round: 2195 Weight: [2.55000228 1.34602415] Bias: -1.1276131349585596 loss: 0.3341133789224105\n",
            "Round: 2196 Weight: [2.55001345 1.34602991] Bias: -1.1276173335409907 loss: 0.3341133771613095\n",
            "Round: 2197 Weight: [2.55002458 1.34603566] Bias: -1.1276215219231294 loss: 0.33411337540875163\n",
            "Round: 2198 Weight: [2.55003569 1.34604139] Bias: -1.1276257001298717 loss: 0.3341133736646952\n",
            "Round: 2199 Weight: [2.55004678 1.34604711] Bias: -1.1276298681860524 loss: 0.33411337192909907\n",
            "Round: 2200 Weight: [2.55005784 1.34605281] Bias: -1.1276340261164448 loss: 0.33411337020192217\n",
            "Round: 2201 Weight: [2.55006887 1.3460585 ] Bias: -1.1276381739457615 loss: 0.3341133684831232\n",
            "Round: 2202 Weight: [2.55007987 1.34606418] Bias: -1.127642311698654 loss: 0.3341133667726618\n",
            "Round: 2203 Weight: [2.55009085 1.34606984] Bias: -1.1276464393997134 loss: 0.33411336507049727\n",
            "Round: 2204 Weight: [2.5501018  1.34607549] Bias: -1.1276505570734698 loss: 0.3341133633765893\n",
            "Round: 2205 Weight: [2.55011272 1.34608112] Bias: -1.1276546647443935 loss: 0.33411336169089795\n",
            "Round: 2206 Weight: [2.55012362 1.34608674] Bias: -1.1276587624368937 loss: 0.33411336001338293\n",
            "Round: 2207 Weight: [2.55013449 1.34609235] Bias: -1.1276628501753203 loss: 0.3341133583440047\n",
            "Round: 2208 Weight: [2.55014533 1.34609795] Bias: -1.1276669279839628 loss: 0.33411335668272385\n",
            "Round: 2209 Weight: [2.55015615 1.34610353] Bias: -1.1276709958870512 loss: 0.33411335502950074\n",
            "Round: 2210 Weight: [2.55016694 1.34610909] Bias: -1.1276750539087557 loss: 0.33411335338429654\n",
            "Round: 2211 Weight: [2.55017771 1.34611465] Bias: -1.1276791020731867 loss: 0.33411335174707185\n",
            "Round: 2212 Weight: [2.55018845 1.34612019] Bias: -1.1276831404043957 loss: 0.3341133501177882\n",
            "Round: 2213 Weight: [2.55019916 1.34612571] Bias: -1.1276871689263748 loss: 0.33411334849640695\n",
            "Round: 2214 Weight: [2.55020985 1.34613123] Bias: -1.127691187663057 loss: 0.33411334688288963\n",
            "Round: 2215 Weight: [2.55022051 1.34613673] Bias: -1.1276951966383169 loss: 0.33411334527719816\n",
            "Round: 2216 Weight: [2.55023115 1.34614221] Bias: -1.1276991958759692 loss: 0.33411334367929424\n",
            "Round: 2217 Weight: [2.55024176 1.34614769] Bias: -1.1277031853997712 loss: 0.3341133420891401\n",
            "Round: 2218 Weight: [2.55025234 1.34615315] Bias: -1.127707165233421 loss: 0.3341133405066984\n",
            "Round: 2219 Weight: [2.5502629  1.34615859] Bias: -1.1277111354005585 loss: 0.33411333893193135\n",
            "Round: 2220 Weight: [2.55027343 1.34616403] Bias: -1.1277150959247657 loss: 0.33411333736480164\n",
            "Round: 2221 Weight: [2.55028394 1.34616945] Bias: -1.1277190468295664 loss: 0.33411333580527225\n",
            "Round: 2222 Weight: [2.55029442 1.34617485] Bias: -1.1277229881384263 loss: 0.3341133342533063\n",
            "Round: 2223 Weight: [2.55030488 1.34618025] Bias: -1.1277269198747537 loss: 0.334113332708867\n",
            "Round: 2224 Weight: [2.55031531 1.34618563] Bias: -1.1277308420618992 loss: 0.33411333117191766\n",
            "Round: 2225 Weight: [2.55032571 1.346191  ] Bias: -1.127734754723156 loss: 0.3341133296424219\n",
            "Round: 2226 Weight: [2.55033609 1.34619635] Bias: -1.1277386578817596 loss: 0.3341133281203437\n",
            "Round: 2227 Weight: [2.55034645 1.34620169] Bias: -1.127742551560889 loss: 0.3341133266056469\n",
            "Round: 2228 Weight: [2.55035678 1.34620702] Bias: -1.1277464357836657 loss: 0.3341133250982956\n",
            "Round: 2229 Weight: [2.55036708 1.34621234] Bias: -1.1277503105731546 loss: 0.33411332359825413\n",
            "Round: 2230 Weight: [2.55037736 1.34621764] Bias: -1.1277541759523633 loss: 0.334113322105487\n",
            "Round: 2231 Weight: [2.55038762 1.34622293] Bias: -1.1277580319442435 loss: 0.33411332061995874\n",
            "Round: 2232 Weight: [2.55039785 1.34622821] Bias: -1.1277618785716903 loss: 0.3341133191416344\n",
            "Round: 2233 Weight: [2.55040805 1.34623347] Bias: -1.1277657158575423 loss: 0.3341133176704788\n",
            "Round: 2234 Weight: [2.55041823 1.34623872] Bias: -1.1277695438245818 loss: 0.3341133162064571\n",
            "Round: 2235 Weight: [2.55042839 1.34624396] Bias: -1.1277733624955355 loss: 0.3341133147495349\n",
            "Round: 2236 Weight: [2.55043852 1.34624919] Bias: -1.1277771718930738 loss: 0.33411331329967736\n",
            "Round: 2237 Weight: [2.55044862 1.3462544 ] Bias: -1.1277809720398115 loss: 0.33411331185685034\n",
            "Round: 2238 Weight: [2.55045871 1.3462596 ] Bias: -1.127784762958308 loss: 0.33411331042101966\n",
            "Round: 2239 Weight: [2.55046876 1.34626479] Bias: -1.1277885446710667 loss: 0.3341133089921514\n",
            "Round: 2240 Weight: [2.5504788  1.34626997] Bias: -1.1277923172005362 loss: 0.3341133075702116\n",
            "Round: 2241 Weight: [2.5504888  1.34627513] Bias: -1.1277960805691098 loss: 0.33411330615516677\n",
            "Round: 2242 Weight: [2.55049879 1.34628028] Bias: -1.1277998347991256 loss: 0.33411330474698314\n",
            "Round: 2243 Weight: [2.55050875 1.34628542] Bias: -1.1278035799128667 loss: 0.3341133033456276\n",
            "Round: 2244 Weight: [2.55051868 1.34629054] Bias: -1.127807315932562 loss: 0.33411330195106687\n",
            "Round: 2245 Weight: [2.5505286  1.34629566] Bias: -1.1278110428803847 loss: 0.3341133005632681\n",
            "Round: 2246 Weight: [2.55053848 1.34630076] Bias: -1.1278147607784546 loss: 0.33411329918219823\n",
            "Round: 2247 Weight: [2.55054835 1.34630584] Bias: -1.1278184696488363 loss: 0.3341132978078248\n",
            "Round: 2248 Weight: [2.55055819 1.34631092] Bias: -1.1278221695135404 loss: 0.33411329644011506\n",
            "Round: 2249 Weight: [2.550568   1.34631598] Bias: -1.127825860394524 loss: 0.33411329507903675\n",
            "Round: 2250 Weight: [2.55057779 1.34632103] Bias: -1.1278295423136893 loss: 0.3341132937245577\n",
            "Round: 2251 Weight: [2.55058756 1.34632607] Bias: -1.1278332152928852 loss: 0.3341132923766457\n",
            "Round: 2252 Weight: [2.55059731 1.3463311 ] Bias: -1.1278368793539066 loss: 0.33411329103526904\n",
            "Round: 2253 Weight: [2.55060703 1.34633611] Bias: -1.1278405345184954 loss: 0.3341132897003959\n",
            "Round: 2254 Weight: [2.55061673 1.34634112] Bias: -1.1278441808083395 loss: 0.33411328837199455\n",
            "Round: 2255 Weight: [2.5506264  1.34634611] Bias: -1.1278478182450737 loss: 0.3341132870500339\n",
            "Round: 2256 Weight: [2.55063605 1.34635109] Bias: -1.1278514468502796 loss: 0.33411328573448223\n",
            "Round: 2257 Weight: [2.55064568 1.34635605] Bias: -1.1278550666454858 loss: 0.33411328442530885\n",
            "Round: 2258 Weight: [2.55065528 1.34636101] Bias: -1.1278586776521682 loss: 0.3341132831224824\n",
            "Round: 2259 Weight: [2.55066486 1.34636595] Bias: -1.1278622798917497 loss: 0.33411328182597233\n",
            "Round: 2260 Weight: [2.55067442 1.34637088] Bias: -1.1278658733856004 loss: 0.3341132805357478\n",
            "Round: 2261 Weight: [2.55068395 1.3463758 ] Bias: -1.1278694581550384 loss: 0.3341132792517782\n",
            "Round: 2262 Weight: [2.55069346 1.3463807 ] Bias: -1.127873034221329 loss: 0.33411327797403345\n",
            "Round: 2263 Weight: [2.55070295 1.3463856 ] Bias: -1.1278766016056854 loss: 0.33411327670248303\n",
            "Round: 2264 Weight: [2.55071241 1.34639048] Bias: -1.1278801603292685 loss: 0.33411327543709707\n",
            "Round: 2265 Weight: [2.55072185 1.34639535] Bias: -1.1278837104131878 loss: 0.3341132741778455\n",
            "Round: 2266 Weight: [2.55073127 1.34640021] Bias: -1.1278872518785001 loss: 0.3341132729246986\n",
            "Round: 2267 Weight: [2.55074067 1.34640505] Bias: -1.1278907847462114 loss: 0.33411327167762667\n",
            "Round: 2268 Weight: [2.55075004 1.34640989] Bias: -1.1278943090372753 loss: 0.3341132704366003\n",
            "Round: 2269 Weight: [2.55075939 1.34641471] Bias: -1.1278978247725944 loss: 0.33411326920158985\n",
            "Round: 2270 Weight: [2.55076872 1.34641952] Bias: -1.1279013319730198 loss: 0.3341132679725664\n",
            "Round: 2271 Weight: [2.55077802 1.34642432] Bias: -1.1279048306593515 loss: 0.33411326674950087\n",
            "Round: 2272 Weight: [2.55078731 1.34642911] Bias: -1.1279083208523384 loss: 0.3341132655323642\n",
            "Round: 2273 Weight: [2.55079657 1.34643389] Bias: -1.1279118025726782 loss: 0.3341132643211276\n",
            "Round: 2274 Weight: [2.5508058  1.34643865] Bias: -1.127915275841018 loss: 0.3341132631157625\n",
            "Round: 2275 Weight: [2.55081502 1.34644341] Bias: -1.1279187406779543 loss: 0.33411326191624036\n",
            "Round: 2276 Weight: [2.55082421 1.34644815] Bias: -1.1279221971040327 loss: 0.3341132607225327\n",
            "Round: 2277 Weight: [2.55083338 1.34645288] Bias: -1.1279256451397488 loss: 0.3341132595346116\n",
            "Round: 2278 Weight: [2.55084253 1.3464576 ] Bias: -1.1279290848055474 loss: 0.3341132583524486\n",
            "Round: 2279 Weight: [2.55085166 1.34646231] Bias: -1.1279325161218237 loss: 0.33411325717601587\n",
            "Round: 2280 Weight: [2.55086076 1.346467  ] Bias: -1.127935939108922 loss: 0.3341132560052857\n",
            "Round: 2281 Weight: [2.55086984 1.34647169] Bias: -1.1279393537871374 loss: 0.33411325484023024\n",
            "Round: 2282 Weight: [2.5508789  1.34647636] Bias: -1.127942760176715 loss: 0.334113253680822\n",
            "Round: 2283 Weight: [2.55088794 1.34648102] Bias: -1.1279461582978496 loss: 0.33411325252703356\n",
            "Round: 2284 Weight: [2.55089695 1.34648567] Bias: -1.1279495481706874 loss: 0.3341132513788377\n",
            "Round: 2285 Weight: [2.55090595 1.34649031] Bias: -1.1279529298153246 loss: 0.3341132502362071\n",
            "Round: 2286 Weight: [2.55091492 1.34649494] Bias: -1.1279563032518078 loss: 0.3341132490991148\n",
            "Round: 2287 Weight: [2.55092387 1.34649956] Bias: -1.1279596685001352 loss: 0.3341132479675341\n",
            "Round: 2288 Weight: [2.5509328  1.34650416] Bias: -1.1279630255802553 loss: 0.33411324684143795\n",
            "Round: 2289 Weight: [2.5509417  1.34650876] Bias: -1.1279663745120676 loss: 0.3341132457208\n",
            "Round: 2290 Weight: [2.55095059 1.34651334] Bias: -1.1279697153154231 loss: 0.3341132446055935\n",
            "Round: 2291 Weight: [2.55095945 1.34651791] Bias: -1.1279730480101242 loss: 0.3341132434957922\n",
            "Round: 2292 Weight: [2.5509683  1.34652248] Bias: -1.1279763726159242 loss: 0.33411324239136997\n",
            "Round: 2293 Weight: [2.55097712 1.34652703] Bias: -1.1279796891525282 loss: 0.33411324129230047\n",
            "Round: 2294 Weight: [2.55098592 1.34653156] Bias: -1.127982997639593 loss: 0.3341132401985578\n",
            "Round: 2295 Weight: [2.55099469 1.34653609] Bias: -1.1279862980967268 loss: 0.33411323911011614\n",
            "Round: 2296 Weight: [2.55100345 1.34654061] Bias: -1.1279895905434902 loss: 0.33411323802694987\n",
            "Round: 2297 Weight: [2.55101219 1.34654512] Bias: -1.1279928749993957 loss: 0.3341132369490331\n",
            "Round: 2298 Weight: [2.5510209  1.34654961] Bias: -1.1279961514839076 loss: 0.33411323587634056\n",
            "Round: 2299 Weight: [2.55102959 1.3465541 ] Bias: -1.127999420016443 loss: 0.33411323480884675\n",
            "Round: 2300 Weight: [2.55103826 1.34655857] Bias: -1.1280026806163705 loss: 0.3341132337465265\n",
            "Round: 2301 Weight: [2.55104692 1.34656303] Bias: -1.1280059333030121 loss: 0.3341132326893547\n",
            "Round: 2302 Weight: [2.55105555 1.34656748] Bias: -1.1280091780956418 loss: 0.3341132316373065\n",
            "Round: 2303 Weight: [2.55106415 1.34657192] Bias: -1.1280124150134867 loss: 0.3341132305903567\n",
            "Round: 2304 Weight: [2.55107274 1.34657635] Bias: -1.1280156440757265 loss: 0.3341132295484808\n",
            "Round: 2305 Weight: [2.55108131 1.34658077] Bias: -1.128018865301494 loss: 0.3341132285116541\n",
            "Round: 2306 Weight: [2.55108986 1.34658518] Bias: -1.1280220787098747 loss: 0.33411322747985206\n",
            "Round: 2307 Weight: [2.55109838 1.34658958] Bias: -1.128025284319908 loss: 0.3341132264530504\n",
            "Round: 2308 Weight: [2.55110689 1.34659397] Bias: -1.1280284821505857 loss: 0.33411322543122474\n",
            "Round: 2309 Weight: [2.55111537 1.34659834] Bias: -1.1280316722208539 loss: 0.33411322441435093\n",
            "Round: 2310 Weight: [2.55112383 1.34660271] Bias: -1.1280348545496115 loss: 0.334113223402405\n",
            "Round: 2311 Weight: [2.55113228 1.34660707] Bias: -1.1280380291557117 loss: 0.33411322239536295\n",
            "Round: 2312 Weight: [2.5511407  1.34661141] Bias: -1.128041196057961 loss: 0.3341132213932011\n",
            "Round: 2313 Weight: [2.5511491  1.34661575] Bias: -1.12804435527512 loss: 0.3341132203958957\n",
            "Round: 2314 Weight: [2.55115749 1.34662007] Bias: -1.1280475068259033 loss: 0.3341132194034232\n",
            "Round: 2315 Weight: [2.55116585 1.34662438] Bias: -1.1280506507289791 loss: 0.3341132184157599\n",
            "Round: 2316 Weight: [2.55117419 1.34662869] Bias: -1.1280537870029708 loss: 0.33411321743288286\n",
            "Round: 2317 Weight: [2.55118251 1.34663298] Bias: -1.1280569156664553 loss: 0.33411321645476855\n",
            "Round: 2318 Weight: [2.55119081 1.34663726] Bias: -1.1280600367379643 loss: 0.334113215481394\n",
            "Round: 2319 Weight: [2.55119909 1.34664153] Bias: -1.1280631502359841 loss: 0.33411321451273623\n",
            "Round: 2320 Weight: [2.55120735 1.34664579] Bias: -1.1280662561789556 loss: 0.3341132135487722\n",
            "Round: 2321 Weight: [2.55121559 1.34665004] Bias: -1.1280693545852745 loss: 0.3341132125894793\n",
            "Round: 2322 Weight: [2.55122381 1.34665428] Bias: -1.1280724454732913 loss: 0.3341132116348347\n",
            "Round: 2323 Weight: [2.55123201 1.34665852] Bias: -1.1280755288613118 loss: 0.33411321068481603\n",
            "Round: 2324 Weight: [2.5512402  1.34666274] Bias: -1.1280786047675966 loss: 0.33411320973940056\n",
            "Round: 2325 Weight: [2.55124836 1.34666695] Bias: -1.1280816732103616 loss: 0.3341132087985662\n",
            "Round: 2326 Weight: [2.5512565  1.34667114] Bias: -1.1280847342077782 loss: 0.33411320786229065\n",
            "Round: 2327 Weight: [2.55126462 1.34667533] Bias: -1.1280877877779731 loss: 0.33411320693055174\n",
            "Round: 2328 Weight: [2.55127272 1.34667951] Bias: -1.128090833939029 loss: 0.33411320600332756\n",
            "Round: 2329 Weight: [2.5512808  1.34668368] Bias: -1.1280938727089835 loss: 0.33411320508059605\n",
            "Round: 2330 Weight: [2.55128887 1.34668784] Bias: -1.1280969041058306 loss: 0.33411320416233553\n",
            "Round: 2331 Weight: [2.55129691 1.34669199] Bias: -1.1280999281475201 loss: 0.33411320324852417\n",
            "Round: 2332 Weight: [2.55130493 1.34669613] Bias: -1.1281029448519577 loss: 0.3341132023391405\n",
            "Round: 2333 Weight: [2.55131294 1.34670026] Bias: -1.1281059542370053 loss: 0.33411320143416307\n",
            "Round: 2334 Weight: [2.55132092 1.34670438] Bias: -1.128108956320481 loss: 0.33411320053357046\n",
            "Round: 2335 Weight: [2.55132889 1.34670849] Bias: -1.128111951120159 loss: 0.33411319963734126\n",
            "Round: 2336 Weight: [2.55133683 1.34671259] Bias: -1.1281149386537703 loss: 0.33411319874545437\n",
            "Round: 2337 Weight: [2.55134476 1.34671667] Bias: -1.1281179189390023 loss: 0.33411319785788884\n",
            "Round: 2338 Weight: [2.55135267 1.34672075] Bias: -1.128120891993499 loss: 0.3341131969746236\n",
            "Round: 2339 Weight: [2.55136055 1.34672482] Bias: -1.1281238578348616 loss: 0.3341131960956377\n",
            "Round: 2340 Weight: [2.55136842 1.34672888] Bias: -1.1281268164806475 loss: 0.33411319522091065\n",
            "Round: 2341 Weight: [2.55137627 1.34673293] Bias: -1.1281297679483715 loss: 0.33411319435042147\n",
            "Round: 2342 Weight: [2.5513841  1.34673697] Bias: -1.1281327122555056 loss: 0.33411319348414975\n",
            "Round: 2343 Weight: [2.55139192 1.346741  ] Bias: -1.1281356494194785 loss: 0.3341131926220751\n",
            "Round: 2344 Weight: [2.55139971 1.34674502] Bias: -1.1281385794576768 loss: 0.3341131917641769\n",
            "Round: 2345 Weight: [2.55140748 1.34674903] Bias: -1.128141502387444 loss: 0.3341131909104352\n",
            "Round: 2346 Weight: [2.55141524 1.34675303] Bias: -1.1281444182260814 loss: 0.3341131900608297\n",
            "Round: 2347 Weight: [2.55142298 1.34675702] Bias: -1.1281473269908477 loss: 0.33411318921534017\n",
            "Round: 2348 Weight: [2.55143069 1.346761  ] Bias: -1.1281502286989598 loss: 0.3341131883739468\n",
            "Round: 2349 Weight: [2.55143839 1.34676497] Bias: -1.1281531233675919 loss: 0.33411318753662983\n",
            "Round: 2350 Weight: [2.55144607 1.34676894] Bias: -1.1281560110138764 loss: 0.33411318670336926\n",
            "Round: 2351 Weight: [2.55145373 1.34677289] Bias: -1.1281588916549037 loss: 0.3341131858741456\n",
            "Round: 2352 Weight: [2.55146138 1.34677683] Bias: -1.128161765307722 loss: 0.3341131850489391\n",
            "Round: 2353 Weight: [2.551469   1.34678076] Bias: -1.1281646319893386 loss: 0.3341131842277303\n",
            "Round: 2354 Weight: [2.55147661 1.34678469] Bias: -1.1281674917167182 loss: 0.3341131834104999\n",
            "Round: 2355 Weight: [2.5514842 1.3467886] Bias: -1.1281703445067846 loss: 0.33411318259722844\n",
            "Round: 2356 Weight: [2.55149177 1.34679251] Bias: -1.1281731903764198 loss: 0.33411318178789706\n",
            "Round: 2357 Weight: [2.55149932 1.3467964 ] Bias: -1.1281760293424647 loss: 0.33411318098248616\n",
            "Round: 2358 Weight: [2.55150685 1.34680029] Bias: -1.1281788614217187 loss: 0.3341131801809771\n",
            "Round: 2359 Weight: [2.55151436 1.34680416] Bias: -1.1281816866309404 loss: 0.3341131793833508\n",
            "Round: 2360 Weight: [2.55152186 1.34680803] Bias: -1.128184504986847 loss: 0.33411317858958844\n",
            "Round: 2361 Weight: [2.55152934 1.34681189] Bias: -1.1281873165061151 loss: 0.3341131777996712\n",
            "Round: 2362 Weight: [2.5515368  1.34681574] Bias: -1.1281901212053802 loss: 0.33411317701358056\n",
            "Round: 2363 Weight: [2.55154424 1.34681958] Bias: -1.1281929191012372 loss: 0.33411317623129777\n",
            "Round: 2364 Weight: [2.55155166 1.3468234 ] Bias: -1.1281957102102405 loss: 0.33411317545280467\n",
            "Round: 2365 Weight: [2.55155907 1.34682723] Bias: -1.1281984945489036 loss: 0.3341131746780827\n",
            "Round: 2366 Weight: [2.55156646 1.34683104] Bias: -1.1282012721337 loss: 0.3341131739071134\n",
            "Round: 2367 Weight: [2.55157383 1.34683484] Bias: -1.1282040429810627 loss: 0.3341131731398788\n",
            "Round: 2368 Weight: [2.55158118 1.34683863] Bias: -1.1282068071073843 loss: 0.3341131723763606\n",
            "Round: 2369 Weight: [2.55158851 1.34684241] Bias: -1.1282095645290173 loss: 0.33411317161654114\n",
            "Round: 2370 Weight: [2.55159583 1.34684619] Bias: -1.1282123152622745 loss: 0.33411317086040204\n",
            "Round: 2371 Weight: [2.55160313 1.34684995] Bias: -1.1282150593234286 loss: 0.33411317010792574\n",
            "Round: 2372 Weight: [2.55161041 1.34685371] Bias: -1.1282177967287124 loss: 0.3341131693590942\n",
            "Round: 2373 Weight: [2.55161767 1.34685746] Bias: -1.128220527494319 loss: 0.33411316861388995\n",
            "Round: 2374 Weight: [2.55162492 1.34686119] Bias: -1.1282232516364015 loss: 0.33411316787229534\n",
            "Round: 2375 Weight: [2.55163215 1.34686492] Bias: -1.1282259691710743 loss: 0.33411316713429284\n",
            "Round: 2376 Weight: [2.55163936 1.34686864] Bias: -1.1282286801144117 loss: 0.3341131663998652\n",
            "Round: 2377 Weight: [2.55164655 1.34687235] Bias: -1.128231384482449 loss: 0.3341131656689948\n",
            "Round: 2378 Weight: [2.55165372 1.34687605] Bias: -1.1282340822911818 loss: 0.33411316494166465\n",
            "Round: 2379 Weight: [2.55166088 1.34687975] Bias: -1.1282367735565673 loss: 0.33411316421785736\n",
            "Round: 2380 Weight: [2.55166802 1.34688343] Bias: -1.1282394582945228 loss: 0.33411316349755593\n",
            "Round: 2381 Weight: [2.55167515 1.3468871 ] Bias: -1.1282421365209272 loss: 0.3341131627807433\n",
            "Round: 2382 Weight: [2.55168225 1.34689077] Bias: -1.1282448082516205 loss: 0.3341131620674028\n",
            "Round: 2383 Weight: [2.55168934 1.34689443] Bias: -1.128247473502404 loss: 0.33411316135751723\n",
            "Round: 2384 Weight: [2.55169641 1.34689807] Bias: -1.12825013228904 loss: 0.3341131606510701\n",
            "Round: 2385 Weight: [2.55170347 1.34690171] Bias: -1.1282527846272523 loss: 0.33411315994804464\n",
            "Round: 2386 Weight: [2.55171051 1.34690534] Bias: -1.1282554305327266 loss: 0.3341131592484243\n",
            "Round: 2387 Weight: [2.55171753 1.34690896] Bias: -1.1282580700211098 loss: 0.3341131585521923\n",
            "Round: 2388 Weight: [2.55172453 1.34691258] Bias: -1.1282607031080107 loss: 0.33411315785933254\n",
            "Round: 2389 Weight: [2.55173152 1.34691618] Bias: -1.128263329809 loss: 0.3341131571698286\n",
            "Round: 2390 Weight: [2.55173849 1.34691978] Bias: -1.12826595013961 loss: 0.334113156483664\n",
            "Round: 2391 Weight: [2.55174544 1.34692336] Bias: -1.1282685641153354 loss: 0.3341131558008229\n",
            "Round: 2392 Weight: [2.55175237 1.34692694] Bias: -1.1282711717516327 loss: 0.334113155121289\n",
            "Round: 2393 Weight: [2.55175929 1.34693051] Bias: -1.128273773063921 loss: 0.334113154445046\n",
            "Round: 2394 Weight: [2.5517662  1.34693407] Bias: -1.128276368067581 loss: 0.3341131537720784\n",
            "Round: 2395 Weight: [2.55177308 1.34693762] Bias: -1.1282789567779563 loss: 0.33411315310237005\n",
            "Round: 2396 Weight: [2.55177995 1.34694117] Bias: -1.128281539210353 loss: 0.33411315243590517\n",
            "Round: 2397 Weight: [2.5517868 1.3469447] Bias: -1.1282841153800394 loss: 0.3341131517726681\n",
            "Round: 2398 Weight: [2.55179364 1.34694823] Bias: -1.1282866853022466 loss: 0.33411315111264306\n",
            "Round: 2399 Weight: [2.55180046 1.34695174] Bias: -1.1282892489921688 loss: 0.3341131504558145\n",
            "Round: 2400 Weight: [2.55180726 1.34695525] Bias: -1.1282918064649623 loss: 0.3341131498021671\n",
            "Round: 2401 Weight: [2.55181405 1.34695875] Bias: -1.1282943577357472 loss: 0.3341131491516852\n",
            "Round: 2402 Weight: [2.55182082 1.34696225] Bias: -1.1282969028196057 loss: 0.33411314850435375\n",
            "Round: 2403 Weight: [2.55182757 1.34696573] Bias: -1.128299441731584 loss: 0.3341131478601571\n",
            "Round: 2404 Weight: [2.55183431 1.3469692 ] Bias: -1.128301974486691 loss: 0.3341131472190803\n",
            "Round: 2405 Weight: [2.55184103 1.34697267] Bias: -1.1283045010998989 loss: 0.33411314658110824\n",
            "Round: 2406 Weight: [2.55184773 1.34697613] Bias: -1.1283070215861435 loss: 0.3341131459462256\n",
            "Round: 2407 Weight: [2.55185442 1.34697958] Bias: -1.128309535960324 loss: 0.3341131453144177\n",
            "Round: 2408 Weight: [2.55186109 1.34698302] Bias: -1.128312044237303 loss: 0.3341131446856695\n",
            "Round: 2409 Weight: [2.55186774 1.34698645] Bias: -1.128314546431907 loss: 0.3341131440599661\n",
            "Round: 2410 Weight: [2.55187438 1.34698988] Bias: -1.1283170425589264 loss: 0.3341131434372928\n",
            "Round: 2411 Weight: [2.55188101 1.3469933 ] Bias: -1.1283195326331148 loss: 0.33411314281763504\n",
            "Round: 2412 Weight: [2.55188761 1.3469967 ] Bias: -1.12832201666919 loss: 0.33411314220097804\n",
            "Round: 2413 Weight: [2.55189421 1.3470001 ] Bias: -1.1283244946818343 loss: 0.3341131415873072\n",
            "Round: 2414 Weight: [2.55190078 1.3470035 ] Bias: -1.1283269666856934 loss: 0.33411314097660816\n",
            "Round: 2415 Weight: [2.55190734 1.34700688] Bias: -1.1283294326953779 loss: 0.33411314036886647\n",
            "Round: 2416 Weight: [2.55191388 1.34701025] Bias: -1.128331892725462 loss: 0.3341131397640678\n",
            "Round: 2417 Weight: [2.55192041 1.34701362] Bias: -1.1283343467904847 loss: 0.334113139162198\n",
            "Round: 2418 Weight: [2.55192692 1.34701698] Bias: -1.1283367949049494 loss: 0.33411313856324254\n",
            "Round: 2419 Weight: [2.55193342 1.34702033] Bias: -1.1283392370833238 loss: 0.33411313796718756\n",
            "Round: 2420 Weight: [2.5519399  1.34702367] Bias: -1.1283416733400407 loss: 0.33411313737401904\n",
            "Round: 2421 Weight: [2.55194636 1.34702701] Bias: -1.128344103689497 loss: 0.3341131367837228\n",
            "Round: 2422 Weight: [2.55195281 1.34703033] Bias: -1.128346528146055 loss: 0.33411313619628497\n",
            "Round: 2423 Weight: [2.55195924 1.34703365] Bias: -1.1283489467240415 loss: 0.3341131356116918\n",
            "Round: 2424 Weight: [2.55196566 1.34703696] Bias: -1.1283513594377486 loss: 0.3341131350299294\n",
            "Round: 2425 Weight: [2.55197206 1.34704027] Bias: -1.128353766301433 loss: 0.334113134450984\n",
            "Round: 2426 Weight: [2.55197845 1.34704356] Bias: -1.128356167329317 loss: 0.334113133874842\n",
            "Round: 2427 Weight: [2.55198482 1.34704685] Bias: -1.128358562535588 loss: 0.3341131333014899\n",
            "Round: 2428 Weight: [2.55199118 1.34705013] Bias: -1.128360951934399 loss: 0.3341131327309139\n",
            "Round: 2429 Weight: [2.55199752 1.3470534 ] Bias: -1.1283633355398675 loss: 0.334113132163101\n",
            "Round: 2430 Weight: [2.55200384 1.34705666] Bias: -1.1283657133660776 loss: 0.3341131315980373\n",
            "Round: 2431 Weight: [2.55201015 1.34705991] Bias: -1.1283680854270783 loss: 0.33411313103570983\n",
            "Round: 2432 Weight: [2.55201645 1.34706316] Bias: -1.1283704517368847 loss: 0.33411313047610514\n",
            "Round: 2433 Weight: [2.55202272 1.3470664 ] Bias: -1.1283728123094772 loss: 0.33411312991921005\n",
            "Round: 2434 Weight: [2.55202899 1.34706963] Bias: -1.1283751671588023 loss: 0.3341131293650116\n",
            "Round: 2435 Weight: [2.55203524 1.34707285] Bias: -1.1283775162987724 loss: 0.3341131288134964\n",
            "Round: 2436 Weight: [2.55204147 1.34707607] Bias: -1.128379859743266 loss: 0.3341131282646517\n",
            "Round: 2437 Weight: [2.55204769 1.34707928] Bias: -1.1283821975061274 loss: 0.3341131277184646\n",
            "Round: 2438 Weight: [2.55205389 1.34708248] Bias: -1.1283845296011676 loss: 0.334113127174922\n",
            "Round: 2439 Weight: [2.55206008 1.34708567] Bias: -1.1283868560421633 loss: 0.33411312663401116\n",
            "Round: 2440 Weight: [2.55206625 1.34708885] Bias: -1.1283891768428576 loss: 0.33411312609571936\n",
            "Round: 2441 Weight: [2.55207241 1.34709203] Bias: -1.1283914920169604 loss: 0.3341131255600339\n",
            "Round: 2442 Weight: [2.55207855 1.3470952 ] Bias: -1.1283938015781478 loss: 0.33411312502694207\n",
            "Round: 2443 Weight: [2.55208468 1.34709836] Bias: -1.1283961055400626 loss: 0.33411312449643144\n",
            "Round: 2444 Weight: [2.5520908  1.34710151] Bias: -1.1283984039163142 loss: 0.3341131239684893\n",
            "Round: 2445 Weight: [2.55209689 1.34710466] Bias: -1.128400696720479 loss: 0.3341131234431034\n",
            "Round: 2446 Weight: [2.55210298 1.3471078 ] Bias: -1.1284029839660996 loss: 0.3341131229202613\n",
            "Round: 2447 Weight: [2.55210905 1.34711093] Bias: -1.1284052656666863 loss: 0.33411312239995056\n",
            "Round: 2448 Weight: [2.5521151  1.34711405] Bias: -1.128407541835716 loss: 0.3341131218821589\n",
            "Round: 2449 Weight: [2.55212114 1.34711717] Bias: -1.1284098124866326 loss: 0.3341131213668744\n",
            "Round: 2450 Weight: [2.55212717 1.34712027] Bias: -1.1284120776328475 loss: 0.33411312085408446\n",
            "Round: 2451 Weight: [2.55213318 1.34712337] Bias: -1.1284143372877389 loss: 0.33411312034377755\n",
            "Round: 2452 Weight: [2.55213917 1.34712647] Bias: -1.1284165914646527 loss: 0.3341131198359409\n",
            "Round: 2453 Weight: [2.55214515 1.34712955] Bias: -1.128418840176902 loss: 0.3341131193305632\n",
            "Round: 2454 Weight: [2.55215112 1.34713263] Bias: -1.1284210834377675 loss: 0.3341131188276322\n",
            "Round: 2455 Weight: [2.55215707 1.3471357 ] Bias: -1.1284233212604975 loss: 0.33411311832713625\n",
            "Round: 2456 Weight: [2.55216301 1.34713876] Bias: -1.1284255536583077 loss: 0.3341131178290632\n",
            "Round: 2457 Weight: [2.55216894 1.34714182] Bias: -1.1284277806443817 loss: 0.3341131173334017\n",
            "Round: 2458 Weight: [2.55217485 1.34714487] Bias: -1.1284300022318707 loss: 0.33411311684013983\n",
            "Round: 2459 Weight: [2.55218074 1.34714791] Bias: -1.1284322184338944 loss: 0.33411311634926605\n",
            "Round: 2460 Weight: [2.55218662 1.34715094] Bias: -1.1284344292635398 loss: 0.3341131158607688\n",
            "Round: 2461 Weight: [2.55219249 1.34715397] Bias: -1.1284366347338621 loss: 0.3341131153746364\n",
            "Round: 2462 Weight: [2.55219834 1.34715699] Bias: -1.1284388348578849 loss: 0.33411311489085754\n",
            "Round: 2463 Weight: [2.55220418 1.34716   ] Bias: -1.1284410296485994 loss: 0.3341131144094207\n",
            "Round: 2464 Weight: [2.55221  1.347163] Bias: -1.1284432191189657 loss: 0.3341131139303148\n",
            "Round: 2465 Weight: [2.55221581 1.347166  ] Bias: -1.1284454032819122 loss: 0.3341131134535282\n",
            "Round: 2466 Weight: [2.55222161 1.34716899] Bias: -1.1284475821503355 loss: 0.3341131129790497\n",
            "Round: 2467 Weight: [2.55222739 1.34717197] Bias: -1.1284497557371005 loss: 0.3341131125068685\n",
            "Round: 2468 Weight: [2.55223316 1.34717495] Bias: -1.128451924055041 loss: 0.33411311203697297\n",
            "Round: 2469 Weight: [2.55223891 1.34717792] Bias: -1.1284540871169597 loss: 0.33411311156935236\n",
            "Round: 2470 Weight: [2.55224465 1.34718088] Bias: -1.1284562449356277 loss: 0.3341131111039954\n",
            "Round: 2471 Weight: [2.55225038 1.34718383] Bias: -1.1284583975237847 loss: 0.33411311064089144\n",
            "Round: 2472 Weight: [2.55225609 1.34718678] Bias: -1.1284605448941398 loss: 0.3341131101800293\n",
            "Round: 2473 Weight: [2.55226179 1.34718972] Bias: -1.1284626870593708 loss: 0.334113109721398\n",
            "Round: 2474 Weight: [2.55226747 1.34719265] Bias: -1.1284648240321247 loss: 0.3341131092649872\n",
            "Round: 2475 Weight: [2.55227314 1.34719557] Bias: -1.1284669558250173 loss: 0.33411310881078576\n",
            "Round: 2476 Weight: [2.5522788  1.34719849] Bias: -1.1284690824506343 loss: 0.33411310835878305\n",
            "Round: 2477 Weight: [2.55228444 1.3472014 ] Bias: -1.1284712039215297 loss: 0.3341131079089684\n",
            "Round: 2478 Weight: [2.55229007 1.34720431] Bias: -1.1284733202502277 loss: 0.3341131074613313\n",
            "Round: 2479 Weight: [2.55229568 1.3472072 ] Bias: -1.1284754314492216 loss: 0.33411310701586117\n",
            "Round: 2480 Weight: [2.55230129 1.34721009] Bias: -1.128477537530974 loss: 0.33411310657254745\n",
            "Round: 2481 Weight: [2.55230688 1.34721298] Bias: -1.1284796385079172 loss: 0.3341131061313796\n",
            "Round: 2482 Weight: [2.55231245 1.34721585] Bias: -1.1284817343924536 loss: 0.3341131056923476\n",
            "Round: 2483 Weight: [2.55231801 1.34721872] Bias: -1.128483825196955 loss: 0.33411310525544063\n",
            "Round: 2484 Weight: [2.55232356 1.34722158] Bias: -1.1284859109337626 loss: 0.33411310482064865\n",
            "Round: 2485 Weight: [2.55232909 1.34722444] Bias: -1.128487991615188 loss: 0.3341131043879614\n",
            "Round: 2486 Weight: [2.55233462 1.34722728] Bias: -1.1284900672535128 loss: 0.33411310395736865\n",
            "Round: 2487 Weight: [2.55234012 1.34723013] Bias: -1.1284921378609882 loss: 0.33411310352886026\n",
            "Round: 2488 Weight: [2.55234562 1.34723296] Bias: -1.1284942034498358 loss: 0.3341131031024259\n",
            "Round: 2489 Weight: [2.5523511  1.34723579] Bias: -1.1284962640322473 loss: 0.33411310267805605\n",
            "Round: 2490 Weight: [2.55235657 1.34723861] Bias: -1.1284983196203848 loss: 0.3341131022557402\n",
            "Round: 2491 Weight: [2.55236202 1.34724142] Bias: -1.1285003702263805 loss: 0.33411310183546866\n",
            "Round: 2492 Weight: [2.55236746 1.34724423] Bias: -1.128502415862337 loss: 0.3341131014172314\n",
            "Round: 2493 Weight: [2.55237289 1.34724703] Bias: -1.1285044565403273 loss: 0.3341131010010186\n",
            "Round: 2494 Weight: [2.55237831 1.34724982] Bias: -1.1285064922723953 loss: 0.33411310058682064\n",
            "Round: 2495 Weight: [2.55238371 1.34725261] Bias: -1.1285085230705554 loss: 0.3341131001746275\n",
            "Round: 2496 Weight: [2.5523891  1.34725539] Bias: -1.1285105489467924 loss: 0.33411309976442943\n",
            "Round: 2497 Weight: [2.55239447 1.34725816] Bias: -1.128512569913062 loss: 0.3341130993562171\n",
            "Round: 2498 Weight: [2.55239984 1.34726093] Bias: -1.1285145859812908 loss: 0.3341130989499804\n",
            "Round: 2499 Weight: [2.55240519 1.34726369] Bias: -1.1285165971633764 loss: 0.33411309854571025\n",
            "Round: 2500 Weight: [2.55241052 1.34726644] Bias: -1.1285186034711872 loss: 0.33411309814339685\n",
            "Round: 2501 Weight: [2.55241585 1.34726919] Bias: -1.1285206049165626 loss: 0.33411309774303066\n",
            "Round: 2502 Weight: [2.55242116 1.34727193] Bias: -1.1285226015113132 loss: 0.33411309734460237\n",
            "Round: 2503 Weight: [2.55242645 1.34727466] Bias: -1.1285245932672208 loss: 0.3341130969481028\n",
            "Round: 2504 Weight: [2.55243174 1.34727738] Bias: -1.1285265801960385 loss: 0.33411309655352217\n",
            "Round: 2505 Weight: [2.55243701 1.3472801 ] Bias: -1.1285285623094905 loss: 0.3341130961608514\n",
            "Round: 2506 Weight: [2.55244227 1.34728282] Bias: -1.1285305396192726 loss: 0.3341130957700813\n",
            "Round: 2507 Weight: [2.55244752 1.34728552] Bias: -1.1285325121370522 loss: 0.33411309538120265\n",
            "Round: 2508 Weight: [2.55245275 1.34728822] Bias: -1.128534479874468 loss: 0.3341130949942061\n",
            "Round: 2509 Weight: [2.55245798 1.34729092] Bias: -1.1285364428431304 loss: 0.33411309460908273\n",
            "Round: 2510 Weight: [2.55246318 1.3472936 ] Bias: -1.1285384010546213 loss: 0.33411309422582336\n",
            "Round: 2511 Weight: [2.55246838 1.34729629] Bias: -1.1285403545204948 loss: 0.334113093844419\n",
            "Round: 2512 Weight: [2.55247356 1.34729896] Bias: -1.1285423032522763 loss: 0.3341130934648606\n",
            "Round: 2513 Weight: [2.55247873 1.34730163] Bias: -1.1285442472614635 loss: 0.3341130930871394\n",
            "Round: 2514 Weight: [2.55248389 1.34730429] Bias: -1.1285461865595257 loss: 0.33411309271124634\n",
            "Round: 2515 Weight: [2.55248904 1.34730694] Bias: -1.1285481211579045 loss: 0.3341130923371725\n",
            "Round: 2516 Weight: [2.55249417 1.34730959] Bias: -1.1285500510680133 loss: 0.3341130919649093\n",
            "Round: 2517 Weight: [2.55249929 1.34731223] Bias: -1.1285519763012382 loss: 0.3341130915944477\n",
            "Round: 2518 Weight: [2.5525044  1.34731487] Bias: -1.1285538968689368 loss: 0.3341130912257792\n",
            "Round: 2519 Weight: [2.5525095 1.3473175] Bias: -1.1285558127824398 loss: 0.334113090858895\n",
            "Round: 2520 Weight: [2.55251458 1.34732012] Bias: -1.1285577240530495 loss: 0.33411309049378635\n",
            "Round: 2521 Weight: [2.55251966 1.34732273] Bias: -1.1285596306920411 loss: 0.33411309013044477\n",
            "Round: 2522 Weight: [2.55252471 1.34732534] Bias: -1.1285615327106622 loss: 0.33411308976886195\n",
            "Round: 2523 Weight: [2.55252976 1.34732795] Bias: -1.128563430120133 loss: 0.3341130894090288\n",
            "Round: 2524 Weight: [2.5525348  1.34733055] Bias: -1.1285653229316464 loss: 0.33411308905093734\n",
            "Round: 2525 Weight: [2.55253982 1.34733314] Bias: -1.1285672111563676 loss: 0.33411308869457895\n",
            "Round: 2526 Weight: [2.55254483 1.34733572] Bias: -1.1285690948054352 loss: 0.33411308833994524\n",
            "Round: 2527 Weight: [2.55254983 1.3473383 ] Bias: -1.12857097388996 loss: 0.3341130879870279\n",
            "Round: 2528 Weight: [2.55255482 1.34734087] Bias: -1.1285728484210265 loss: 0.3341130876358184\n",
            "Round: 2529 Weight: [2.55255979 1.34734344] Bias: -1.1285747184096913 loss: 0.3341130872863088\n",
            "Round: 2530 Weight: [2.55256475 1.347346  ] Bias: -1.1285765838669846 loss: 0.33411308693849057\n",
            "Round: 2531 Weight: [2.5525697  1.34734855] Bias: -1.1285784448039093 loss: 0.3341130865923557\n",
            "Round: 2532 Weight: [2.55257464 1.3473511 ] Bias: -1.1285803012314422 loss: 0.33411308624789604\n",
            "Round: 2533 Weight: [2.55257957 1.34735364] Bias: -1.1285821531605325 loss: 0.3341130859051034\n",
            "Round: 2534 Weight: [2.55258448 1.34735617] Bias: -1.128584000602103 loss: 0.3341130855639696\n",
            "Round: 2535 Weight: [2.55258938 1.3473587 ] Bias: -1.1285858435670502 loss: 0.33411308522448685\n",
            "Round: 2536 Weight: [2.55259427 1.34736123] Bias: -1.1285876820662435 loss: 0.33411308488664704\n",
            "Round: 2537 Weight: [2.55259915 1.34736374] Bias: -1.1285895161105264 loss: 0.33411308455044214\n",
            "Round: 2538 Weight: [2.55260402 1.34736625] Bias: -1.1285913457107153 loss: 0.33411308421586444\n",
            "Round: 2539 Weight: [2.55260887 1.34736876] Bias: -1.1285931708776007 loss: 0.3341130838829057\n",
            "Round: 2540 Weight: [2.55261372 1.34737126] Bias: -1.1285949916219467 loss: 0.33411308355155844\n",
            "Round: 2541 Weight: [2.55261855 1.34737375] Bias: -1.128596807954491 loss: 0.3341130832218147\n",
            "Round: 2542 Weight: [2.55262337 1.34737623] Bias: -1.1285986198859455 loss: 0.33411308289366665\n",
            "Round: 2543 Weight: [2.55262818 1.34737871] Bias: -1.1286004274269954 loss: 0.33411308256710665\n",
            "Round: 2544 Weight: [2.55263297 1.34738119] Bias: -1.1286022305883003 loss: 0.3341130822421269\n",
            "Round: 2545 Weight: [2.55263776 1.34738366] Bias: -1.1286040293804938 loss: 0.33411308191871986\n",
            "Round: 2546 Weight: [2.55264253 1.34738612] Bias: -1.1286058238141834 loss: 0.3341130815968779\n",
            "Round: 2547 Weight: [2.55264729 1.34738858] Bias: -1.1286076138999508 loss: 0.33411308127659356\n",
            "Round: 2548 Weight: [2.55265204 1.34739103] Bias: -1.128609399648352 loss: 0.334113080957859\n",
            "Round: 2549 Weight: [2.55265678 1.34739347] Bias: -1.128611181069917 loss: 0.33411308064066686\n",
            "Round: 2550 Weight: [2.55266151 1.34739591] Bias: -1.1286129581751507 loss: 0.33411308032500975\n",
            "Round: 2551 Weight: [2.55266623 1.34739834] Bias: -1.1286147309745318 loss: 0.3341130800108802\n",
            "Round: 2552 Weight: [2.55267093 1.34740077] Bias: -1.1286164994785137 loss: 0.33411307969827075\n",
            "Round: 2553 Weight: [2.55267562 1.34740319] Bias: -1.1286182636975244 loss: 0.33411307938717394\n",
            "Round: 2554 Weight: [2.5526803 1.3474056] Bias: -1.1286200236419663 loss: 0.3341130790775828\n",
            "Round: 2555 Weight: [2.55268497 1.34740801] Bias: -1.1286217793222166 loss: 0.33411307876948965\n",
            "Round: 2556 Weight: [2.55268963 1.34741042] Bias: -1.1286235307486272 loss: 0.33411307846288724\n",
            "Round: 2557 Weight: [2.55269428 1.34741281] Bias: -1.1286252779315247 loss: 0.33411307815776875\n",
            "Round: 2558 Weight: [2.55269892 1.3474152 ] Bias: -1.1286270208812104 loss: 0.33411307785412664\n",
            "Round: 2559 Weight: [2.55270354 1.34741759] Bias: -1.1286287596079607 loss: 0.33411307755195385\n",
            "Round: 2560 Weight: [2.55270816 1.34741997] Bias: -1.128630494122027 loss: 0.33411307725124334\n",
            "Round: 2561 Weight: [2.55271276 1.34742234] Bias: -1.128632224433636 loss: 0.3341130769519879\n",
            "Round: 2562 Weight: [2.55271735 1.34742471] Bias: -1.1286339505529885 loss: 0.33411307665418055\n",
            "Round: 2563 Weight: [2.55272193 1.34742708] Bias: -1.1286356724902615 loss: 0.33411307635781434\n",
            "Round: 2564 Weight: [2.5527265  1.34742943] Bias: -1.1286373902556066 loss: 0.3341130760628822\n",
            "Round: 2565 Weight: [2.55273106 1.34743178] Bias: -1.1286391038591508 loss: 0.33411307576937715\n",
            "Round: 2566 Weight: [2.55273561 1.34743413] Bias: -1.1286408133109964 loss: 0.33411307547729235\n",
            "Round: 2567 Weight: [2.55274014 1.34743647] Bias: -1.1286425186212214 loss: 0.334113075186621\n",
            "Round: 2568 Weight: [2.55274467 1.3474388 ] Bias: -1.1286442197998787 loss: 0.3341130748973561\n",
            "Round: 2569 Weight: [2.55274918 1.34744113] Bias: -1.1286459168569971 loss: 0.33411307460949097\n",
            "Round: 2570 Weight: [2.55275369 1.34744346] Bias: -1.1286476098025808 loss: 0.33411307432301857\n",
            "Round: 2571 Weight: [2.55275818 1.34744577] Bias: -1.12864929864661 loss: 0.33411307403793244\n",
            "Round: 2572 Weight: [2.55276266 1.34744809] Bias: -1.1286509833990397 loss: 0.3341130737542258\n",
            "Round: 2573 Weight: [2.55276713 1.34745039] Bias: -1.1286526640698016 loss: 0.33411307347189195\n",
            "Round: 2574 Weight: [2.55277159 1.34745269] Bias: -1.1286543406688028 loss: 0.3341130731909242\n",
            "Round: 2575 Weight: [2.55277604 1.34745499] Bias: -1.128656013205926 loss: 0.33411307291131603\n",
            "Round: 2576 Weight: [2.55278048 1.34745728] Bias: -1.1286576816910305 loss: 0.3341130726330607\n",
            "Round: 2577 Weight: [2.55278491 1.34745956] Bias: -1.128659346133951 loss: 0.3341130723561518\n",
            "Round: 2578 Weight: [2.55278932 1.34746184] Bias: -1.1286610065444982 loss: 0.3341130720805828\n",
            "Round: 2579 Weight: [2.55279373 1.34746411] Bias: -1.1286626629324594 loss: 0.3341130718063472\n",
            "Round: 2580 Weight: [2.55279812 1.34746638] Bias: -1.128664315307598 loss: 0.3341130715334384\n",
            "Round: 2581 Weight: [2.55280251 1.34746864] Bias: -1.1286659636796528 loss: 0.33411307126185014\n",
            "Round: 2582 Weight: [2.55280688 1.3474709 ] Bias: -1.12866760805834 loss: 0.33411307099157594\n",
            "Round: 2583 Weight: [2.55281125 1.34747315] Bias: -1.1286692484533514 loss: 0.3341130707226096\n",
            "Round: 2584 Weight: [2.5528156  1.34747539] Bias: -1.1286708848743554 loss: 0.3341130704549444\n",
            "Round: 2585 Weight: [2.55281994 1.34747763] Bias: -1.1286725173309968 loss: 0.3341130701885746\n",
            "Round: 2586 Weight: [2.55282428 1.34747987] Bias: -1.128674145832897 loss: 0.33411306992349354\n",
            "Round: 2587 Weight: [2.5528286 1.3474821] Bias: -1.1286757703896542 loss: 0.33411306965969495\n",
            "Round: 2588 Weight: [2.55283291 1.34748432] Bias: -1.1286773910108425 loss: 0.33411306939717283\n",
            "Round: 2589 Weight: [2.55283721 1.34748654] Bias: -1.1286790077060134 loss: 0.3341130691359209\n",
            "Round: 2590 Weight: [2.5528415  1.34748875] Bias: -1.1286806204846946 loss: 0.334113068875933\n",
            "Round: 2591 Weight: [2.55284578 1.34749096] Bias: -1.1286822293563912 loss: 0.3341130686172031\n",
            "Round: 2592 Weight: [2.55285005 1.34749316] Bias: -1.1286838343305847 loss: 0.334113068359725\n",
            "Round: 2593 Weight: [2.55285431 1.34749536] Bias: -1.1286854354167335 loss: 0.3341130681034925\n",
            "Round: 2594 Weight: [2.55285856 1.34749755] Bias: -1.1286870326242733 loss: 0.33411306784849987\n",
            "Round: 2595 Weight: [2.55286279 1.34749974] Bias: -1.1286886259626163 loss: 0.3341130675947411\n",
            "Round: 2596 Weight: [2.55286702 1.34750192] Bias: -1.1286902154411524 loss: 0.33411306734220986\n",
            "Round: 2597 Weight: [2.55287124 1.34750409] Bias: -1.1286918010692482 loss: 0.3341130670909005\n",
            "Round: 2598 Weight: [2.55287545 1.34750626] Bias: -1.1286933828562475 loss: 0.3341130668408071\n",
            "Round: 2599 Weight: [2.55287965 1.34750843] Bias: -1.1286949608114716 loss: 0.33411306659192375\n",
            "Round: 2600 Weight: [2.55288383 1.34751059] Bias: -1.1286965349442188 loss: 0.33411306634424437\n",
            "Round: 2601 Weight: [2.55288801 1.34751274] Bias: -1.128698105263765 loss: 0.33411306609776353\n",
            "Round: 2602 Weight: [2.55289218 1.34751489] Bias: -1.1286996717793636 loss: 0.334113065852475\n",
            "Round: 2603 Weight: [2.55289633 1.34751704] Bias: -1.128701234500245 loss: 0.33411306560837334\n",
            "Round: 2604 Weight: [2.55290048 1.34751918] Bias: -1.1287027934356175 loss: 0.3341130653654527\n",
            "Round: 2605 Weight: [2.55290462 1.34752131] Bias: -1.128704348594667 loss: 0.3341130651237073\n",
            "Round: 2606 Weight: [2.55290875 1.34752344] Bias: -1.128705899986557 loss: 0.33411306488313147\n",
            "Round: 2607 Weight: [2.55291286 1.34752556] Bias: -1.1287074476204282 loss: 0.3341130646437196\n",
            "Round: 2608 Weight: [2.55291697 1.34752768] Bias: -1.1287089915053998 loss: 0.33411306440546595\n",
            "Round: 2609 Weight: [2.55292107 1.3475298 ] Bias: -1.1287105316505683 loss: 0.33411306416836517\n",
            "Round: 2610 Weight: [2.55292515 1.3475319 ] Bias: -1.1287120680650085 loss: 0.33411306393241136\n",
            "Round: 2611 Weight: [2.55292923 1.34753401] Bias: -1.1287136007577725 loss: 0.3341130636975991\n",
            "Round: 2612 Weight: [2.5529333  1.34753611] Bias: -1.1287151297378908 loss: 0.3341130634639228\n",
            "Round: 2613 Weight: [2.55293736 1.3475382 ] Bias: -1.1287166550143717 loss: 0.3341130632313771\n",
            "Round: 2614 Weight: [2.5529414  1.34754029] Bias: -1.1287181765962018 loss: 0.33411306299995647\n",
            "Round: 2615 Weight: [2.55294544 1.34754237] Bias: -1.1287196944923454 loss: 0.33411306276965536\n",
            "Round: 2616 Weight: [2.55294947 1.34754445] Bias: -1.1287212087117457 loss: 0.3341130625404685\n",
            "Round: 2617 Weight: [2.55295349 1.34754652] Bias: -1.1287227192633233 loss: 0.3341130623123904\n",
            "Round: 2618 Weight: [2.5529575  1.34754859] Bias: -1.1287242261559778 loss: 0.33411306208541575\n",
            "Round: 2619 Weight: [2.55296149 1.34755065] Bias: -1.1287257293985864 loss: 0.3341130618595392\n",
            "Round: 2620 Weight: [2.55296548 1.34755271] Bias: -1.1287272290000054 loss: 0.33411306163475535\n",
            "Round: 2621 Weight: [2.55296946 1.34755476] Bias: -1.1287287249690692 loss: 0.3341130614110589\n",
            "Round: 2622 Weight: [2.55297343 1.34755681] Bias: -1.1287302173145906 loss: 0.3341130611884448\n",
            "Round: 2623 Weight: [2.55297739 1.34755885] Bias: -1.128731706045361 loss: 0.33411306096690757\n",
            "Round: 2624 Weight: [2.55298134 1.34756089] Bias: -1.1287331911701506 loss: 0.33411306074644204\n",
            "Round: 2625 Weight: [2.55298529 1.34756292] Bias: -1.128734672697708 loss: 0.3341130605270432\n",
            "Round: 2626 Weight: [2.55298922 1.34756495] Bias: -1.128736150636761 loss: 0.3341130603087057\n",
            "Round: 2627 Weight: [2.55299314 1.34756697] Bias: -1.1287376249960155 loss: 0.33411306009142444\n",
            "Round: 2628 Weight: [2.55299705 1.34756899] Bias: -1.1287390957841565 loss: 0.3341130598751943\n",
            "Round: 2629 Weight: [2.55300095 1.34757101] Bias: -1.128740563009848 loss: 0.33411305966001026\n",
            "Round: 2630 Weight: [2.55300485 1.34757301] Bias: -1.1287420266817325 loss: 0.3341130594458671\n",
            "Round: 2631 Weight: [2.55300873 1.34757502] Bias: -1.1287434868084318 loss: 0.33411305923276013\n",
            "Round: 2632 Weight: [2.55301261 1.34757702] Bias: -1.1287449433985468 loss: 0.33411305902068394\n",
            "Round: 2633 Weight: [2.55301647 1.34757901] Bias: -1.1287463964606572 loss: 0.3341130588096337\n",
            "Round: 2634 Weight: [2.55302033 1.347581  ] Bias: -1.128747846003322 loss: 0.3341130585996045\n",
            "Round: 2635 Weight: [2.55302418 1.34758298] Bias: -1.1287492920350795 loss: 0.3341130583905913\n",
            "Round: 2636 Weight: [2.55302801 1.34758496] Bias: -1.1287507345644467 loss: 0.3341130581825892\n",
            "Round: 2637 Weight: [2.55303184 1.34758694] Bias: -1.1287521735999204 loss: 0.3341130579755933\n",
            "Round: 2638 Weight: [2.55303566 1.34758891] Bias: -1.1287536091499764 loss: 0.3341130577695988\n",
            "Round: 2639 Weight: [2.55303947 1.34759087] Bias: -1.1287550412230698 loss: 0.3341130575646008\n",
            "Round: 2640 Weight: [2.55304327 1.34759283] Bias: -1.1287564698276358 loss: 0.3341130573605945\n",
            "Round: 2641 Weight: [2.55304706 1.34759479] Bias: -1.1287578949720882 loss: 0.334113057157575\n",
            "Round: 2642 Weight: [2.55305084 1.34759674] Bias: -1.1287593166648209 loss: 0.33411305695553756\n",
            "Round: 2643 Weight: [2.55305462 1.34759869] Bias: -1.128760734914207 loss: 0.33411305675447767\n",
            "Round: 2644 Weight: [2.55305838 1.34760063] Bias: -1.1287621497285996 loss: 0.3341130565543903\n",
            "Round: 2645 Weight: [2.55306213 1.34760256] Bias: -1.1287635611163311 loss: 0.33411305635527083\n",
            "Round: 2646 Weight: [2.55306588 1.3476045 ] Bias: -1.128764969085714 loss: 0.33411305615711445\n",
            "Round: 2647 Weight: [2.55306962 1.34760642] Bias: -1.1287663736450402 loss: 0.3341130559599168\n",
            "Round: 2648 Weight: [2.55307334 1.34760835] Bias: -1.1287677748025817 loss: 0.33411305576367306\n",
            "Round: 2649 Weight: [2.55307706 1.34761026] Bias: -1.1287691725665903 loss: 0.3341130555683785\n",
            "Round: 2650 Weight: [2.55308077 1.34761218] Bias: -1.1287705669452976 loss: 0.3341130553740288\n",
            "Round: 2651 Weight: [2.55308447 1.34761409] Bias: -1.1287719579469155 loss: 0.3341130551806191\n",
            "Round: 2652 Weight: [2.55308816 1.34761599] Bias: -1.1287733455796356 loss: 0.3341130549881451\n",
            "Round: 2653 Weight: [2.55309185 1.34761789] Bias: -1.1287747298516295 loss: 0.334113054796602\n",
            "Round: 2654 Weight: [2.55309552 1.34761978] Bias: -1.128776110771049 loss: 0.33411305460598567\n",
            "Round: 2655 Weight: [2.55309918 1.34762167] Bias: -1.1287774883460264 loss: 0.3341130544162912\n",
            "Round: 2656 Weight: [2.55310284 1.34762356] Bias: -1.1287788625846737 loss: 0.33411305422751447\n",
            "Round: 2657 Weight: [2.55310649 1.34762544] Bias: -1.1287802334950838 loss: 0.3341130540396508\n",
            "Round: 2658 Weight: [2.55311012 1.34762732] Bias: -1.128781601085329 loss: 0.3341130538526959\n",
            "Round: 2659 Weight: [2.55311375 1.34762919] Bias: -1.1287829653634631 loss: 0.33411305366664534\n",
            "Round: 2660 Weight: [2.55311737 1.34763106] Bias: -1.1287843263375192 loss: 0.33411305348149467\n",
            "Round: 2661 Weight: [2.55312099 1.34763292] Bias: -1.1287856840155115 loss: 0.3341130532972396\n",
            "Round: 2662 Weight: [2.55312459 1.34763478] Bias: -1.1287870384054346 loss: 0.33411305311387596\n",
            "Round: 2663 Weight: [2.55312818 1.34763663] Bias: -1.1287883895152637 loss: 0.3341130529313992\n",
            "Round: 2664 Weight: [2.55313177 1.34763848] Bias: -1.1287897373529543 loss: 0.334113052749805\n",
            "Round: 2665 Weight: [2.55313535 1.34764033] Bias: -1.1287910819264428 loss: 0.3341130525690893\n",
            "Round: 2666 Weight: [2.55313891 1.34764217] Bias: -1.1287924232436464 loss: 0.3341130523892477\n",
            "Round: 2667 Weight: [2.55314247 1.347644  ] Bias: -1.1287937613124628 loss: 0.334113052210276\n",
            "Round: 2668 Weight: [2.55314602 1.34764584] Bias: -1.1287950961407704 loss: 0.33411305203216995\n",
            "Round: 2669 Weight: [2.55314957 1.34764766] Bias: -1.1287964277364289 loss: 0.3341130518549255\n",
            "Round: 2670 Weight: [2.5531531  1.34764949] Bias: -1.1287977561072784 loss: 0.3341130516785383\n",
            "Round: 2671 Weight: [2.55315663 1.3476513 ] Bias: -1.1287990812611401 loss: 0.33411305150300447\n",
            "Round: 2672 Weight: [2.55316014 1.34765312] Bias: -1.1288004032058165 loss: 0.33411305132831953\n",
            "Round: 2673 Weight: [2.55316365 1.34765493] Bias: -1.1288017219490905 loss: 0.33411305115447953\n",
            "Round: 2674 Weight: [2.55316715 1.34765673] Bias: -1.1288030374987263 loss: 0.33411305098148036\n",
            "Round: 2675 Weight: [2.55317064 1.34765853] Bias: -1.1288043498624696 loss: 0.33411305080931814\n",
            "Round: 2676 Weight: [2.55317412 1.34766033] Bias: -1.1288056590480469 loss: 0.3341130506379885\n",
            "Round: 2677 Weight: [2.5531776  1.34766212] Bias: -1.1288069650631658 loss: 0.33411305046748757\n",
            "Round: 2678 Weight: [2.55318106 1.34766391] Bias: -1.1288082679155156 loss: 0.33411305029781146\n",
            "Round: 2679 Weight: [2.55318452 1.34766569] Bias: -1.1288095676127663 loss: 0.33411305012895587\n",
            "Round: 2680 Weight: [2.55318797 1.34766747] Bias: -1.1288108641625698 loss: 0.3341130499609172\n",
            "Round: 2681 Weight: [2.55319141 1.34766925] Bias: -1.128812157572559 loss: 0.3341130497936913\n",
            "Round: 2682 Weight: [2.55319484 1.34767102] Bias: -1.1288134478503484 loss: 0.3341130496272741\n",
            "Round: 2683 Weight: [2.55319827 1.34767279] Bias: -1.128814735003534 loss: 0.33411304946166187\n",
            "Round: 2684 Weight: [2.55320168 1.34767455] Bias: -1.1288160190396934 loss: 0.3341130492968507\n",
            "Round: 2685 Weight: [2.55320509 1.3476763 ] Bias: -1.1288172999663857 loss: 0.3341130491328367\n",
            "Round: 2686 Weight: [2.55320849 1.34767806] Bias: -1.1288185777911512 loss: 0.33411304896961597\n",
            "Round: 2687 Weight: [2.55321188 1.34767981] Bias: -1.1288198525215127 loss: 0.3341130488071846\n",
            "Round: 2688 Weight: [2.55321526 1.34768155] Bias: -1.1288211241649742 loss: 0.3341130486455391\n",
            "Round: 2689 Weight: [2.55321864 1.34768329] Bias: -1.1288223927290213 loss: 0.33411304848467527\n",
            "Round: 2690 Weight: [2.55322201 1.34768503] Bias: -1.1288236582211215 loss: 0.3341130483245896\n",
            "Round: 2691 Weight: [2.55322536 1.34768676] Bias: -1.1288249206487246 loss: 0.33411304816527815\n",
            "Round: 2692 Weight: [2.55322871 1.34768849] Bias: -1.1288261800192618 loss: 0.3341130480067372\n",
            "Round: 2693 Weight: [2.55323206 1.34769021] Bias: -1.1288274363401463 loss: 0.3341130478489632\n",
            "Round: 2694 Weight: [2.55323539 1.34769193] Bias: -1.1288286896187731 loss: 0.33411304769195205\n",
            "Round: 2695 Weight: [2.55323872 1.34769365] Bias: -1.12882993986252 loss: 0.3341130475357004\n",
            "Round: 2696 Weight: [2.55324203 1.34769536] Bias: -1.1288311870787457 loss: 0.33411304738020464\n",
            "Round: 2697 Weight: [2.55324534 1.34769707] Bias: -1.128832431274792 loss: 0.3341130472254609\n",
            "Round: 2698 Weight: [2.55324865 1.34769877] Bias: -1.1288336724579822 loss: 0.33411304707146555\n",
            "Round: 2699 Weight: [2.55325194 1.34770047] Bias: -1.1288349106356224 loss: 0.3341130469182149\n",
            "Round: 2700 Weight: [2.55325523 1.34770217] Bias: -1.1288361458150002 loss: 0.33411304676570563\n",
            "Round: 2701 Weight: [2.5532585  1.34770386] Bias: -1.1288373780033862 loss: 0.334113046613934\n",
            "Round: 2702 Weight: [2.55326177 1.34770554] Bias: -1.1288386072080328 loss: 0.33411304646289625\n",
            "Round: 2703 Weight: [2.55326504 1.34770723] Bias: -1.1288398334361749 loss: 0.334113046312589\n",
            "Round: 2704 Weight: [2.55326829 1.3477089 ] Bias: -1.12884105669503 loss: 0.3341130461630088\n",
            "Round: 2705 Weight: [2.55327154 1.34771058] Bias: -1.1288422769917978 loss: 0.33411304601415204\n",
            "Round: 2706 Weight: [2.55327477 1.34771225] Bias: -1.128843494333661 loss: 0.33411304586601515\n",
            "Round: 2707 Weight: [2.553278   1.34771392] Bias: -1.128844708727784 loss: 0.3341130457185948\n",
            "Round: 2708 Weight: [2.55328123 1.34771558] Bias: -1.1288459201813144 loss: 0.33411304557188753\n",
            "Round: 2709 Weight: [2.55328444 1.34771724] Bias: -1.1288471287013822 loss: 0.33411304542588965\n",
            "Round: 2710 Weight: [2.55328765 1.34771889] Bias: -1.1288483342951001 loss: 0.3341130452805979\n",
            "Round: 2711 Weight: [2.55329085 1.34772054] Bias: -1.1288495369695637 loss: 0.33411304513600887\n",
            "Round: 2712 Weight: [2.55329404 1.34772219] Bias: -1.128850736731851 loss: 0.334113044992119\n",
            "Round: 2713 Weight: [2.55329722 1.34772383] Bias: -1.128851933589023 loss: 0.33411304484892534\n",
            "Round: 2714 Weight: [2.5533004  1.34772547] Bias: -1.1288531275481237 loss: 0.33411304470642395\n",
            "Round: 2715 Weight: [2.55330357 1.3477271 ] Bias: -1.1288543186161795 loss: 0.3341130445646118\n",
            "Round: 2716 Weight: [2.55330673 1.34772873] Bias: -1.1288555068002002 loss: 0.33411304442348555\n",
            "Round: 2717 Weight: [2.55330988 1.34773036] Bias: -1.128856692107178 loss: 0.33411304428304184\n",
            "Round: 2718 Weight: [2.55331303 1.34773198] Bias: -1.128857874544089 loss: 0.3341130441432773\n",
            "Round: 2719 Weight: [2.55331617 1.3477336 ] Bias: -1.1288590541178913 loss: 0.33411304400418873\n",
            "Round: 2720 Weight: [2.5533193  1.34773522] Bias: -1.1288602308355271 loss: 0.33411304386577273\n",
            "Round: 2721 Weight: [2.55332242 1.34773683] Bias: -1.128861404703921 loss: 0.33411304372802636\n",
            "Round: 2722 Weight: [2.55332554 1.34773843] Bias: -1.1288625757299806 loss: 0.3341130435909461\n",
            "Round: 2723 Weight: [2.55332864 1.34774004] Bias: -1.1288637439205975 loss: 0.33411304345452864\n",
            "Round: 2724 Weight: [2.55333174 1.34774164] Bias: -1.1288649092826462 loss: 0.33411304331877106\n",
            "Round: 2725 Weight: [2.55333484 1.34774323] Bias: -1.1288660718229842 loss: 0.33411304318367\n",
            "Round: 2726 Weight: [2.55333792 1.34774482] Bias: -1.1288672315484525 loss: 0.33411304304922235\n",
            "Round: 2727 Weight: [2.553341   1.34774641] Bias: -1.1288683884658757 loss: 0.3341130429154249\n",
            "Round: 2728 Weight: [2.55334407 1.34774799] Bias: -1.1288695425820616 loss: 0.33411304278227444\n",
            "Round: 2729 Weight: [2.55334713 1.34774957] Bias: -1.1288706939038016 loss: 0.334113042649768\n",
            "Round: 2730 Weight: [2.55335019 1.34775115] Bias: -1.1288718424378703 loss: 0.33411304251790236\n",
            "Round: 2731 Weight: [2.55335324 1.34775272] Bias: -1.1288729881910262 loss: 0.33411304238667433\n",
            "Round: 2732 Weight: [2.55335628 1.34775429] Bias: -1.128874131170011 loss: 0.334113042256081\n",
            "Round: 2733 Weight: [2.55335931 1.34775586] Bias: -1.1288752713815504 loss: 0.3341130421261193\n",
            "Round: 2734 Weight: [2.55336234 1.34775742] Bias: -1.1288764088323535 loss: 0.33411304199678615\n",
            "Round: 2735 Weight: [2.55336535 1.34775897] Bias: -1.1288775435291132 loss: 0.33411304186807844\n",
            "Round: 2736 Weight: [2.55336837 1.34776053] Bias: -1.128878675478506 loss: 0.33411304173999307\n",
            "Round: 2737 Weight: [2.55337137 1.34776208] Bias: -1.1288798046871924 loss: 0.33411304161252714\n",
            "Round: 2738 Weight: [2.55337437 1.34776362] Bias: -1.1288809311618164 loss: 0.3341130414856777\n",
            "Round: 2739 Weight: [2.55337736 1.34776516] Bias: -1.1288820549090062 loss: 0.33411304135944164\n",
            "Round: 2740 Weight: [2.55338034 1.3477667 ] Bias: -1.1288831759353735 loss: 0.33411304123381613\n",
            "Round: 2741 Weight: [2.55338331 1.34776824] Bias: -1.1288842942475144 loss: 0.3341130411087981\n",
            "Round: 2742 Weight: [2.55338628 1.34776977] Bias: -1.1288854098520085 loss: 0.3341130409843847\n",
            "Round: 2743 Weight: [2.55338924 1.34777129] Bias: -1.1288865227554197 loss: 0.3341130408605729\n",
            "Round: 2744 Weight: [2.5533922  1.34777282] Bias: -1.128887632964296 loss: 0.33411304073736\n",
            "Round: 2745 Weight: [2.55339514 1.34777434] Bias: -1.1288887404851693 loss: 0.3341130406147426\n",
            "Round: 2746 Weight: [2.55339808 1.34777585] Bias: -1.1288898453245557 loss: 0.3341130404927185\n",
            "Round: 2747 Weight: [2.55340101 1.34777737] Bias: -1.1288909474889555 loss: 0.3341130403712844\n",
            "Round: 2748 Weight: [2.55340394 1.34777888] Bias: -1.1288920469848531 loss: 0.33411304025043753\n",
            "Round: 2749 Weight: [2.55340686 1.34778038] Bias: -1.1288931438187173 loss: 0.33411304013017507\n",
            "Round: 2750 Weight: [2.55340977 1.34778188] Bias: -1.128894237997001 loss: 0.33411304001049413\n",
            "Round: 2751 Weight: [2.55341267 1.34778338] Bias: -1.1288953295261417 loss: 0.334113039891392\n",
            "Round: 2752 Weight: [2.55341557 1.34778487] Bias: -1.1288964184125607 loss: 0.3341130397728658\n",
            "Round: 2753 Weight: [2.55341846 1.34778636] Bias: -1.1288975046626644 loss: 0.3341130396549129\n",
            "Round: 2754 Weight: [2.55342134 1.34778785] Bias: -1.128898588282843 loss: 0.3341130395375303\n",
            "Round: 2755 Weight: [2.55342422 1.34778934] Bias: -1.128899669279472 loss: 0.33411303942071524\n",
            "Round: 2756 Weight: [2.55342708 1.34779082] Bias: -1.1289007476589104 loss: 0.33411303930446534\n",
            "Round: 2757 Weight: [2.55342995 1.34779229] Bias: -1.1289018234275023 loss: 0.33411303918877727\n",
            "Round: 2758 Weight: [2.5534328  1.34779376] Bias: -1.1289028965915764 loss: 0.33411303907364887\n",
            "Round: 2759 Weight: [2.55343565 1.34779523] Bias: -1.128903967157446 loss: 0.33411303895907724\n",
            "Round: 2760 Weight: [2.55343849 1.3477967 ] Bias: -1.1289050351314087 loss: 0.3341130388450594\n",
            "Round: 2761 Weight: [2.55344132 1.34779816] Bias: -1.1289061005197474 loss: 0.3341130387315932\n",
            "Round: 2762 Weight: [2.55344415 1.34779962] Bias: -1.1289071633287293 loss: 0.3341130386186756\n",
            "Round: 2763 Weight: [2.55344697 1.34780107] Bias: -1.1289082235646066 loss: 0.3341130385063039\n",
            "Round: 2764 Weight: [2.55344979 1.34780253] Bias: -1.1289092812336161 loss: 0.33411303839447576\n",
            "Round: 2765 Weight: [2.55345259 1.34780397] Bias: -1.1289103363419797 loss: 0.3341130382831883\n",
            "Round: 2766 Weight: [2.55345539 1.34780542] Bias: -1.128911388895904 loss: 0.334113038172439\n",
            "Round: 2767 Weight: [2.55345819 1.34780686] Bias: -1.1289124389015803 loss: 0.33411303806222525\n",
            "Round: 2768 Weight: [2.55346097 1.3478083 ] Bias: -1.1289134863651855 loss: 0.33411303795254443\n",
            "Round: 2769 Weight: [2.55346375 1.34780973] Bias: -1.128914531292881 loss: 0.33411303784339397\n",
            "Round: 2770 Weight: [2.55346653 1.34781116] Bias: -1.1289155736908134 loss: 0.3341130377347714\n",
            "Round: 2771 Weight: [2.55346929 1.34781259] Bias: -1.1289166135651143 loss: 0.33411303762667405\n",
            "Round: 2772 Weight: [2.55347205 1.34781401] Bias: -1.1289176509219003 loss: 0.3341130375190995\n",
            "Round: 2773 Weight: [2.5534748  1.34781543] Bias: -1.1289186857672733 loss: 0.334113037412045\n",
            "Round: 2774 Weight: [2.55347755 1.34781685] Bias: -1.1289197181073203 loss: 0.3341130373055082\n",
            "Round: 2775 Weight: [2.55348029 1.34781826] Bias: -1.1289207479481136 loss: 0.33411303719948665\n",
            "Round: 2776 Weight: [2.55348302 1.34781967] Bias: -1.1289217752957108 loss: 0.3341130370939777\n",
            "Round: 2777 Weight: [2.55348575 1.34782108] Bias: -1.1289228001561546 loss: 0.334113036988979\n",
            "Round: 2778 Weight: [2.55348847 1.34782248] Bias: -1.1289238225354732 loss: 0.33411303688448785\n",
            "Round: 2779 Weight: [2.55349118 1.34782388] Bias: -1.1289248424396798 loss: 0.3341130367805022\n",
            "Round: 2780 Weight: [2.55349389 1.34782528] Bias: -1.1289258598747736 loss: 0.3341130366770192\n",
            "Round: 2781 Weight: [2.55349659 1.34782667] Bias: -1.1289268748467385 loss: 0.3341130365740367\n",
            "Round: 2782 Weight: [2.55349928 1.34782806] Bias: -1.1289278873615445 loss: 0.3341130364715521\n",
            "Round: 2783 Weight: [2.55350197 1.34782944] Bias: -1.1289288974251468 loss: 0.33411303636956313\n",
            "Round: 2784 Weight: [2.55350465 1.34783083] Bias: -1.1289299050434862 loss: 0.33411303626806726\n",
            "Round: 2785 Weight: [2.55350733 1.34783221] Bias: -1.1289309102224891 loss: 0.3341130361670622\n",
            "Round: 2786 Weight: [2.55350999 1.34783358] Bias: -1.1289319129680675 loss: 0.3341130360665456\n",
            "Round: 2787 Weight: [2.55351265 1.34783495] Bias: -1.1289329132861188 loss: 0.334113035966515\n",
            "Round: 2788 Weight: [2.55351531 1.34783632] Bias: -1.1289339111825263 loss: 0.3341130358669679\n",
            "Round: 2789 Weight: [2.55351796 1.34783769] Bias: -1.1289349066631589 loss: 0.3341130357679024\n",
            "Round: 2790 Weight: [2.5535206  1.34783905] Bias: -1.1289358997338714 loss: 0.3341130356693158\n",
            "Round: 2791 Weight: [2.55352323 1.34784041] Bias: -1.1289368904005046 loss: 0.3341130355712059\n",
            "Round: 2792 Weight: [2.55352586 1.34784177] Bias: -1.1289378786688844 loss: 0.3341130354735705\n",
            "Round: 2793 Weight: [2.55352849 1.34784312] Bias: -1.1289388645448233 loss: 0.3341130353764072\n",
            "Round: 2794 Weight: [2.5535311  1.34784447] Bias: -1.128939848034119 loss: 0.3341130352797136\n",
            "Round: 2795 Weight: [2.55353371 1.34784582] Bias: -1.1289408291425558 loss: 0.3341130351834876\n",
            "Round: 2796 Weight: [2.55353632 1.34784716] Bias: -1.1289418078759035 loss: 0.3341130350877269\n",
            "Round: 2797 Weight: [2.55353891 1.3478485 ] Bias: -1.1289427842399178 loss: 0.33411303499242917\n",
            "Round: 2798 Weight: [2.55354151 1.34784984] Bias: -1.128943758240341 loss: 0.3341130348975923\n",
            "Round: 2799 Weight: [2.55354409 1.34785117] Bias: -1.1289447298829007 loss: 0.3341130348032139\n",
            "Round: 2800 Weight: [2.55354667 1.3478525 ] Bias: -1.1289456991733113 loss: 0.3341130347092919\n",
            "Round: 2801 Weight: [2.55354924 1.34785383] Bias: -1.128946666117273 loss: 0.33411303461582414\n",
            "Round: 2802 Weight: [2.55355181 1.34785515] Bias: -1.1289476307204718 loss: 0.3341130345228081\n",
            "Round: 2803 Weight: [2.55355437 1.34785647] Bias: -1.1289485929885805 loss: 0.33411303443024193\n",
            "Round: 2804 Weight: [2.55355692 1.34785779] Bias: -1.1289495529272577 loss: 0.3341130343381234\n",
            "Round: 2805 Weight: [2.55355947 1.3478591 ] Bias: -1.1289505105421487 loss: 0.3341130342464502\n",
            "Round: 2806 Weight: [2.55356201 1.34786041] Bias: -1.1289514658388846 loss: 0.33411303415522026\n",
            "Round: 2807 Weight: [2.55356455 1.34786172] Bias: -1.128952418823083 loss: 0.33411303406443155\n",
            "Round: 2808 Weight: [2.55356707 1.34786303] Bias: -1.1289533695003482 loss: 0.33411303397408165\n",
            "Round: 2809 Weight: [2.5535696  1.34786433] Bias: -1.1289543178762702 loss: 0.33411303388416863\n",
            "Round: 2810 Weight: [2.55357211 1.34786563] Bias: -1.128955263956426 loss: 0.3341130337946905\n",
            "Round: 2811 Weight: [2.55357463 1.34786692] Bias: -1.1289562077463788 loss: 0.3341130337056449\n",
            "Round: 2812 Weight: [2.55357713 1.34786821] Bias: -1.1289571492516786 loss: 0.3341130336170299\n",
            "Round: 2813 Weight: [2.55357963 1.3478695 ] Bias: -1.1289580884778614 loss: 0.33411303352884325\n",
            "Round: 2814 Weight: [2.55358212 1.34787079] Bias: -1.12895902543045 loss: 0.3341130334410831\n",
            "Round: 2815 Weight: [2.55358461 1.34787207] Bias: -1.128959960114954 loss: 0.3341130333537472\n",
            "Round: 2816 Weight: [2.55358709 1.34787335] Bias: -1.1289608925368695 loss: 0.33411303326683367\n",
            "Round: 2817 Weight: [2.55358956 1.34787463] Bias: -1.128961822701679 loss: 0.33411303318034036\n",
            "Round: 2818 Weight: [2.55359203 1.3478759 ] Bias: -1.1289627506148523 loss: 0.3341130330942651\n",
            "Round: 2819 Weight: [2.55359449 1.34787717] Bias: -1.1289636762818451 loss: 0.33411303300860623\n",
            "Round: 2820 Weight: [2.55359695 1.34787844] Bias: -1.1289645997081004 loss: 0.3341130329233615\n",
            "Round: 2821 Weight: [2.5535994 1.3478797] Bias: -1.1289655208990477 loss: 0.3341130328385287\n",
            "Round: 2822 Weight: [2.55360185 1.34788096] Bias: -1.1289664398601036 loss: 0.3341130327541063\n",
            "Round: 2823 Weight: [2.55360429 1.34788222] Bias: -1.1289673565966714 loss: 0.334113032670092\n",
            "Round: 2824 Weight: [2.55360672 1.34788348] Bias: -1.1289682711141413 loss: 0.334113032586484\n",
            "Round: 2825 Weight: [2.55360915 1.34788473] Bias: -1.1289691834178905 loss: 0.33411303250328\n",
            "Round: 2826 Weight: [2.55361157 1.34788598] Bias: -1.128970093513283 loss: 0.3341130324204786\n",
            "Round: 2827 Weight: [2.55361398 1.34788722] Bias: -1.1289710014056695 loss: 0.3341130323380774\n",
            "Round: 2828 Weight: [2.55361639 1.34788846] Bias: -1.1289719071003885 loss: 0.3341130322560746\n",
            "Round: 2829 Weight: [2.55361879 1.3478897 ] Bias: -1.128972810602765 loss: 0.33411303217446825\n",
            "Round: 2830 Weight: [2.55362119 1.34789094] Bias: -1.128973711918111 loss: 0.3341130320932565\n",
            "Round: 2831 Weight: [2.55362358 1.34789218] Bias: -1.1289746110517256 loss: 0.33411303201243736\n",
            "Round: 2832 Weight: [2.55362597 1.34789341] Bias: -1.1289755080088955 loss: 0.33411303193200903\n",
            "Round: 2833 Weight: [2.55362835 1.34789463] Bias: -1.1289764027948939 loss: 0.3341130318519696\n",
            "Round: 2834 Weight: [2.55363073 1.34789586] Bias: -1.1289772954149817 loss: 0.334113031772317\n",
            "Round: 2835 Weight: [2.55363309 1.34789708] Bias: -1.128978185874407 loss: 0.3341130316930496\n",
            "Round: 2836 Weight: [2.55363546 1.3478983 ] Bias: -1.128979074178405 loss: 0.33411303161416545\n",
            "Round: 2837 Weight: [2.55363782 1.34789952] Bias: -1.1289799603321982 loss: 0.33411303153566274\n",
            "Round: 2838 Weight: [2.55364017 1.34790073] Bias: -1.1289808443409963 loss: 0.33411303145753946\n",
            "Round: 2839 Weight: [2.55364251 1.34790194] Bias: -1.1289817262099966 loss: 0.3341130313797941\n",
            "Round: 2840 Weight: [2.55364485 1.34790315] Bias: -1.1289826059443837 loss: 0.3341130313024244\n",
            "Round: 2841 Weight: [2.55364719 1.34790435] Bias: -1.1289834835493295 loss: 0.3341130312254289\n",
            "Round: 2842 Weight: [2.55364952 1.34790555] Bias: -1.1289843590299937 loss: 0.3341130311488057\n",
            "Round: 2843 Weight: [2.55365184 1.34790675] Bias: -1.1289852323915228 loss: 0.3341130310725528\n",
            "Round: 2844 Weight: [2.55365416 1.34790795] Bias: -1.1289861036390516 loss: 0.33411303099666867\n",
            "Round: 2845 Weight: [2.55365647 1.34790914] Bias: -1.1289869727777018 loss: 0.33411303092115135\n",
            "Round: 2846 Weight: [2.55365878 1.34791033] Bias: -1.128987839812583 loss: 0.3341130308459992\n",
            "Round: 2847 Weight: [2.55366108 1.34791152] Bias: -1.1289887047487923 loss: 0.3341130307712104\n",
            "Round: 2848 Weight: [2.55366337 1.3479127 ] Bias: -1.1289895675914146 loss: 0.3341130306967832\n",
            "Round: 2849 Weight: [2.55366566 1.34791388] Bias: -1.1289904283455219 loss: 0.3341130306227157\n",
            "Round: 2850 Weight: [2.55366795 1.34791506] Bias: -1.1289912870161747 loss: 0.3341130305490065\n",
            "Round: 2851 Weight: [2.55367023 1.34791623] Bias: -1.1289921436084205 loss: 0.3341130304756535\n",
            "Round: 2852 Weight: [2.5536725  1.34791741] Bias: -1.128992998127295 loss: 0.33411303040265516\n",
            "Round: 2853 Weight: [2.55367477 1.34791858] Bias: -1.1289938505778216 loss: 0.33411303033000983\n",
            "Round: 2854 Weight: [2.55367703 1.34791974] Bias: -1.1289947009650112 loss: 0.3341130302577157\n",
            "Round: 2855 Weight: [2.55367929 1.34792091] Bias: -1.128995549293863 loss: 0.334113030185771\n",
            "Round: 2856 Weight: [2.55368154 1.34792207] Bias: -1.1289963955693638 loss: 0.3341130301141742\n",
            "Round: 2857 Weight: [2.55368379 1.34792323] Bias: -1.1289972397964883 loss: 0.3341130300429235\n",
            "Round: 2858 Weight: [2.55368603 1.34792438] Bias: -1.128998081980199 loss: 0.33411302997201736\n",
            "Round: 2859 Weight: [2.55368826 1.34792554] Bias: -1.1289989221254466 loss: 0.3341130299014539\n",
            "Round: 2860 Weight: [2.55369049 1.34792669] Bias: -1.1289997602371697 loss: 0.33411302983123176\n",
            "Round: 2861 Weight: [2.55369271 1.34792783] Bias: -1.129000596320295 loss: 0.33411302976134893\n",
            "Round: 2862 Weight: [2.55369493 1.34792898] Bias: -1.1290014303797369 loss: 0.334113029691804\n",
            "Round: 2863 Weight: [2.55369715 1.34793012] Bias: -1.1290022624203984 loss: 0.33411302962259537\n",
            "Round: 2864 Weight: [2.55369936 1.34793126] Bias: -1.1290030924471701 loss: 0.33411302955372135\n",
            "Round: 2865 Weight: [2.55370156 1.3479324 ] Bias: -1.1290039204649311 loss: 0.33411302948518035\n",
            "Round: 2866 Weight: [2.55370376 1.34793353] Bias: -1.1290047464785486 loss: 0.3341130294169704\n",
            "Round: 2867 Weight: [2.55370595 1.34793466] Bias: -1.1290055704928779 loss: 0.3341130293490906\n",
            "Round: 2868 Weight: [2.55370814 1.34793579] Bias: -1.1290063925127622 loss: 0.3341130292815387\n",
            "Round: 2869 Weight: [2.55371032 1.34793691] Bias: -1.1290072125430335 loss: 0.33411302921431346\n",
            "Round: 2870 Weight: [2.55371249 1.34793804] Bias: -1.1290080305885117 loss: 0.33411302914741337\n",
            "Round: 2871 Weight: [2.55371466 1.34793916] Bias: -1.1290088466540051 loss: 0.33411302908083657\n",
            "Round: 2872 Weight: [2.55371683 1.34794027] Bias: -1.1290096607443105 loss: 0.33411302901458156\n",
            "Round: 2873 Weight: [2.55371899 1.34794139] Bias: -1.129010472864213 loss: 0.33411302894864703\n",
            "Round: 2874 Weight: [2.55372115 1.3479425 ] Bias: -1.1290112830184857 loss: 0.3341130288830311\n",
            "Round: 2875 Weight: [2.5537233  1.34794361] Bias: -1.1290120912118906 loss: 0.3341130288177325\n",
            "Round: 2876 Weight: [2.55372544 1.34794472] Bias: -1.129012897449178 loss: 0.33411302875274956\n",
            "Round: 2877 Weight: [2.55372758 1.34794582] Bias: -1.1290137017350865 loss: 0.3341130286880808\n",
            "Round: 2878 Weight: [2.55372971 1.34794692] Bias: -1.1290145040743436 loss: 0.3341130286237247\n",
            "Round: 2879 Weight: [2.55373184 1.34794802] Bias: -1.1290153044716649 loss: 0.3341130285596796\n",
            "Round: 2880 Weight: [2.55373397 1.34794911] Bias: -1.1290161029317547 loss: 0.3341130284959442\n",
            "Round: 2881 Weight: [2.55373609 1.34795021] Bias: -1.129016899459306 loss: 0.3341130284325169\n",
            "Round: 2882 Weight: [2.5537382 1.3479513] Bias: -1.129017694059 loss: 0.33411302836939627\n",
            "Round: 2883 Weight: [2.55374031 1.34795239] Bias: -1.1290184867355073 loss: 0.3341130283065808\n",
            "Round: 2884 Weight: [2.55374241 1.34795347] Bias: -1.1290192774934864 loss: 0.3341130282440689\n",
            "Round: 2885 Weight: [2.55374451 1.34795455] Bias: -1.1290200663375851 loss: 0.3341130281818593\n",
            "Round: 2886 Weight: [2.55374661 1.34795563] Bias: -1.1290208532724395 loss: 0.33411302811995036\n",
            "Round: 2887 Weight: [2.55374869 1.34795671] Bias: -1.1290216383026745 loss: 0.3341130280583409\n",
            "Round: 2888 Weight: [2.55375078 1.34795778] Bias: -1.1290224214329039 loss: 0.33411302799702913\n",
            "Round: 2889 Weight: [2.55375286 1.34795886] Bias: -1.1290232026677303 loss: 0.3341130279360138\n",
            "Round: 2890 Weight: [2.55375493 1.34795993] Bias: -1.1290239820117451 loss: 0.33411302787529346\n",
            "Round: 2891 Weight: [2.553757   1.34796099] Bias: -1.1290247594695286 loss: 0.33411302781486674\n",
            "Round: 2892 Weight: [2.55375906 1.34796206] Bias: -1.12902553504565 loss: 0.334113027754732\n",
            "Round: 2893 Weight: [2.55376112 1.34796312] Bias: -1.129026308744667 loss: 0.334113027694888\n",
            "Round: 2894 Weight: [2.55376317 1.34796418] Bias: -1.1290270805711269 loss: 0.33411302763533335\n",
            "Round: 2895 Weight: [2.55376522 1.34796524] Bias: -1.1290278505295657 loss: 0.33411302757606653\n",
            "Round: 2896 Weight: [2.55376727 1.34796629] Bias: -1.1290286186245082 loss: 0.3341130275170862\n",
            "Round: 2897 Weight: [2.5537693  1.34796734] Bias: -1.1290293848604684 loss: 0.33411302745839105\n",
            "Round: 2898 Weight: [2.55377134 1.34796839] Bias: -1.1290301492419494 loss: 0.3341130273999796\n",
            "Round: 2899 Weight: [2.55377337 1.34796944] Bias: -1.1290309117734434 loss: 0.33411302734185055\n",
            "Round: 2900 Weight: [2.55377539 1.34797048] Bias: -1.1290316724594314 loss: 0.33411302728400266\n",
            "Round: 2901 Weight: [2.55377741 1.34797152] Bias: -1.1290324313043838 loss: 0.3341130272264343\n",
            "Round: 2902 Weight: [2.55377942 1.34797256] Bias: -1.1290331883127602 loss: 0.33411302716914426\n",
            "Round: 2903 Weight: [2.55378143 1.3479736 ] Bias: -1.129033943489009 loss: 0.33411302711213103\n",
            "Round: 2904 Weight: [2.55378344 1.34797463] Bias: -1.1290346968375684 loss: 0.3341130270553936\n",
            "Round: 2905 Weight: [2.55378543 1.34797566] Bias: -1.1290354483628653 loss: 0.3341130269989304\n",
            "Round: 2906 Weight: [2.55378743 1.34797669] Bias: -1.129036198069316 loss: 0.33411302694274014\n",
            "Round: 2907 Weight: [2.55378942 1.34797772] Bias: -1.129036945961326 loss: 0.3341130268868215\n",
            "Round: 2908 Weight: [2.5537914  1.34797874] Bias: -1.1290376920432907 loss: 0.3341130268311732\n",
            "Round: 2909 Weight: [2.55379338 1.34797976] Bias: -1.1290384363195942 loss: 0.334113026775794\n",
            "Round: 2910 Weight: [2.55379536 1.34798078] Bias: -1.1290391787946101 loss: 0.3341130267206824\n",
            "Round: 2911 Weight: [2.55379733 1.3479818 ] Bias: -1.1290399194727014 loss: 0.3341130266658372\n",
            "Round: 2912 Weight: [2.5537993  1.34798281] Bias: -1.1290406583582207 loss: 0.3341130266112571\n",
            "Round: 2913 Weight: [2.55380126 1.34798382] Bias: -1.1290413954555096 loss: 0.334113026556941\n",
            "Round: 2914 Weight: [2.55380321 1.34798483] Bias: -1.1290421307688998 loss: 0.3341130265028874\n",
            "Round: 2915 Weight: [2.55380516 1.34798584] Bias: -1.129042864302712 loss: 0.334113026449095\n",
            "Round: 2916 Weight: [2.55380711 1.34798684] Bias: -1.1290435960612564 loss: 0.33411302639556273\n",
            "Round: 2917 Weight: [2.55380905 1.34798784] Bias: -1.1290443260488332 loss: 0.3341130263422893\n",
            "Round: 2918 Weight: [2.55381099 1.34798884] Bias: -1.129045054269732 loss: 0.3341130262892733\n",
            "Round: 2919 Weight: [2.55381292 1.34798984] Bias: -1.1290457807282313 loss: 0.33411302623651357\n",
            "Round: 2920 Weight: [2.55381485 1.34799084] Bias: -1.1290465054286003 loss: 0.33411302618400907\n",
            "Round: 2921 Weight: [2.55381677 1.34799183] Bias: -1.1290472283750972 loss: 0.33411302613175814\n",
            "Round: 2922 Weight: [2.55381869 1.34799282] Bias: -1.12904794957197 loss: 0.33411302607975985\n",
            "Round: 2923 Weight: [2.55382061 1.3479938 ] Bias: -1.1290486690234565 loss: 0.334113026028013\n",
            "Round: 2924 Weight: [2.55382252 1.34799479] Bias: -1.1290493867337839 loss: 0.33411302597651626\n",
            "Round: 2925 Weight: [2.55382442 1.34799577] Bias: -1.1290501027071695 loss: 0.33411302592526854\n",
            "Round: 2926 Weight: [2.55382632 1.34799675] Bias: -1.1290508169478202 loss: 0.3341130258742684\n",
            "Round: 2927 Weight: [2.55382822 1.34799773] Bias: -1.1290515294599328 loss: 0.3341130258235148\n",
            "Round: 2928 Weight: [2.55383011 1.3479987 ] Bias: -1.129052240247694 loss: 0.33411302577300667\n",
            "Round: 2929 Weight: [2.55383199 1.34799968] Bias: -1.1290529493152797 loss: 0.3341130257227426\n",
            "Round: 2930 Weight: [2.55383388 1.34800065] Bias: -1.1290536566668565 loss: 0.3341130256727216\n",
            "Round: 2931 Weight: [2.55383575 1.34800162] Bias: -1.1290543623065805 loss: 0.3341130256229423\n",
            "Round: 2932 Weight: [2.55383763 1.34800258] Bias: -1.1290550662385979 loss: 0.3341130255734038\n",
            "Round: 2933 Weight: [2.55383949 1.34800355] Bias: -1.1290557684670446 loss: 0.33411302552410455\n",
            "Round: 2934 Weight: [2.55384136 1.34800451] Bias: -1.1290564689960465 loss: 0.33411302547504373\n",
            "Round: 2935 Weight: [2.55384322 1.34800547] Bias: -1.1290571678297199 loss: 0.33411302542621996\n",
            "Round: 2936 Weight: [2.55384507 1.34800642] Bias: -1.1290578649721705 loss: 0.3341130253776324\n",
            "Round: 2937 Weight: [2.55384692 1.34800738] Bias: -1.1290585604274943 loss: 0.33411302532927956\n",
            "Round: 2938 Weight: [2.55384877 1.34800833] Bias: -1.1290592541997775 loss: 0.3341130252811605\n",
            "Round: 2939 Weight: [2.55385061 1.34800928] Bias: -1.1290599462930964 loss: 0.3341130252332741\n",
            "Round: 2940 Weight: [2.55385245 1.34801023] Bias: -1.129060636711517 loss: 0.3341130251856191\n",
            "Round: 2941 Weight: [2.55385428 1.34801117] Bias: -1.129061325459096 loss: 0.33411302513819435\n",
            "Round: 2942 Weight: [2.55385611 1.34801212] Bias: -1.12906201253988 loss: 0.334113025090999\n",
            "Round: 2943 Weight: [2.55385793 1.34801306] Bias: -1.1290626979579057 loss: 0.33411302504403173\n",
            "Round: 2944 Weight: [2.55385975 1.34801399] Bias: -1.1290633817172 loss: 0.33411302499729145\n",
            "Round: 2945 Weight: [2.55386156 1.34801493] Bias: -1.1290640638217802 loss: 0.33411302495077727\n",
            "Round: 2946 Weight: [2.55386337 1.34801586] Bias: -1.1290647442756538 loss: 0.33411302490448774\n",
            "Round: 2947 Weight: [2.55386518 1.3480168 ] Bias: -1.1290654230828185 loss: 0.3341130248584221\n",
            "Round: 2948 Weight: [2.55386698 1.34801773] Bias: -1.1290661002472626 loss: 0.33411302481257904\n",
            "Round: 2949 Weight: [2.55386878 1.34801865] Bias: -1.1290667757729642 loss: 0.3341130247669577\n",
            "Round: 2950 Weight: [2.55387057 1.34801958] Bias: -1.1290674496638922 loss: 0.33411302472155685\n",
            "Round: 2951 Weight: [2.55387236 1.3480205 ] Bias: -1.1290681219240055 loss: 0.3341130246763753\n",
            "Round: 2952 Weight: [2.55387414 1.34802142] Bias: -1.1290687925572538 loss: 0.3341130246314123\n",
            "Round: 2953 Weight: [2.55387592 1.34802234] Bias: -1.129069461567577 loss: 0.33411302458666664\n",
            "Round: 2954 Weight: [2.5538777  1.34802325] Bias: -1.1290701289589054 loss: 0.33411302454213726\n",
            "Round: 2955 Weight: [2.55387947 1.34802417] Bias: -1.12907079473516 loss: 0.3341130244978231\n",
            "Round: 2956 Weight: [2.55388124 1.34802508] Bias: -1.1290714589002517 loss: 0.3341130244537232\n",
            "Round: 2957 Weight: [2.553883   1.34802599] Bias: -1.129072121458083 loss: 0.3341130244098363\n",
            "Round: 2958 Weight: [2.55388476 1.3480269 ] Bias: -1.1290727824125457 loss: 0.3341130243661618\n",
            "Round: 2959 Weight: [2.55388651 1.3480278 ] Bias: -1.1290734417675232 loss: 0.3341130243226982\n",
            "Round: 2960 Weight: [2.55388826 1.3480287 ] Bias: -1.1290740995268889 loss: 0.3341130242794448\n",
            "Round: 2961 Weight: [2.55389001 1.3480296 ] Bias: -1.1290747556945067 loss: 0.3341130242364004\n",
            "Round: 2962 Weight: [2.55389175 1.3480305 ] Bias: -1.1290754102742315 loss: 0.3341130241935641\n",
            "Round: 2963 Weight: [2.55389349 1.3480314 ] Bias: -1.1290760632699088 loss: 0.33411302415093486\n",
            "Round: 2964 Weight: [2.55389522 1.34803229] Bias: -1.1290767146853746 loss: 0.3341130241085116\n",
            "Round: 2965 Weight: [2.55389695 1.34803318] Bias: -1.1290773645244556 loss: 0.33411302406629356\n",
            "Round: 2966 Weight: [2.55389867 1.34803407] Bias: -1.1290780127909694 loss: 0.33411302402427956\n",
            "Round: 2967 Weight: [2.55390039 1.34803496] Bias: -1.1290786594887243 loss: 0.33411302398246856\n",
            "Round: 2968 Weight: [2.55390211 1.34803585] Bias: -1.1290793046215193 loss: 0.3341130239408597\n",
            "Round: 2969 Weight: [2.55390382 1.34803673] Bias: -1.129079948193144 loss: 0.3341130238994519\n",
            "Round: 2970 Weight: [2.55390553 1.34803761] Bias: -1.129080590207379 loss: 0.33411302385824443\n",
            "Round: 2971 Weight: [2.55390723 1.34803849] Bias: -1.129081230667996 loss: 0.3341130238172359\n",
            "Round: 2972 Weight: [2.55390893 1.34803937] Bias: -1.1290818695787572 loss: 0.33411302377642577\n",
            "Round: 2973 Weight: [2.55391063 1.34804024] Bias: -1.1290825069434158 loss: 0.33411302373581286\n",
            "Round: 2974 Weight: [2.55391232 1.34804111] Bias: -1.1290831427657158 loss: 0.3341130236953962\n",
            "Round: 2975 Weight: [2.55391401 1.34804198] Bias: -1.129083777049392 loss: 0.334113023655175\n",
            "Round: 2976 Weight: [2.55391569 1.34804285] Bias: -1.1290844097981707 loss: 0.33411302361514805\n",
            "Round: 2977 Weight: [2.55391737 1.34804372] Bias: -1.1290850410157687 loss: 0.3341130235753148\n",
            "Round: 2978 Weight: [2.55391905 1.34804458] Bias: -1.1290856707058936 loss: 0.33411302353567396\n",
            "Round: 2979 Weight: [2.55392072 1.34804544] Bias: -1.1290862988722445 loss: 0.3341130234962246\n",
            "Round: 2980 Weight: [2.55392239 1.3480463 ] Bias: -1.1290869255185114 loss: 0.33411302345696614\n",
            "Round: 2981 Weight: [2.55392405 1.34804716] Bias: -1.129087550648375 loss: 0.33411302341789734\n",
            "Round: 2982 Weight: [2.55392571 1.34804802] Bias: -1.1290881742655077 loss: 0.3341130233790175\n",
            "Round: 2983 Weight: [2.55392736 1.34804887] Bias: -1.1290887963735723 loss: 0.3341130233403254\n",
            "Round: 2984 Weight: [2.55392901 1.34804972] Bias: -1.1290894169762231 loss: 0.3341130233018205\n",
            "Round: 2985 Weight: [2.55393066 1.34805057] Bias: -1.1290900360771057 loss: 0.3341130232635016\n",
            "Round: 2986 Weight: [2.5539323  1.34805142] Bias: -1.1290906536798566 loss: 0.33411302322536796\n",
            "Round: 2987 Weight: [2.55393394 1.34805227] Bias: -1.1290912697881035 loss: 0.33411302318741853\n",
            "Round: 2988 Weight: [2.55393558 1.34805311] Bias: -1.1290918844054652 loss: 0.33411302314965274\n",
            "Round: 2989 Weight: [2.55393721 1.34805395] Bias: -1.129092497535552 loss: 0.33411302311206936\n",
            "Round: 2990 Weight: [2.55393884 1.34805479] Bias: -1.1290931091819654 loss: 0.33411302307466767\n",
            "Round: 2991 Weight: [2.55394046 1.34805563] Bias: -1.129093719348298 loss: 0.3341130230374467\n",
            "Round: 2992 Weight: [2.55394208 1.34805646] Bias: -1.1290943280381336 loss: 0.3341130230004057\n",
            "Round: 2993 Weight: [2.5539437 1.3480573] Bias: -1.1290949352550477 loss: 0.3341130229635436\n",
            "Round: 2994 Weight: [2.55394531 1.34805813] Bias: -1.129095541002607 loss: 0.3341130229268599\n",
            "Round: 2995 Weight: [2.55394691 1.34805896] Bias: -1.129096145284369 loss: 0.33411302289035344\n",
            "Round: 2996 Weight: [2.55394852 1.34805978] Bias: -1.1290967481038836 loss: 0.33411302285402333\n",
            "Round: 2997 Weight: [2.55395012 1.34806061] Bias: -1.1290973494646912 loss: 0.3341130228178689\n",
            "Round: 2998 Weight: [2.55395171 1.34806143] Bias: -1.129097949370324 loss: 0.3341130227818892\n",
            "Round: 2999 Weight: [2.55395331 1.34806225] Bias: -1.1290985478243054 loss: 0.33411302274608334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41bV6yoTSsOI",
        "outputId": "d7a856bb-914d-4e74-90be-4d503db73939"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.74794123,  0.1546519 ],\n",
              "       [-0.13969655, -0.60069237],\n",
              "       [ 1.37394551, -1.44319175],\n",
              "       [ 0.04950871,  0.00939338],\n",
              "       [ 1.46854813,  2.10111597],\n",
              "       [ 0.04950871, -0.57164067],\n",
              "       [-0.80191495,  2.24637449],\n",
              "       [ 2.0361639 ,  1.72344384],\n",
              "       [-0.42350443, -0.31017535],\n",
              "       [-0.23429918, -0.60069237],\n",
              "       [ 0.14411134,  1.49103022],\n",
              "       [-0.3289018 ,  1.20051319],\n",
              "       [-0.70731232, -0.25207194],\n",
              "       [ 1.09013762, -1.00741621],\n",
              "       [ 0.80632974,  0.50327233],\n",
              "       [-1.74794123,  0.41611722],\n",
              "       [ 1.94156127,  0.88094446],\n",
              "       [ 0.42791922, -0.48448556],\n",
              "       [ 0.04950871, -0.60069237],\n",
              "       [-0.23429918, -1.41414004],\n",
              "       [-0.04509392,  0.1837036 ],\n",
              "       [ 0.99553499,  1.83965065],\n",
              "       [-0.13969655,  1.57818533],\n",
              "       [-0.61270969, -1.61750196],\n",
              "       [-1.27492809, -0.45543386],\n",
              "       [-0.42350443,  1.22956489],\n",
              "       [-0.42350443, -0.04871002],\n",
              "       [-0.9911202 ,  1.92680576],\n",
              "       [ 0.61712448,  1.98490916],\n",
              "       [-0.3289018 , -0.80405429],\n",
              "       [-0.23429918,  0.03844509],\n",
              "       [ 1.84695865, -0.31017535],\n",
              "       [-1.46413334, -1.53034686],\n",
              "       [ 0.80632974, -1.41414004],\n",
              "       [ 1.09013762, -1.23982983],\n",
              "       [-0.89651757,  0.47422063],\n",
              "       [-0.70731232, -1.61750196],\n",
              "       [ 0.04950871, -0.33922705],\n",
              "       [-0.23429918, -0.39733045],\n",
              "       [ 0.42791922,  0.241807  ],\n",
              "       [ 0.14411134,  0.73568595],\n",
              "       [ 0.99553499,  0.56137573],\n",
              "       [-0.23429918,  0.50327233],\n",
              "       [ 0.42791922,  0.27085871],\n",
              "       [-0.51810706, -1.53034686],\n",
              "       [-0.70731232,  1.31672   ],\n",
              "       [ 0.99553499, -1.18172642],\n",
              "       [ 2.13076653, -1.06551961],\n",
              "       [-0.9911202 , -1.55939856],\n",
              "       [ 1.75235602, -0.31017535],\n",
              "       [ 0.14411134,  0.241807  ],\n",
              "       [ 0.23871397,  1.05525468],\n",
              "       [-0.23429918, -0.51353726],\n",
              "       [ 0.14411134,  0.1837036 ],\n",
              "       [-0.04509392, -0.51353726],\n",
              "       [-1.27492809, -1.50129515],\n",
              "       [ 0.33331659, -0.57164067],\n",
              "       [ 1.46854813, -1.06551961],\n",
              "       [ 0.14411134,  0.00939338],\n",
              "       [-1.55873597, -0.07776172],\n",
              "       [-1.6533386 ,  0.09654849],\n",
              "       [-1.55873597,  0.03844509],\n",
              "       [ 0.14411134, -0.83310599],\n",
              "       [ 0.14411134,  1.83965065],\n",
              "       [-0.23429918, -1.47224345],\n",
              "       [ 1.09013762,  2.04301257],\n",
              "       [ 0.90093236, -1.32698494],\n",
              "       [ 0.33331659, -0.54258897],\n",
              "       [ 0.42791922, -0.51353726],\n",
              "       [-0.61270969, -0.07776172],\n",
              "       [ 0.80632974,  0.73568595],\n",
              "       [ 0.04950871, -0.28112364],\n",
              "       [-0.9911202 , -1.47224345],\n",
              "       [-1.18032546,  0.27085871],\n",
              "       [ 0.99553499, -1.09457132],\n",
              "       [ 0.14411134, -0.33922705],\n",
              "       [-0.61270969,  0.09654849],\n",
              "       [-1.27492809, -0.36827875],\n",
              "       [-0.89651757,  0.41611722],\n",
              "       [-0.9911202 , -0.39733045],\n",
              "       [ 0.23871397, -0.16491683],\n",
              "       [ 0.33331659, -0.31017535],\n",
              "       [-1.18032546, -1.41414004],\n",
              "       [ 0.90093236,  1.05525468],\n",
              "       [ 1.75235602,  0.96809957],\n",
              "       [ 1.84695865, -1.29793323],\n",
              "       [-0.13969655,  1.37482341],\n",
              "       [ 1.37394551,  1.2586166 ],\n",
              "       [-1.08572283, -1.18172642],\n",
              "       [ 0.14411134,  0.12560019],\n",
              "       [-0.13969655,  0.12560019],\n",
              "       [-1.74794123, -1.50129515],\n",
              "       [ 1.09013762,  0.44516892],\n",
              "       [-0.13969655, -1.09457132],\n",
              "       [-1.08572283, -0.54258897],\n",
              "       [-0.23429918, -0.33922705],\n",
              "       [-0.51810706, -1.53034686],\n",
              "       [-0.80191495, -1.23982983],\n",
              "       [ 0.52252185,  1.20051319],\n",
              "       [ 0.23871397, -0.68784748],\n",
              "       [-1.46413334, -1.26888153],\n",
              "       [ 0.33331659,  0.03844509],\n",
              "       [-0.04509392,  0.27085871],\n",
              "       [-0.9911202 ,  0.56137573],\n",
              "       [-1.08572283,  0.27085871],\n",
              "       [ 0.99553499,  1.40387511],\n",
              "       [-1.08572283,  1.37482341],\n",
              "       [-0.61270969,  1.37482341],\n",
              "       [ 1.18474025, -0.77500259],\n",
              "       [-1.36953072, -0.22302024],\n",
              "       [-0.23429918,  0.03844509],\n",
              "       [ 0.99553499,  1.75249554],\n",
              "       [-1.55873597, -1.58845026],\n",
              "       [ 0.04950871, -0.16491683],\n",
              "       [ 0.90093236,  0.99715127],\n",
              "       [-0.04509392, -0.01965832],\n",
              "       [-0.42350443,  2.27542619],\n",
              "       [ 1.27934288,  2.18827108],\n",
              "       [-0.04509392, -0.39733045],\n",
              "       [-1.55873597,  0.50327233],\n",
              "       [ 1.84695865,  0.09654849],\n",
              "       [-0.80191495, -0.80405429],\n",
              "       [-0.23429918,  0.241807  ],\n",
              "       [-0.42350443, -0.57164067],\n",
              "       [-0.61270969,  0.53232403],\n",
              "       [-1.08572283,  0.27085871],\n",
              "       [-0.9911202 ,  0.53232403],\n",
              "       [-0.23429918,  0.12560019],\n",
              "       [-0.51810706,  2.30447789],\n",
              "       [-0.70731232,  0.241807  ],\n",
              "       [ 0.23871397,  0.12560019],\n",
              "       [ 0.23871397, -0.39733045],\n",
              "       [-0.89651757, -1.12362302],\n",
              "       [ 0.99553499,  1.95585746],\n",
              "       [-1.08572283,  0.03844509],\n",
              "       [ 0.42791922,  0.96809957],\n",
              "       [ 0.23871397,  2.07206427],\n",
              "       [ 1.94156127,  2.13016768],\n",
              "       [ 0.42791922, -0.16491683],\n",
              "       [-0.23429918, -1.26888153],\n",
              "       [ 0.23871397,  0.00939338],\n",
              "       [ 0.33331659,  0.03844509],\n",
              "       [-0.04509392,  2.13016768],\n",
              "       [ 0.14411134, -0.83310599],\n",
              "       [-0.23429918, -0.77500259],\n",
              "       [ 1.56315076, -0.01965832],\n",
              "       [ 0.99553499, -1.09457132],\n",
              "       [ 1.46854813,  0.03844509],\n",
              "       [ 2.13076653,  0.90999617],\n",
              "       [-0.51810706,  1.43292681],\n",
              "       [ 0.33331659,  0.03844509],\n",
              "       [-0.23429918, -0.36827875],\n",
              "       [-1.08572283, -1.12362302],\n",
              "       [ 0.90093236, -0.62974407],\n",
              "       [-1.6533386 , -0.62974407],\n",
              "       [-0.23429918,  0.06749679],\n",
              "       [-0.23429918,  1.08430638],\n",
              "       [-0.51810706,  1.3457717 ],\n",
              "       [ 1.46854813,  0.32896211],\n",
              "       [-0.61270969, -0.13586513],\n",
              "       [ 0.42791922, -0.01965832],\n",
              "       [-0.51810706,  1.3457717 ],\n",
              "       [-1.84254386, -0.07776172],\n",
              "       [ 0.14411134,  0.06749679],\n",
              "       [ 0.52252185,  1.69439214],\n",
              "       [ 0.90093236, -1.47224345],\n",
              "       [-0.23429918, -0.60069237],\n",
              "       [-0.13969655,  1.60723703],\n",
              "       [ 2.13076653,  1.08430638],\n",
              "       [ 0.23871397,  0.03844509],\n",
              "       [ 1.09013762,  0.50327233],\n",
              "       [-1.18032546, -1.09457132],\n",
              "       [-0.13969655, -0.48448556],\n",
              "       [-1.08572283,  0.44516892],\n",
              "       [-0.9911202 , -0.36827875],\n",
              "       [ 1.94156127, -1.38508834],\n",
              "       [ 1.18474025, -1.00741621],\n",
              "       [-0.23429918,  2.21732278],\n",
              "       [ 1.94156127,  0.70663425],\n",
              "       [-1.74794123, -0.01965832],\n",
              "       [-0.80191495,  0.27085871],\n",
              "       [-0.89651757, -0.97836451],\n",
              "       [-0.89651757, -0.33922705],\n",
              "       [ 0.71172711, -1.41414004],\n",
              "       [-0.70731232, -1.55939856],\n",
              "       [ 0.33331659,  0.27085871],\n",
              "       [ 2.0361639 ,  0.35801382],\n",
              "       [ 0.42791922,  0.56137573],\n",
              "       [-0.80191495,  0.12560019],\n",
              "       [ 0.33331659, -0.54258897],\n",
              "       [-0.80191495,  0.35801382],\n",
              "       [-0.23429918, -0.28112364],\n",
              "       [ 0.42791922,  0.06749679],\n",
              "       [-0.70731232,  0.27085871],\n",
              "       [ 2.13076653, -0.83310599],\n",
              "       [ 1.75235602,  1.81059895],\n",
              "       [ 2.13076653, -0.83310599],\n",
              "       [ 0.23871397,  0.2127553 ],\n",
              "       [ 0.14411134,  1.83965065],\n",
              "       [-1.27492809, -0.45543386],\n",
              "       [-0.04509392,  0.2127553 ],\n",
              "       [ 0.90093236, -1.18172642],\n",
              "       [-0.9911202 ,  0.73568595],\n",
              "       [-1.27492809, -1.26888153],\n",
              "       [-0.61270969,  0.1546519 ],\n",
              "       [-0.61270969, -1.53034686],\n",
              "       [ 0.90093236, -0.80405429],\n",
              "       [ 0.71172711, -1.29793323],\n",
              "       [-0.42350443, -0.80405429],\n",
              "       [-1.84254386,  0.44516892],\n",
              "       [-1.74794123, -1.32698494],\n",
              "       [ 0.33331659, -1.18172642],\n",
              "       [ 0.14411134,  0.00939338],\n",
              "       [ 0.99553499, -1.03646791],\n",
              "       [-0.9911202 , -0.36827875],\n",
              "       [ 1.56315076, -1.29793323],\n",
              "       [-1.08572283, -1.55939856],\n",
              "       [-0.42350443, -0.86215769],\n",
              "       [ 0.42791922,  1.08430638],\n",
              "       [-0.04509392, -0.54258897],\n",
              "       [-1.74794123, -1.29793323],\n",
              "       [ 1.94156127, -0.9493128 ],\n",
              "       [-0.89651757,  0.38706552],\n",
              "       [ 0.04950871,  1.22956489],\n",
              "       [-1.36953072,  0.32896211],\n",
              "       [-1.36953072, -0.13586513],\n",
              "       [-0.23429918, -1.38508834],\n",
              "       [-1.18032546,  0.241807  ],\n",
              "       [ 0.23871397, -0.28112364],\n",
              "       [ 0.42791922,  0.27085871],\n",
              "       [-0.61270969,  0.00939338],\n",
              "       [-0.3289018 ,  0.03844509],\n",
              "       [ 1.09013762, -1.23982983],\n",
              "       [-0.13969655, -0.22302024],\n",
              "       [-1.84254386, -0.54258897],\n",
              "       [ 0.90093236, -0.57164067],\n",
              "       [ 2.0361639 ,  0.1546519 ],\n",
              "       [-1.27492809,  0.38706552],\n",
              "       [ 0.42791922,  0.12560019],\n",
              "       [ 0.52252185,  1.81059895],\n",
              "       [-1.84254386, -0.77500259],\n",
              "       [ 1.27934288,  1.83965065],\n",
              "       [ 2.0361639 , -1.21077813],\n",
              "       [-1.84254386,  0.32896211],\n",
              "       [-1.27492809,  0.53232403],\n",
              "       [ 1.37394551,  2.30447789],\n",
              "       [ 2.0361639 , -0.83310599],\n",
              "       [ 1.27934288, -1.38508834],\n",
              "       [-1.46413334,  0.29991041],\n",
              "       [-0.3289018 ,  1.2876683 ],\n",
              "       [-1.08572283, -0.80405429],\n",
              "       [-0.04509392,  0.09654849],\n",
              "       [ 0.99553499, -0.86215769],\n",
              "       [-0.89651757,  0.241807  ],\n",
              "       [-0.13969655,  2.13016768],\n",
              "       [-0.61270969, -0.36827875],\n",
              "       [-0.23429918,  0.12560019],\n",
              "       [-1.46413334, -0.45543386],\n",
              "       [ 0.42791922,  2.27542619],\n",
              "       [ 0.80632974,  0.241807  ],\n",
              "       [-0.13969655,  0.82284106],\n",
              "       [ 1.65775339, -0.9202611 ],\n",
              "       [-1.08572283, -1.61750196],\n",
              "       [ 2.0361639 ,  2.10111597],\n",
              "       [ 0.33331659,  0.47422063],\n",
              "       [-1.08572283, -1.03646791],\n",
              "       [-0.04509392,  0.241807  ],\n",
              "       [ 1.56315076,  0.96809957],\n",
              "       [-0.89651757, -0.33922705],\n",
              "       [-0.51810706,  0.85189276],\n",
              "       [-0.70731232,  1.05525468],\n",
              "       [-0.42350443, -1.23982983],\n",
              "       [-1.27492809, -1.12362302],\n",
              "       [ 0.04950871,  0.27085871],\n",
              "       [-0.3289018 , -1.32698494],\n",
              "       [ 1.09013762,  0.09654849],\n",
              "       [-0.9911202 , -0.48448556],\n",
              "       [ 0.23871397, -0.31017535],\n",
              "       [ 0.23871397, -0.39733045],\n",
              "       [-0.42350443, -1.15267472],\n",
              "       [ 0.99553499,  0.09654849],\n",
              "       [ 1.46854813,  0.96809957],\n",
              "       [ 1.84695865, -1.09457132],\n",
              "       [-1.08572283,  0.29991041],\n",
              "       [ 0.71172711,  1.75249554],\n",
              "       [-0.23429918,  0.00939338],\n",
              "       [-1.08572283,  0.38706552],\n",
              "       [ 0.71172711, -0.74595088],\n",
              "       [ 0.33331659, -0.22302024],\n",
              "       [ 0.90093236, -1.06551961],\n",
              "       [ 0.80632974, -0.33922705],\n",
              "       [-1.6533386 ,  0.32896211],\n",
              "       [-0.04509392,  2.18827108],\n",
              "       [ 0.33331659, -0.74595088],\n",
              "       [ 1.37394551,  0.56137573],\n",
              "       [-0.04509392,  0.27085871],\n",
              "       [-0.23429918, -0.45543386],\n",
              "       [-0.70731232,  0.53232403],\n",
              "       [ 0.71172711, -1.12362302],\n",
              "       [-0.70731232,  0.47422063]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred=predict(X_test)\n",
        "Y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU-a7XtWSyux",
        "outputId": "c9074904-da7a-4d89-c765-93e62a870fd6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print actual and predicted values in a table\n",
        "print(\"actual Value\\tpredicted values\")\n",
        "for i in range(len(y_test)):\n",
        "    print(y_test[i],\"\\t\\t\",int(y_pred[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ronrTSBPS4W9",
        "outputId": "6dbe57df-87ae-40f2-c5aa-608938464be1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual Value\tpredicted values\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=0\n",
        "for i in range(len(y_test)):\n",
        "  if(y_test[i]==y_pred[i]):\n",
        "    x+=1\n",
        "print((x/len(y_test))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNFWkQoES8F6",
        "outputId": "2cdc4adc-bbe7-4c8e-8ae3-1498f5050df7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression()\n",
        "from sklearn.metrics import  accuracy_score\n",
        "#Fit\n",
        "LR.fit(X_train,y_train)\n",
        "\n",
        "#predicting the test label with LR. Predict always takes X as input\n",
        "y_test_pred = LR.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_test_pred)*100\n",
        "print(\"Accuracy: \", accuracy,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx9sKDfeS-sI",
        "outputId": "784b39f5-caeb-4190-a4c8-52b5309d3afa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  79.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "l1=np.array(l1)"
      ],
      "metadata": {
        "id": "vNmVZId7TBtC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(l1)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eVRcreOTjJS",
        "outputId": "1702da4b-4b5f-4d3f-ae85-1a2a935602a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsvEXB-uTpXE",
        "outputId": "3cbc1f5e-5931-452a-fb5e-5af1518bbb4f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7254722 , 0.70993322, 0.69522336, ..., 0.33411302, 0.33411302,\n",
              "       0.33411302])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(range(0,3000))"
      ],
      "metadata": {
        "id": "QgizVzcATtgJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHw95bdWUnaq",
        "outputId": "00238c28-7af1-4976-f957-825966798731"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 2997, 2998, 2999])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hello1=np.array([[28,76000]])\n",
        "hello1=np.array(hello1)\n",
        "     \n",
        "\n",
        "hello1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qznusjrRUqU5",
        "outputId": "2b616d21-dae4-4e7e-b025-c2f836652627"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   28, 76000]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ask=sc.fit(hello1)\n",
        "     \n",
        "\n",
        "x_ask=x_ask.transform(hello1)\n",
        "     \n",
        "\n",
        "x_ask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4e1MogVUxOe",
        "outputId": "baddea25-9afb-46b1-c28f-22e032186e87"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LR.predict(x_ask)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjUroTVWU0n5",
        "outputId": "df41e83e-8d41-48f9-a30d-b30f7ba22fae"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}